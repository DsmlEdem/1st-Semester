{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4285c70c",
   "metadata": {},
   "source": [
    "# Μηχανική Μάθηση - Εργασία 1 - Μέρος Α: Επιβλεπόμενη Μάθηση"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256ab024",
   "metadata": {},
   "source": [
    "Στόχος του πρώτου μέρους της ατομικής αυτής εργασίας είναι η εφαρμογή μεθόδων επιβλεπόμενης μάθησης για την ανάλυση ενός συνόλου δεδομένων του OpenML και συγκεκριμένα του συνόλου με ID 312, γνωστό και ως **Scene**. Το σύνολο από το οποίο προέκυψε βασίζεται σε πραγματικές εικόνες, από τις οποίες έχουν εξαχθεί ορισμένα χαρακτηριστικά, για χρήση μεθόδων πολλαπλής ταξινόμησης (multi label classification) σε 6 κατηγορίες. Το παρόν σύνολο αφορά μονάχα τη δυαδική ταξινόμηση σε μια κατηγορία (όπως διαβάζει κανείς καλώντας την `dataset.description` παρακάτω) και συγκεκριμένα το κατά πόσο κάθε εικόνα αντιστοιχεί σε αστικό σκηνικό (urban) ή όχι (not urban).\n",
    "\n",
    "Πριν ξεκινήσουμε την επισκόπηση του συνόλου δεδομένων, θα κάνουμε `import` ορισμένες βασικές βιβλιοθήκες, απαραίτητες για κάθε σχεδόν πρόβλημα μηχανικής μάθησης ή ανάλυσης δεδομένων. Επιπλέον, θα ορίσουμε κάποια πράγματα απαραίτητα για το formatting της εργασίας (auxiliary functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d2ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd1f51e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import colors\n",
    "\n",
    "# Some custom colors\n",
    "mycol = (0.13333, 0.35294, 0.38824)\n",
    "mycomplcol = (0.6, 0.4549, 0.2078)\n",
    "\n",
    "sns.set(style = \"darkgrid\") # for graphs style\n",
    "\n",
    "# to present plt.show() graphs centered\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea68ef5",
   "metadata": {},
   "source": [
    "## Επισκόπηση\n",
    "\n",
    "Το πρώτο βήμα της επεξεργασίας αποτελεί η λήψη των δεδομένων, η οποία γίνεται μέσω του API του OpenML, όπως φαίνεται στα ακόλουθα βήματα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b88e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import openml\n",
    "import openml as oml\n",
    "\n",
    "# The following variable contained the API key which is not made public for\n",
    "# obvious reasons. Please use your own key if you want to run this notebook.\n",
    "oml.config.apikey = '????'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a04be6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is dataset scene, the default target feature is Urban.\n",
      "URL: https://www.openml.org/data/v1/download/1390080/scene.arff\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset by ID\n",
    "dataset = oml.datasets.get_dataset(312)\n",
    "\n",
    "# Basic information about the dataset.\n",
    "print(f\"This is dataset {dataset.name}, the default target feature is {dataset.default_target_attribute}.\")\n",
    "print(f\"URL: {dataset.url}\")\n",
    "\n",
    "# Uncomment the following to get details on the dataset.\n",
    "# The \"Description\" paragraph explains that the current dataset is\n",
    "# a binary classification problem considering just the 'Urban' label.\n",
    "\n",
    "#print(dataset.description)\n",
    "\n",
    "X, y, categorical_indicator, attribute_names = dataset.get_data(dataset_format=\"array\", target=dataset.default_target_attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ada8789",
   "metadata": {},
   "source": [
    "Καθίσταται προφανές πως, εφόσον τα δεδομένα δεν ελήφθησαν «χειροκίνητα», δεν υπήρχε ζήτημα μετατροπών κάποιων plain text αρχείων. Παρακάτω, μέσω της βιβλιοθήκης `pandas` τα δεδομένα που ελήφθησαν μέσω του API φορτώνονται σε ένα pandas dataframe, προς περαιτέρω επεξεργασία. Η μεταβλητή `attribute_names` στην παραπάνω κλήση φροντίζει να θέσει την ονομασία (ετικέτες) των στηλών του dataframe, ενώ η μεταβλητή `categorical_indicator` υποδεικνύει ποιες από τις στήλες περιλαμβάνουν κατηγορικά χαρακτηριστικά και ποιες όχι. Τέλος, η δείκτρια μεταβλητή `y` αντιστοιχεί στην κατηγορία ταξινόμησης (η οποία είναι η Urban, αλλά στα παρακάτω τη μετονομάζουμε σε Class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a4ec79c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr1</th>\n",
       "      <th>attr2</th>\n",
       "      <th>attr3</th>\n",
       "      <th>attr4</th>\n",
       "      <th>attr5</th>\n",
       "      <th>attr6</th>\n",
       "      <th>attr7</th>\n",
       "      <th>attr8</th>\n",
       "      <th>attr9</th>\n",
       "      <th>attr10</th>\n",
       "      <th>...</th>\n",
       "      <th>attr291</th>\n",
       "      <th>attr292</th>\n",
       "      <th>attr293</th>\n",
       "      <th>attr294</th>\n",
       "      <th>Beach</th>\n",
       "      <th>Sunset</th>\n",
       "      <th>FallFoliage</th>\n",
       "      <th>Field</th>\n",
       "      <th>Mountain</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.646467</td>\n",
       "      <td>0.666435</td>\n",
       "      <td>0.685047</td>\n",
       "      <td>0.699053</td>\n",
       "      <td>0.652746</td>\n",
       "      <td>0.407864</td>\n",
       "      <td>0.150309</td>\n",
       "      <td>0.535193</td>\n",
       "      <td>0.555689</td>\n",
       "      <td>0.580782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157332</td>\n",
       "      <td>0.247298</td>\n",
       "      <td>0.014025</td>\n",
       "      <td>0.029709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.770156</td>\n",
       "      <td>0.767255</td>\n",
       "      <td>0.761053</td>\n",
       "      <td>0.745630</td>\n",
       "      <td>0.742231</td>\n",
       "      <td>0.688086</td>\n",
       "      <td>0.708416</td>\n",
       "      <td>0.757351</td>\n",
       "      <td>0.760633</td>\n",
       "      <td>0.740314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251454</td>\n",
       "      <td>0.137833</td>\n",
       "      <td>0.082672</td>\n",
       "      <td>0.036320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.793984</td>\n",
       "      <td>0.772096</td>\n",
       "      <td>0.761820</td>\n",
       "      <td>0.762213</td>\n",
       "      <td>0.740569</td>\n",
       "      <td>0.734361</td>\n",
       "      <td>0.722677</td>\n",
       "      <td>0.849128</td>\n",
       "      <td>0.839607</td>\n",
       "      <td>0.812746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0.051125</td>\n",
       "      <td>0.112506</td>\n",
       "      <td>0.083924</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.938563</td>\n",
       "      <td>0.949260</td>\n",
       "      <td>0.955621</td>\n",
       "      <td>0.966743</td>\n",
       "      <td>0.968649</td>\n",
       "      <td>0.869619</td>\n",
       "      <td>0.696925</td>\n",
       "      <td>0.953460</td>\n",
       "      <td>0.959631</td>\n",
       "      <td>0.966320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019267</td>\n",
       "      <td>0.031290</td>\n",
       "      <td>0.049780</td>\n",
       "      <td>0.090959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.512130</td>\n",
       "      <td>0.524684</td>\n",
       "      <td>0.520020</td>\n",
       "      <td>0.504467</td>\n",
       "      <td>0.471209</td>\n",
       "      <td>0.417654</td>\n",
       "      <td>0.364292</td>\n",
       "      <td>0.562266</td>\n",
       "      <td>0.588592</td>\n",
       "      <td>0.584449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198151</td>\n",
       "      <td>0.238796</td>\n",
       "      <td>0.164270</td>\n",
       "      <td>0.184290</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      attr1     attr2     attr3     attr4     attr5     attr6     attr7  \\\n",
       "0  0.646467  0.666435  0.685047  0.699053  0.652746  0.407864  0.150309   \n",
       "1  0.770156  0.767255  0.761053  0.745630  0.742231  0.688086  0.708416   \n",
       "2  0.793984  0.772096  0.761820  0.762213  0.740569  0.734361  0.722677   \n",
       "3  0.938563  0.949260  0.955621  0.966743  0.968649  0.869619  0.696925   \n",
       "4  0.512130  0.524684  0.520020  0.504467  0.471209  0.417654  0.364292   \n",
       "\n",
       "      attr8     attr9    attr10  ...   attr291   attr292   attr293   attr294  \\\n",
       "0  0.535193  0.555689  0.580782  ...  0.157332  0.247298  0.014025  0.029709   \n",
       "1  0.757351  0.760633  0.740314  ...  0.251454  0.137833  0.082672  0.036320   \n",
       "2  0.849128  0.839607  0.812746  ...  0.017166  0.051125  0.112506  0.083924   \n",
       "3  0.953460  0.959631  0.966320  ...  0.019267  0.031290  0.049780  0.090959   \n",
       "4  0.562266  0.588592  0.584449  ...  0.198151  0.238796  0.164270  0.184290   \n",
       "\n",
       "   Beach  Sunset  FallFoliage  Field  Mountain  Class  \n",
       "0    1.0     0.0          0.0    0.0       1.0      0  \n",
       "1    1.0     0.0          0.0    0.0       0.0      1  \n",
       "2    1.0     0.0          0.0    0.0       0.0      0  \n",
       "3    1.0     0.0          0.0    0.0       0.0      0  \n",
       "4    1.0     0.0          0.0    0.0       0.0      0  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X, columns=attribute_names)\n",
    "df[\"Class\"] = y # This corresponds to 'Urban'\n",
    "# To get a glimpse of the constructed dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05082914",
   "metadata": {},
   "source": [
    "Γίνεται εμφανές πως οι επικεφαλίδες για τις στήλες υπάρχουν (θα μπορούσε, για παράδειγμα, το `attribute_names` να είναι κενό), αν και η πληροφορία ως προς το τι είναι το κάθε χαρακτηριστικό απουσιάζει (τα χαρακτηριστικά καλούνται απλώς με το πρόθεμα attr και έναν αύξοντα αριθμό). Για λόγους σύμβασης, θα μετατρέψουμε τις τιμές των στηλών με τίτλο `Beach`, `Sunset`, `FallFoliage`, `Field` και `Mountain` σε ακεραίους (0,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "982ad825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({\"Beach\": int, \"Sunset\": int, \"FallFoliage\": int, \"Field\": int, \"Mountain\": int})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa67c20",
   "metadata": {},
   "source": [
    "Ας δούμε τώρα μέσω των επόμενων εκτυπώσεων κάποια άλλα βασικά χαρακτηριστικά του συνόλου που επεξεργαζόμαστε."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "581b31ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ The dataframe includes 300 column(s) and 2407 row(s).\n",
      "▶ The first 299 columns correspond to feature values, while the last column corresponds to the class label.\n",
      "▶ Of the 299 features, 294 correspond to numeric values, while 5 correspond to categorical values.\n",
      "▶ There is a total of 0 missing value(s) from the dataset.\n"
     ]
    }
   ],
   "source": [
    "print(f\"▶ The dataframe includes {df.shape[1]} column(s) and {df.shape[0]} row(s).\")\n",
    "print(f\"▶ The first {len(attribute_names)} columns correspond to feature values, while the last column corresponds to the class label.\")\n",
    "print(f\"▶ Of the {len(attribute_names)} features, {(np.asarray(categorical_indicator)==False).sum()} correspond to numeric values, while {(np.asarray(categorical_indicator)==True).sum()} correspond to categorical values.\")\n",
    "print(f\"▶ There is a total of {df.isnull().values.sum()} missing value(s) from the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20321dbe",
   "metadata": {},
   "source": [
    "Σε κάθε περίπτωση, είναι ευχάριστο το γεγονός πως δεν υπάρχουν απουσιάζουσες τιμές στο σύνολο δεδομένων. Στο σημείο αυτό, όμως, εγείρεται ένα σημαντικό ερώτημα: παρότι δεν υπάρχουν μη διατεταγμένα δεδομένα, αφού τα 6 κατηγορικά χαρακτηριστικά έχουν χωριστεί σε 6 διαφορετικές στήλες, καθεμιά εκ των οποίων λαμβάνει την τιμή 0 ή 1, τα 5 από τα 6 κατηγορικά χαρακτηριστικά δεν έχουν κατασκευαστεί ώστε να αποτελούν χαρακτηριστικά προς ταξινόμηση των δεδομένων σε urban/not urban. Αντιθέτως, το σύνολο δεδομένων κατασκευάστηκε αρχικά για να αποτελέσει ένα σύνολο για χρήση πολλαπλής ταξινόμησης. Είναι, λοιπόν, σωστό τα labels των υπόλοιπων κατηγοριών να χρησιμοποιηθούν εδώ ως χαρακτηριστικά για τον προσδιορισμό ενός άλλου label; Η απάντηση από μεριάς μας είναι αρνητική από εννοιολογική πλευρά. Ως εκ τούτου, παρακάτω θα αφαιρέσουμε τις στήλες που αφορούν τις 5 κατηγορίες οι οποίες δεν αξιοποιούνται σε αυτό το πρόβλημα.\n",
    "\n",
    "Ολοκληρώνοντας την επισκόπηση του συνόλου δεδομένων, αξίζει να μελετηθεί το κατά πόσο το σύνολο δεδομένων είναι ισορροπημένο ή όχι. Επιλέγουμε, για λόγους πληρότητας, να πραγματοποιήσουμε τη μελέτη αυτή σε δύο άξονες: αφενός, να εξετάσουμε κατά πόσο το σύνολο **αυτό καθ' αυτό** είναι ισορροπημένο, δηλαδή να μελετήσουμε κατά πόσο οι σχετικές συχνότητες των 6 αρχικών κατηγοριών  είναι παρόμοιες ή όχι. Από την άλλη, να εξετάσουμε μόνο τη συχνότητα της δείκτριας κατηγορίας που καλούμαστε να μελετήσουμε παρακάτω και άρα κατά πόσο το σύνολο δεδομένων είναι ισορροπημένο **υπό συνθήκη**, δηλαδή για τη χρήση που επιθυμούμε να κάνουμε."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bbf856",
   "metadata": {},
   "source": [
    "### Έλεγχος ισορροπίας για το σύνολο αυτό καθ' αυτό"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82dc06d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = {}\n",
    "for i in range(6):\n",
    "    # Calculate the instances of each of the original 6 classes\n",
    "    class_num[i] = (df.iloc[:,(np.asarray(categorical_indicator)==False).sum()+i]==1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6acbd6",
   "metadata": {},
   "source": [
    "Ενδιαφέρον παρουσιάζει το γεγονός πως οι 6 αρχικές κατηγορίες δεν ορίζουν ένα πρόβλημα πολλαπλής ταξινόμησης υπό τη συνηθισμένη έννοια του όρου. Αυτό γίνεται εύκολα αντιληπτό, εάν κανείς συγκρίνει τους ακόλουθους αριθμούς:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "086df78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of data is 2407.\n",
      "The total number of class labels equal to 1 (i.e. truth of label) is 2585.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The total number of data is {df.shape[0]}.\")\n",
    "print(f\"The total number of class labels equal to 1 (i.e. truth of label) is {sum(class_num.values())}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b70cfc",
   "metadata": {},
   "source": [
    "Το γεγονός αυτό υποδεικνύει πως υπάρχουν δεδομένα τα οποία ταξινομούνται σε περισσότερες από μία κατηγορίες. Ενδέχεται αυτός να είναι και ο λόγος για τον οποίο στην επεξήγηση του συνόλου δεδομένων αυτό περιγράφεται ως ένα binary classification problem dataset με δείκτρια κατηγορία την Urban. Το πλήθος των δεδομένων τα οποία ταξινομούνται σε περισσότερες από μία κατηγορίες είναι **το πολύ**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5932ba94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum number of data classified in more than one classes are 178.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The maximum number of data classified in more than one classes are {sum(class_num.values())-df.shape[0]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1d2669",
   "metadata": {},
   "source": [
    "Δεδομένου πως αυτός ο αριθμός αποτελεί περίπου το 7% των δεδομένων, θα ακολουθήσουμε τις γνωστές συμβάσεις προκειμένου να αποφανθούμε εάν το αρχικό σύνολο δεδομένων είναι ισορροπημένο ή όχι. Παρ' όλα αυτά, λαμβάνουμε πάντοτε υπ' όψιν πως υπάρχουν ορισμένα περιθώρια σφάλματος στα επόμενα συμπεράσματα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92fd96ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The frequency of class No. 1 in the original data is 17.74%.\n",
      "The frequency of class No. 2 in the original data is 15.12%.\n",
      "The frequency of class No. 3 in the original data is 16.49%.\n",
      "The frequency of class No. 4 in the original data is 17.99%.\n",
      "The frequency of class No. 5 in the original data is 22.14%.\n",
      "The frequency of class No. 6 in the original data is 17.91%.\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(f\"The frequency of class No. {i+1} in the original data is {100*class_num[i]/df.shape[0]:.2f}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3365dae",
   "metadata": {},
   "source": [
    "Σημειώνεται πως, αφού υπάρχουν δεδομένα τα οποία κατατάσσονται σε περισσότερες από μία κατηγορίες, είναι αναμενόμενο τα παραπάνω ποσοστά να μην αθροίζουν στο 100%. Συγκεκριμένα, το άθροισμά τους είναι περίπου 107%, δηλαδή ακριβώς τόσες ποσοστιαίες μονάδες πάνω από το 100%, όσες και το ποσοστό του μέγιστου αριθμού δεδομένων τα οποία κατατάσσονται σε περισσότερες από μία κατηγορίες.\n",
    "\n",
    "Γίνεται εμφανές πως η κατηγορία υπ' αριθμόν 5 (Mountain) είναι η συχνότερη, με σχετική συχνότητα εμφάνισης 22.14%, ενώ η λιγότερο συχνή κατηγορία είναι η υπ' αριθμόν 2 (Sunset) με σχετική συχνότητα εμφάνισης 15.12%. Εφόσον ο λόγος των σχετικών τους συχνοτήτων ισούται περίπου με 1.46, το οποίο είναι μικρότερο από το συμβατικό κατώφλι του 1.5, μπορεί κανείς να συμπεράνει πως το αρχικό σύνολο δεδομένων αυτό καθ' αυτό είναι *οριακά* ισορροπημένο."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ee60cd",
   "metadata": {},
   "source": [
    "### Έλεγχος ισορροπίας για το σύνολο υπό συνθήκη\n",
    "\n",
    "Η προηγούμενη ανάλυση μάλλον κατέστησε ήδη προφανές πως το σύνολο σε ό,τι αφορά την κατηγορία υπ' αριθμόν 6 (Urban) δεν είναι ισορροπημένο. Για του λόγου το αληθές:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec232b5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The instances where class Urban is true is 431 out of 2407 total instances.\n",
      "This indicates that its relevant frequency is about 17.91%.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The instances where class Urban is true is {(df['Class'] == 1).sum()} out of {df.shape[0]} total instances.\")\n",
    "print(f\"This indicates that its relevant frequency is about {100*(df['Class'] == 1).sum()/df.shape[0]:.2f}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79151175",
   "metadata": {},
   "source": [
    "Έτσι, εξετάζοντας το συγκεκριμένο σύνολο δεδομένων ως ένα binary dataset, είναι εξόφθαλμο πως αυτό είναι σημαντικά μη ισορροπημένο, ξεπερνώντας κατά πολύ το συμβατικό κατώφλι του 60%-40% (συγκεκριμένα, εδώ έχουμε ποσοστά 82.09% - 17.91%). Αυτό σημαίνει πως εάν θέλουμε μια αποδοτική εκπαίδευση μοντέλων ταξινόμησης επάνω στο συγκεκριμένο σύνολο δεδομένων θα πρέπει να ληφθούν μέτρα για την τεχνητή εξισορρόπησή του."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba58ebb",
   "metadata": {},
   "source": [
    "## Προετοιμασία - Προεπεξεργασία\n",
    "\n",
    "Η προετοιμασία των δεδομένων προκειμένου αυτά να αξιοποιηθούν για την εκπαίδευση ταξινομητών θα πραγματοποιηθεί για δύο περιπτώσεις: στη μία, τα διαθέσιμα δεδομένα θα χωριστούν απλώς σε δεδομένα εκπαίδευσης και δεδομένα αξιολόγησης, χωρίς περαιτέρω επεξεργασία. Στην άλλη περίπτωση, θα πραγματοποιηθεί μια προεπεξεργασία προκειμένου να αποκτήσουμε μια εικόνα του πόσο η προεπεξεργασία επηρεάζει τα τελικά αποτελέσματα των ταξινομητών που θα μελετηθούν, χωρίς όμως να προχωρήσουμε σε πλήρη βελτιστοποίηση (αυτό θα γίνει στο τέλος, επομένως η παρούσα προεπεξεργασία θα γίνει ως ένα ενδιάμεσο βήμα μεταξύ της out-of-the-box και της τελικής επίδοσης). Σε καθεμία εκ των περιπτώσεων αυτών, το πρώτο βήμα θα είναι η απόρριψη των στηλών που αφορούν τις κατηγορικές μεταβλητές πέραν της Urban, για τους λόγους που εξηγήθηκαν στην προηγούμενη ενότητα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8c4d56e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr1</th>\n",
       "      <th>attr2</th>\n",
       "      <th>attr3</th>\n",
       "      <th>attr4</th>\n",
       "      <th>attr5</th>\n",
       "      <th>attr6</th>\n",
       "      <th>attr7</th>\n",
       "      <th>attr8</th>\n",
       "      <th>attr9</th>\n",
       "      <th>attr10</th>\n",
       "      <th>...</th>\n",
       "      <th>attr286</th>\n",
       "      <th>attr287</th>\n",
       "      <th>attr288</th>\n",
       "      <th>attr289</th>\n",
       "      <th>attr290</th>\n",
       "      <th>attr291</th>\n",
       "      <th>attr292</th>\n",
       "      <th>attr293</th>\n",
       "      <th>attr294</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.646467</td>\n",
       "      <td>0.666435</td>\n",
       "      <td>0.685047</td>\n",
       "      <td>0.699053</td>\n",
       "      <td>0.652746</td>\n",
       "      <td>0.407864</td>\n",
       "      <td>0.150309</td>\n",
       "      <td>0.535193</td>\n",
       "      <td>0.555689</td>\n",
       "      <td>0.580782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049615</td>\n",
       "      <td>0.068962</td>\n",
       "      <td>0.653879</td>\n",
       "      <td>0.354982</td>\n",
       "      <td>0.124074</td>\n",
       "      <td>0.157332</td>\n",
       "      <td>0.247298</td>\n",
       "      <td>0.014025</td>\n",
       "      <td>0.029709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.770156</td>\n",
       "      <td>0.767255</td>\n",
       "      <td>0.761053</td>\n",
       "      <td>0.745630</td>\n",
       "      <td>0.742231</td>\n",
       "      <td>0.688086</td>\n",
       "      <td>0.708416</td>\n",
       "      <td>0.757351</td>\n",
       "      <td>0.760633</td>\n",
       "      <td>0.740314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160008</td>\n",
       "      <td>0.414088</td>\n",
       "      <td>0.361843</td>\n",
       "      <td>0.303399</td>\n",
       "      <td>0.176387</td>\n",
       "      <td>0.251454</td>\n",
       "      <td>0.137833</td>\n",
       "      <td>0.082672</td>\n",
       "      <td>0.036320</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.793984</td>\n",
       "      <td>0.772096</td>\n",
       "      <td>0.761820</td>\n",
       "      <td>0.762213</td>\n",
       "      <td>0.740569</td>\n",
       "      <td>0.734361</td>\n",
       "      <td>0.722677</td>\n",
       "      <td>0.849128</td>\n",
       "      <td>0.839607</td>\n",
       "      <td>0.812746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038082</td>\n",
       "      <td>0.079977</td>\n",
       "      <td>0.004901</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.006049</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0.051125</td>\n",
       "      <td>0.112506</td>\n",
       "      <td>0.083924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.938563</td>\n",
       "      <td>0.949260</td>\n",
       "      <td>0.955621</td>\n",
       "      <td>0.966743</td>\n",
       "      <td>0.968649</td>\n",
       "      <td>0.869619</td>\n",
       "      <td>0.696925</td>\n",
       "      <td>0.953460</td>\n",
       "      <td>0.959631</td>\n",
       "      <td>0.966320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016922</td>\n",
       "      <td>0.024174</td>\n",
       "      <td>0.036799</td>\n",
       "      <td>0.007694</td>\n",
       "      <td>0.009735</td>\n",
       "      <td>0.019267</td>\n",
       "      <td>0.031290</td>\n",
       "      <td>0.049780</td>\n",
       "      <td>0.090959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.512130</td>\n",
       "      <td>0.524684</td>\n",
       "      <td>0.520020</td>\n",
       "      <td>0.504467</td>\n",
       "      <td>0.471209</td>\n",
       "      <td>0.417654</td>\n",
       "      <td>0.364292</td>\n",
       "      <td>0.562266</td>\n",
       "      <td>0.588592</td>\n",
       "      <td>0.584449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023177</td>\n",
       "      <td>0.129994</td>\n",
       "      <td>0.167709</td>\n",
       "      <td>0.226580</td>\n",
       "      <td>0.218534</td>\n",
       "      <td>0.198151</td>\n",
       "      <td>0.238796</td>\n",
       "      <td>0.164270</td>\n",
       "      <td>0.184290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      attr1     attr2     attr3     attr4     attr5     attr6     attr7  \\\n",
       "0  0.646467  0.666435  0.685047  0.699053  0.652746  0.407864  0.150309   \n",
       "1  0.770156  0.767255  0.761053  0.745630  0.742231  0.688086  0.708416   \n",
       "2  0.793984  0.772096  0.761820  0.762213  0.740569  0.734361  0.722677   \n",
       "3  0.938563  0.949260  0.955621  0.966743  0.968649  0.869619  0.696925   \n",
       "4  0.512130  0.524684  0.520020  0.504467  0.471209  0.417654  0.364292   \n",
       "\n",
       "      attr8     attr9    attr10  ...   attr286   attr287   attr288   attr289  \\\n",
       "0  0.535193  0.555689  0.580782  ...  0.049615  0.068962  0.653879  0.354982   \n",
       "1  0.757351  0.760633  0.740314  ...  0.160008  0.414088  0.361843  0.303399   \n",
       "2  0.849128  0.839607  0.812746  ...  0.038082  0.079977  0.004901  0.003460   \n",
       "3  0.953460  0.959631  0.966320  ...  0.016922  0.024174  0.036799  0.007694   \n",
       "4  0.562266  0.588592  0.584449  ...  0.023177  0.129994  0.167709  0.226580   \n",
       "\n",
       "    attr290   attr291   attr292   attr293   attr294  Class  \n",
       "0  0.124074  0.157332  0.247298  0.014025  0.029709      0  \n",
       "1  0.176387  0.251454  0.137833  0.082672  0.036320      1  \n",
       "2  0.006049  0.017166  0.051125  0.112506  0.083924      0  \n",
       "3  0.009735  0.019267  0.031290  0.049780  0.090959      0  \n",
       "4  0.218534  0.198151  0.238796  0.164270  0.184290      0  \n",
       "\n",
       "[5 rows x 295 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Beach', 'Sunset', 'FallFoliage', 'Field', 'Mountain'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf57e3d",
   "metadata": {},
   "source": [
    "Στη συνέχεια, προχωρούμε στο διαχωρισμό των δεδομένων σε δεδομένα εκπαίδευσης και δεδομένα αξιολόγησης σε ποσοστό 30%. Ακολουθούμε τη μέθοδο `stratified split`, μέσω της οποίας επιτυγχάνουμε η αναλογία δεδομένων εκπαίδευσης και δεδομένων αξιολόγησης να είναι σταθερή στα δύο σύνολα δεδομένων. Η `random_state` επιλέγεται καθαρά για λόγους debugging, καθώς και προκειμένου τα αποτελέσματα που θα παρουσιαστούν να είναι αναπαράξιμα και σε μελλοντικές εκτελέσεις του notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8c0fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the sklearn function that performs the splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Keep only the features into a numpy array\n",
    "X_train = np.asarray(df.drop(['Class'], axis=1))\n",
    "\n",
    "X_train_unmod, X_test_unmod, y_train, y_test = train_test_split(X_train, y, test_size=0.3, random_state=24, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f94ed6",
   "metadata": {},
   "source": [
    "Τα παραπάνω numpy arrays για τα χαρακτηριστικά φέρουν τον επιπλέον δείκτη `unmod`, καθώς συνιστούν τα σύνολα εκπαίδευσης και αξιολόγησης που θα αξιοποιηθούν για την out-of-the-box εκπαίδευση και αξιολόγηση των ταξινομητών."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5316808",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7066e6",
   "metadata": {},
   "source": [
    "Σε όσα ακολουθούν στην παρούσα ενότητα, θα γίνει αναφορά σε ορισμένες τεχνικές προεπεξεργασίας τις οποίες θα χρησιμοποιήσουμε πριν προχωρήσουμε στην τελική βελτιστοποίηση του εκάστοτε μοντέλου για να αποκτήσουμε μια εικόνα της επιρροής που αυτές έχουν στην επίδοση των ταξινομητών. Ο λόγος για τον οποίο επιλέγουμε να εισαγάγουμε το ενδιάμεσο αυτό βήμα είναι πως κατά την αναζήτηση πλέγματος μας δίνεται η δυνατότητα να ρυθμίσουμε διάφορες υπερπαραμέτρους, όμως όχι το αν θα εφαρμοστούν ή όχι κάποια σημεία ενός pipeline που ορίζει την προεπεξεργασία των δεδομένων. Για παράδειγμα, το αν θα πρέπει τα δεδομένα να υποστούν κανονικοποίηση μέσω ενός StandardScaler, μέσω ενός MinMaxScaler ή να μην υποστούν καν κανονικοποίηση, είναι κάτι το οποίο η συνήθης αναζήτηση πλέγματος δε μπορεί να διερευνήσει. Φυσικά, θα πραγματοποιήσουμε τη διερεύνηση αυτή χρησιμοποιώντας διασταυρούμενη επικύρωση στο σύνολο των δεδομένων εκπαίδευσης, χωρίς να επέμβουμε με οποιοδήποτε τρόπο στο σύνολο αξιολόγησης, αφού σε ρεαλιστικές συνθήκες δεν υπάρχει πρόσβαση σε αυτό μέχρι και το deployment του εκάστοτε μοντέλου.\n",
    "\n",
    "Αρχικά, θα πραγματοποιήσουμε αξιολόγηση μέσω δεκαπλής διασταυρούμενης επικύρωσης σε κάθε ταξινομητή για τις default τιμές του χρησιμοποιώντας τα `unmod` δεδομένα, ώστε να υπάρχει ένα σημείο αναφοράς με βάση το οποίο θα έχουμε τη δυνατότητα να αξιολογούμε την επιρροή κάθε διαδικασίας προεπεξεργασίας."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be5b7c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required classifier libraries\n",
    "from sklearn.naive_bayes import GaussianNB # for gaussian naive bayes\n",
    "from sklearn import neighbors # for kNN\n",
    "from sklearn.linear_model import LogisticRegression # for logistic regression\n",
    "from sklearn.neural_network import MLPClassifier # for perceptron\n",
    "from sklearn.svm import SVC # for SVC\n",
    "\n",
    "# import the cross validation model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# to ignore convergence warnings for the MLP classifier\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7697bf4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by GaussianNB is 68.52% with a standard deviation of 2.91%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by KNeighborsClassifier is 86.34% with a standard deviation of 2.55%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by LogisticRegression is 86.64% with a standard deviation of 2.90%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by MLPClassifier is 88.66% with a standard deviation of 1.74%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by SVC is 89.37% with a standard deviation of 1.70%.\n"
     ]
    }
   ],
   "source": [
    "# define a function to do the cross-validation and the diagnostics report\n",
    "# so that we don't have to repeat the following lines of code many times.\n",
    "def InitCrossVal(X,y):\n",
    "    \n",
    "    CLFs = {1 : GaussianNB(), 2 : neighbors.KNeighborsClassifier(), 3 : LogisticRegression(), 4 : MLPClassifier(), 5 : SVC()}\n",
    "\n",
    "    for i in range(1,6): # 5 classifiers\n",
    "        clf = CLFs[i]\n",
    "        scores = cross_val_score(clf, X, y, cv=10)\n",
    "        print(101*\"-\")\n",
    "        print(f\"The mean CV-score achieved by {str(CLFs[i]).replace('()','')} is {100*scores.mean():.2f}% with a standard deviation of {100*scores.std():.2f}%.\")\n",
    "\n",
    "    return\n",
    "\n",
    "InitCrossVal(X_train_unmod,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bd5016",
   "metadata": {},
   "source": [
    "Τα πρωταρχικά αυτά αποτελέσματα υποδεικνύουν το λόγο για τον οποίο το ενδιάμεσο αυτό βήμα κρίθηκε απαραίτητο. Όπως γίνεται εμφανές, με εξαίρεση τον Gaussian Naive Bayes, όλοι οι ταξινομητές πετυχαίνουν CV-score υψηλότερο του 85%. Ενδέχεται, λοιπόν, τα δεδομένα που χρησιμοποιούμε να έχουν ήδη υποστεί κάποια προεπεξεργασία, ή τα χαρακτηριστικά να είχαν επιλεγεί με πολύ προσεκτικούς ελέγχους. Αυτό σημαίνει πως, σε αντίθεση με τη συνήθη περίπτωση, η περαιτέρω προεπεξεργασία τους πριν την τελική βελτιστοποίηση των ταξινομητών μπορεί να οδηγήσει σε χαμηλότερες επιδόσεις. Παρακάτω παραθέτουμε έναν πίνακα με τα αποτελέσματα της αξιολόγησης μέσω CV των πέντε αυτών ταξινομητών."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978146cf",
   "metadata": {},
   "source": [
    "| | Gaussian NB | kNN | Log. Reg. | MLP | SVC |\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| **CV-Score (%)** | 68.52 $\\pm$ 2.91 | 86.34 $\\pm$ 2.55 | 86.64 $\\pm$ 2.90 | 88.42 $\\pm$ 1.70 | 89.37 $\\pm$ 1.70 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128535b9",
   "metadata": {},
   "source": [
    "### Μείωση Διαστατικότητας\n",
    "\n",
    "Θα ξεκινήσουμε τη διερεύνηση του κατά πόσο η προεπεξεργασία κρίνεται απαραίτητη σε ό,τι αφορά τη μείωση της διαστατικότητας του προβλήματος. Παρατηρούμε ξανά πως κάθε δεδομένο περιλαμβάνει 294 χαρακτηριστικά, έναν αριθμό σχετικά υψηλό σε σχέση με το συνολικό πλήθος των δεδομένων. Η εφαρμογή της μεθόδου PCA είναι πάντοτε μια καλή επιλογή για τη μείωση της διαστατικότητας του προβλήματος, όμως καλό είναι να επιλέγεται μόνο σε περιπτώσεις όπου η μείωση αυτή καθίσταται απόλυτα απραίτητη, κάτι το οποίο μένει να φανεί αφότου έχουμε μια πρώτη εικόνα από την εκπαίδευση των ταξινομητών. Έτσι, αντί για την PCA, θα πραγματοποιήσουμε αρχικά έναν έλεγχο στα δεδομένα εκπαίδευσης, προκειμένου να δούμε εάν υπάρχουν χαρακτηριστικά πολύ χαμηλής διακύμανσης, τα οποία λόγω αυτού δεν ενισχύουν σημαντικά τη διακριτική ικανότητα του εκάστοτε ταξινομητή. Ο έλεγχος αυτός θα γίνει μέσω της μεθόδου `VarianceThreshold` της `sklearn`, η οποία έχει ως default κατώφλι το μηδέν, δηλαδή πετάει στήλες που αντιστοιχούν σε χαρακτηριστικά μηδενικής διακύμανσης."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0072197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum feature variance is 0.005, while the maximum feature variance is 0.066.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The minimum feature variance is {X_train_unmod.var(axis=0).min():.3f}, while the maximum feature variance is {X_train_unmod.var(axis=0).max():.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edc67e8",
   "metadata": {},
   "source": [
    "Μιας και στο σύνολο δεδομένων δεν υπάρχουν χαρακτηριστικά με μηδενική διακύμανση, η εφαρμογή της `VarianceThreshold` με το default κατώφλι της δε θα επιφέρει κάποιο αποτέλεσμα. Θα εξετάσουμε, επομένως, τι θα συμβεί εάν αφαιρέσουμε από το σύνολο τα χαρακτηριστικά με διακύμανση μικρότερη από μια μη μηδενική τιμή."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0674ba5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selector has dropped 23 feature(s).\n"
     ]
    }
   ],
   "source": [
    "# import the method\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# setup the selector\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "X_train_reduced = selector.fit_transform(X_train_unmod)\n",
    "mask = selector.get_support()\n",
    "\n",
    "print(f\"The selector has dropped {(mask==False).sum()} feature(s).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7828d64f",
   "metadata": {},
   "source": [
    "Παρατηρούμε πως υπάρχουν 19 χαρακτηριστικά με μέση διακύμανση μικρότερη του 0.01, τα οποία απορρίπτονται από το σύνολο δεδομένων. Εάν επαναλάβουμε τη διαδικασία CV, παίρνουμε τα ακόλουθα:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f80f7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by GaussianNB is 69.59% with a standard deviation of 2.51%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by KNeighborsClassifier is 85.98% with a standard deviation of 2.59%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by LogisticRegression is 86.70% with a standard deviation of 2.62%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by MLPClassifier is 88.06% with a standard deviation of 2.27%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by SVC is 89.31% with a standard deviation of 1.63%.\n"
     ]
    }
   ],
   "source": [
    "InitCrossVal(X_train_reduced,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983fb695",
   "metadata": {},
   "source": [
    "Βλέπουμε πως η αφαίρεση χαρακτηριστικών δεν επηρεάζει σημαντικά την επίδοση των περισσότερων ταξινομητών. Σε κάθε περίπτωση, στην τελική βελτιστοποίηση το κατώφλι της `VarianceThreshold` μπορεί να αναπροσαρμοστεί και να ελεγχθεί ποια τιμή του οδηγεί στα βέλτιστα αποτελέσματα. Παραθέτουμε παρακάτω τον προηγούμενο πίνακα, όπου έχουν προστεθεί τα αποτελέσματα κατόπιν εφαρμογής της διαστατικής μείωσης. Με πράσινο ή κόκκινο χρώμα έχουν σημειωθεί τα νέα αποτελέσματα για τους ταξινομητές των οποίων η επίδοση αυξήθηκε ή μειώθηκε, αντίστοιχα, σε σχέση με την αρχική τους αξιολόγηση."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd3468a",
   "metadata": {},
   "source": [
    "| | Gaussian NB | kNN | Log. Reg. | MLP | SVC |\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| **CV-Score - initial (%)** | 68.52 $\\pm$ 2.91 | 86.34 $\\pm$ 2.55 | 86.64 $\\pm$ 2.90 | 88.42 $\\pm$ 1.70 | 89.37 $\\pm$ 1.70 |\n",
    "| **CV-Score - after reduction (%)** | <font color='green'>69.59</font> $\\pm$ 2.51 | <font color='red'>85.98</font> $\\pm$ 2.59 | <font color='green'>86.70</font> $\\pm$ 2.62 | <font color='red'>87.83</font> $\\pm$ 1.49 | <font color='red'>89.31</font> $\\pm$ 1.63 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2674c8",
   "metadata": {},
   "source": [
    "### Κανονικοποίηση\n",
    "\n",
    "Ένα επόμενο λογικό βήμα αποτελεί η κανονικοποίηση των δεδομένων, μια διαδικασία απαραίτητη σε πολλούς ταξινομητές. Για το σκοπό αυτό, θα αξιοποιηθούν οι `StandardScaler` και `MinMaxScaler` της `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e6f1b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating CV procedure for StandardScaler():\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by GaussianNB is 68.52% with a standard deviation of 2.91%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by KNeighborsClassifier is 85.98% with a standard deviation of 3.09%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by LogisticRegression is 85.21% with a standard deviation of 2.79%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by MLPClassifier is 89.01% with a standard deviation of 1.54%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by SVC is 90.38% with a standard deviation of 1.85%.\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "Initiating CV procedure for MinMaxScaler():\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by GaussianNB is 68.52% with a standard deviation of 2.91%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by KNeighborsClassifier is 86.16% with a standard deviation of 2.43%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by LogisticRegression is 86.64% with a standard deviation of 2.90%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by MLPClassifier is 88.24% with a standard deviation of 1.92%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by SVC is 89.37% with a standard deviation of 1.80%.\n"
     ]
    }
   ],
   "source": [
    "# both scalers are included here\n",
    "from sklearn import preprocessing\n",
    "\n",
    "std_scaler = preprocessing.StandardScaler().fit(X_train_unmod)\n",
    "minmax_scaler = preprocessing.MinMaxScaler().fit(X_train_unmod)\n",
    "\n",
    "X_train_std = std_scaler.transform(X_train_unmod)\n",
    "X_train_minmax = minmax_scaler.transform(X_train_unmod)\n",
    "\n",
    "print(\"Initiating CV procedure for StandardScaler():\")\n",
    "InitCrossVal(X_train_std,y_train)\n",
    "print(\"\\n\"+101*\"*\"+\"\\n\")\n",
    "print(\"Initiating CV procedure for MinMaxScaler():\")\n",
    "InitCrossVal(X_train_minmax,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be611b",
   "metadata": {},
   "source": [
    "Σε ό,τι αφορά τον `MinMaxScaler`, παρατηρούμε πως στους μόνους ταξινομητές όπου σημειώνεται διαφορά στην επίδοση, αυτή είναι προς το χειρότερο. Από την άλλη, ο `StandardScaler` οδηγεί σε βελτιώσεις σε δύο από τους τέσσερεις ταξινομητές, η οποία όμως δεν είναι υψηλή (είναι της τάξης του 1%). Βάσει αυτών των αποτελεσμάτων, συμπεραίνουμε πως η χρήση του `StandardScaler` ενδείκνυται, όμως όχι στην περίπτωση της λογιστικής παλινδρόμησης και του kNN. Παραθέτουμε, ξανά, τον πίνακα που απεικονίζει τα αρχικά CV-scores, καθώς και τα αντίστοιχα κατόπιν κάθε είδους κανονικοποίησης."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf43e9",
   "metadata": {},
   "source": [
    "| | Gaussian NB | kNN | Log. Reg. | MLP | SVC |\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| **CV-Score - initial (%)** | 68.52 $\\pm$ 2.91 | 86.34 $\\pm$ 2.55 | 86.64 $\\pm$ 2.90 | 88.42 $\\pm$ 1.70 | 89.37 $\\pm$ 1.70 |\n",
    "| **CV-Score - StandardScaler (%)** | 68.52 $\\pm$ 2.91 | <font color='red'>85.98</font> $\\pm$ 3.09 | <font color='red'>85.21</font> $\\pm$ 2.79 | <font color='green'>89.07</font> $\\pm$ 1.35 | <font color='green'>90.38</font> $\\pm$ 1.85 |\n",
    "| **CV-Score - MinMaxScaler (%)** | 68.52 $\\pm$ 2.91 | <font color='red'>86.16</font> $\\pm$ 2.43 | 86.64 $\\pm$ 2.90 | <font color='red'>88.24</font> $\\pm$ 1.70 | 89.37 $\\pm$ 1.80 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81e0d1f",
   "metadata": {},
   "source": [
    "### Εξισορρόπηση\n",
    "\n",
    "Το τελευταίο σημαντικό βήμα της προεπεξεργασίας των δεδομένων είναι η αντιμετώπιση του προβλήματος εξισορρόπησης του συνόλου δεδομένων, το οποίο εμφανίζει σημαντική ανομοιογένεια ως προς τα δεδομένα που ανήκουν στη δείκτρια κατηγορία σε σχέση με αυτά που δεν ανήκουν. Μάλιστα, τα αντίστοιχα ποσοστά αναμένεται να είναι αυτά που υπολογίστηκαν στην προηγούμενη ενότητα, αφού ο διαχωρισμός των δεδομένων σε δεδομένα εκπαίδευσης και δεδομένα αξιολόγησης έγινε μέσω stratified split. Πράγματι:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dc67783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The relative frequency of 'Urban' data is 17.9%, which means that the relative frequency of non-'Urban' data is 82.1%.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The relative frequency of 'Urban' data is {100*((y_train==1).sum()/len(y_train)):.1f}%, which means that the relative frequency of non-'Urban' data is {100*(1-((y_train==1).sum()/len(y_train))):.1f}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c61d7fd",
   "metadata": {},
   "source": [
    "Υπάρχουν δύο τρόποι για την εξισορρόπηση ενός συνόλου δεδομένων: οι μέθοδοι under- και over-sampling, όπου για την εκπαίδευση ενός ταξινομητή αξιοποιούνται λιγότερα δεδομένα που ανήκουν στην πολυπληθέστερη κατηγορία ή περισσότερα δεδομένα της κατηγορίας με τη μικρότερη συχνότητα εμφάνισης, αντίστοιχα. Κατά σύμβαση, ένα σύνολο δεδομένων που αντιστοιχεί σε πρόβλημα δυαδικής ταξινόμησης θεωρείται ισορροπημένο όταν η αναλογία των δεδομένων που ανήκουν στη δείκτρια κατηγορία σε σχέση με τα δεδομένα που δεν ανήκουν σ' αυτήν δεν έχει εύρος μεγαλύτερο του 20\\% (δηλαδή τα δεδομένα είναι το πολύ 60%-40%). Φυσικά, καθεμιά έχει τα μειονεκτήματά της, με το undersampling να πετάει δεδομένα από το σύνολο δεδομένων, τη στιγμή που θα έπρεπε όλα να αξιοποιούνται στο μέγιστο και το undersampling να δημιουργεί ψεύτικα δεδομένα ή να επαναλαμβάνει ήδη υπάρχοντα.\n",
    "\n",
    "Η βιβλιοθήκη `imblearn` προσφέρει διάφορες επιλογές under- και over-sampling, παρ' όλα αυτά για αρχή θα χρησιμοποιήσουμε μονάχα τους αντίστοιχους random samplers. Για την εξισορρόπηση του συνόλου δεδομένων εκπαίδευσης θα αξιοποιηθούν οι `RandomUnderSampler` και `RandomOverSampler`.\n",
    "\n",
    "Αρχικά, θα επιχειρηθεί η εξισορρόπηση του συνόλου χρησιμοποιώντας μονάχα την `RandomUnderSampler` και κατόπιν θα επιχειρηθεί το ίδιο χρησιμοποιώντας μονάχα την `RandomOverSampler`. Τέλος, θα δοκιμάσουμε έναν συνδυασμό τους, ώστε να μη δίνεται έμφαση μόνο στο under- ή μόνο στο over-sampling, ελπίζοντας για ένα πιο ισορροπημένο αποτέλεσμα. Συγκεκριμένα, κάθε μέθοδος θα κληθεί με τρόπο τέτοιο, ώστε να προσθέτει ή να αφαιρεί τον ίδιο αριθμό δεδομένων στο σύνολο, προκειμένου η τελική αναλογία να φτάσει στο 50%-50%. Το σύνολο $x$ των δεδομένων που πρέπει να προστεθούν και να αφαιρεθούν προκύπτει απλώς ως η λύση της εξίσωσης\n",
    "\n",
    "$$ \\frac{N_U+x}{N_{NU}-x} = 1, $$\n",
    "\n",
    "όπου $N_U$ και $N_{NU}$ είναι το αρχικό πλήθος των δεδομένων Urban και non-Urban, αντίστοιχα. Η λύση ισούται φυσικά με\n",
    "\n",
    "$$ x = \\frac{N_{NU} - N_{U}}{2}. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97b03585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a sanity check:\n",
      "Strictly OS: The new relative frequencies are 50.00% for urban data and 50.00% for non-urban data.\n",
      "Strictly US: The new relative frequencies are 50.00% for urban data and 50.00% for non-urban data.\n",
      "Mixed method: The new relative frequencies are 50.00% for urban data and 50.00% for non-urban data.\n"
     ]
    }
   ],
   "source": [
    "# import the oversampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# import the undersampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Strictly over sampling\n",
    "ros = RandomOverSampler(random_state=24)\n",
    "X_train_OS, y_train_OS = ros.fit_resample(X_train_unmod,y_train)\n",
    "\n",
    "# Strictly under sampling\n",
    "rus = RandomUnderSampler(random_state=24)\n",
    "X_train_US, y_train_US = rus.fit_resample(X_train_unmod,y_train)\n",
    "\n",
    "# Mixed method\n",
    "num_urban = (y_train==1).sum() # N_U\n",
    "num_non_urban = (y_train==0).sum() #N_NU\n",
    "\n",
    "n_samp = 0.5*(num_non_urban - num_urban) # equal to x\n",
    "\n",
    "# Begin by oversampling the minority\n",
    "ros = RandomOverSampler(sampling_strategy=(num_urban+n_samp)/(num_non_urban),random_state=24)\n",
    "X_train_MIX, y_train_MIX = ros.fit_resample(X_train_unmod,y_train)\n",
    "\n",
    "# Finish by undersampling the majority\n",
    "rus = RandomUnderSampler(sampling_strategy=(num_urban+n_samp)/(num_non_urban-n_samp),random_state=24)\n",
    "X_train_MIX, y_train_MIX = rus.fit_resample(X_train_MIX,y_train_MIX)\n",
    "\n",
    "print(f\"As a sanity check:\")\n",
    "print(f\"Strictly OS: The new relative frequencies are {100*((y_train_OS==1).sum()/len(y_train_OS)):.2f}% for urban data and {100*((y_train_OS==0).sum()/len(y_train_OS)):.2f}% for non-urban data.\")\n",
    "print(f\"Strictly US: The new relative frequencies are {100*((y_train_US==1).sum()/len(y_train_US)):.2f}% for urban data and {100*((y_train_US==0).sum()/len(y_train_US)):.2f}% for non-urban data.\")\n",
    "print(f\"Mixed method: The new relative frequencies are {100*((y_train_MIX==1).sum()/len(y_train_MIX)):.2f}% for urban data and {100*((y_train_MIX==0).sum()/len(y_train_MIX)):.2f}% for non-urban data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5cd4dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating CV procedure for Strictly OS:\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by GaussianNB is 76.66% with a standard deviation of 1.92%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by KNeighborsClassifier is 84.33% with a standard deviation of 1.16%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by LogisticRegression is 87.84% with a standard deviation of 1.47%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by MLPClassifier is 95.91% with a standard deviation of 1.09%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by SVC is 91.25% with a standard deviation of 1.56%.\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "Initiating CV procedure for Strictly US:\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by GaussianNB is 76.16% with a standard deviation of 4.09%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by KNeighborsClassifier is 77.15% with a standard deviation of 4.26%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by LogisticRegression is 80.63% with a standard deviation of 4.16%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by MLPClassifier is 78.81% with a standard deviation of 4.26%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by SVC is 82.78% with a standard deviation of 4.34%.\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "Initiating CV procedure for Mixed method:\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by GaussianNB is 76.37% with a standard deviation of 2.85%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by KNeighborsClassifier is 81.35% with a standard deviation of 2.87%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by LogisticRegression is 86.17% with a standard deviation of 3.76%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by MLPClassifier is 91.87% with a standard deviation of 2.23%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by SVC is 89.31% with a standard deviation of 2.73%.\n"
     ]
    }
   ],
   "source": [
    "print(\"Initiating CV procedure for Strictly OS:\")\n",
    "InitCrossVal(X_train_OS,y_train_OS)\n",
    "print(\"\\n\"+101*\"*\"+\"\\n\")\n",
    "print(\"Initiating CV procedure for Strictly US:\")\n",
    "InitCrossVal(X_train_US,y_train_US)\n",
    "print(\"\\n\"+101*\"*\"+\"\\n\")\n",
    "print(\"Initiating CV procedure for Mixed method:\")\n",
    "InitCrossVal(X_train_MIX,y_train_MIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1179f1f5",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>Γίνεται εμφανές πως η undersampling υπονομεύει σημαντικά την επίδοση όλων των ταξινομητών, με εξαίρεση του Gaussian NB. Παρ' όλα αυτά, ακόμα και για τον Gaussian NB, είναι η μέθοδος που οδηγεί στη μικρότερη σχετική αύξηση της επίδοσής του. Η καλύτερη μέθοδος εξισορρόπησης φαίνεται να είναι η Oversampling, για την οποία παρατηρείται σημαντική βελτίωση σε όλους τους ταξινομητές πλην του kNN, με μικρή μάλιστα τυπική απόκλιση. Η μικτή μέθοδος φαίνεται επίσης να βελτιώνει την επίδοση κάποιων ταξινομητών, όμως η βελτίωση αυτή δεν είναι τόσο υψηλή όσο στην περίπτωση της oversampling και, κυρίως, έρχεται με αρκετά αυξημένες τιμές της τυπικής απόκλισης. Παρακάτω παρατίθεται ο γνωστός πίνακας όπου φαίνονται οι μεταβολές στην επίδοση των ταξινομητών σε σχέση με τις τιμές αναφοράς.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03c8e74",
   "metadata": {},
   "source": [
    "| | Gaussian NB | kNN | Log. Reg. | MLP | SVC |\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| **CV-Score - initial (%)** | 68.52 $\\pm$ 2.91 | 86.34 $\\pm$ 2.55 | 86.64 $\\pm$ 2.90 | 88.42 $\\pm$ 1.70 | 89.37 $\\pm$ 1.70 |\n",
    "| **CV-Score - Oversampling (%)** | <font color='green'>76.66</font> $\\pm$ 1.92 | <font color='red'>84.33</font> $\\pm$ 1.16 | <font color='green'>87.84</font> $\\pm$ 1.47 | <font color='green'>95.73</font> $\\pm$ 1.30 | <font color='green'>91.25</font> $\\pm$ 1.56 |\n",
    "| **CV-Score - Undersampling (%)** | <font color='green'>76.16</font> $\\pm$ 4.09 | <font color='red'>77.15</font> $\\pm$ 4.26 | <font color='red'>80.63</font> $\\pm$ 4.16 | <font color='red'>79.14</font> $\\pm$ 5.07 | <font color='red'>82.78</font> $\\pm$ 4.34 |\n",
    "| **CV-Score - Mixed method (%)** | <font color='green'>76.37</font> $\\pm$ 2.85 | <font color='red'>81.35</font> $\\pm$ 2.87 | <font color='red'>86.17</font> $\\pm$ 3.76 | <font color='green'>91.39</font> $\\pm$ 1.87 | <font color='red'>89.31</font> $\\pm$ 2.73 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2df97c0",
   "metadata": {},
   "source": [
    "Παρότι βρήκαμε το βέλτιστο τρόπο να πραγματοποιήσουμε την εξισορρόπηση του συνόλου δεδομένων μας, ενδέχεται να μην έχουμε βρει το βέλτιστο αλγόριθμο για το oversampling, καθώς παραπάνω χρησιμοποιήθηκε ο `RandomOverSampler`, ενώ η βιβλιοθήκη `imblearn` παρέχει κι άλλους. Αξίζει, λοιπόν, να μελετήσουμε εάν άλλοι oversamplers δίνουν πιο πολλά υποσχόμενα αποτελέσματα. Για το σκοπό αυτό, θα πραγματοποιήσουμε μια αντίστοιχη διαδικασία χρησιμοποιώντας τους `SMOTE`, `ADASYN` και `SVMSMOTE`, οι οποίοι στηρίζονται στη δημιουργία νέων δεδομένων, αντί για επαναλήψεις των ήδη υπαρχόντων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74f793d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating CV procedure for SMOTE:\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by GaussianNB is 79.09% with a standard deviation of 2.87%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by KNeighborsClassifier is 80.24% with a standard deviation of 1.88%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by LogisticRegression is 88.10% with a standard deviation of 1.82%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by MLPClassifier is 95.19% with a standard deviation of 1.50%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by SVC is 92.84% with a standard deviation of 2.21%.\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "Initiating CV procedure for ADESYN:\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by GaussianNB is 75.53% with a standard deviation of 2.55%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by KNeighborsClassifier is 77.36% with a standard deviation of 1.90%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by LogisticRegression is 83.92% with a standard deviation of 2.07%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by MLPClassifier is 95.10% with a standard deviation of 1.54%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by SVC is 90.40% with a standard deviation of 2.03%.\n",
      "\n",
      "*****************************************************************************************************\n",
      "\n",
      "Initiating CV procedure for SVM SMOTE:\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by GaussianNB is 74.53% with a standard deviation of 1.75%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by KNeighborsClassifier is 78.54% with a standard deviation of 1.86%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by LogisticRegression is 86.29% with a standard deviation of 1.65%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by MLPClassifier is 94.61% with a standard deviation of 1.45%.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "The mean CV-score achieved by SVC is 90.63% with a standard deviation of 1.77%.\n"
     ]
    }
   ],
   "source": [
    "# import the oversamplers\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "\n",
    "smt_sampler = SMOTE(random_state=24, n_jobs=-1)\n",
    "X_train_smt, y_train_smt = smt_sampler.fit_resample(X_train_unmod,y_train)\n",
    "\n",
    "ada_sampler = ADASYN(random_state=24, n_jobs=-1)\n",
    "X_train_ada, y_train_ada = ada_sampler.fit_resample(X_train_unmod,y_train)\n",
    "\n",
    "svmsmt_sampler = SVMSMOTE(random_state=24, n_jobs=-1)\n",
    "X_train_svmsmt, y_train_svmsmt = svmsmt_sampler.fit_resample(X_train_unmod,y_train)\n",
    "\n",
    "print(\"Initiating CV procedure for SMOTE:\")\n",
    "InitCrossVal(X_train_smt,y_train_smt)\n",
    "print(\"\\n\"+101*\"*\"+\"\\n\")\n",
    "print(\"Initiating CV procedure for ADESYN:\")\n",
    "InitCrossVal(X_train_ada,y_train_ada)\n",
    "print(\"\\n\"+101*\"*\"+\"\\n\")\n",
    "print(\"Initiating CV procedure for SVM SMOTE:\")\n",
    "InitCrossVal(X_train_svmsmt,y_train_svmsmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113a78c6",
   "metadata": {},
   "source": [
    "Φαίνεται πως ο μοναδικός oversampler ο οποίος δίνει καλύτερα αποτελέσματα από τον `RandomOverSampler` για κάποιους ταξινομητές είναι ο `SMOTE`, ενώ ο ταξινομητής kNN εξακολουθεί να έχει μειωμένη επίδοση λόγω της εξισορρόπησης. Παρακάτω ακολουθεί ο γνωστός πίνακας, μόνο που αυτή τη φορά ο χρωματικός κώδικας διαφέρει. Συγκεκριμένα, με πράσινο έχουν σημειωθεί μόνο οι καλύτερες επιδόσεις συνολικά για κάθε ταξινομητή, λαμβάνοντας φυσικά υπ' όψιν και τις σχετικές τυπικές αποκλίσεις."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1409ff",
   "metadata": {},
   "source": [
    "| | Gaussian NB | kNN | Log. Reg. | MLP | SVC |\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| **CV-Score - initial (%)** | 68.52 $\\pm$ 2.91 | <font color='green'>86.34</font> $\\pm$ 2.55 | 86.64 $\\pm$ 2.90 | 88.42 $\\pm$ 1.70 | 89.37 $\\pm$ 1.70 |\n",
    "| **CV-Score - ROS (%)** | 76.66 $\\pm$ 1.92 | 84.33 $\\pm$ 1.16 | 87.84 $\\pm$ 1.47 | <font color='green'>95.73</font> $\\pm$ 1.30 | 91.25 $\\pm$ 1.56 |\n",
    "| **CV-Score - SMOTE (%)** | <font color='green'>79.09</font> $\\pm$ 2.87 | 80.24 $\\pm$ 1.88 | <font color='green'>88.10</font> $\\pm$ 1.82 | 95.33 $\\pm$ 2.04 | <font color='green'>92.84</font> $\\pm$ 2.21 |\n",
    "| **CV-Score - ADASYN (%)** | 75.53 $\\pm$ 2.55 | 77.36 $\\pm$ 1.90 | 83.92 $\\pm$ 2.07 | 94.96 $\\pm$ 1.22 | 90.40 $\\pm$ 2.03 |\n",
    "| **CV-Score - KMeansSMOTE (%)** | 74.53 $\\pm$ 1.75 | 78.54 $\\pm$ 1.86 | 86.29 $\\pm$ 1.65 | 94.93 $\\pm$ 1.24 | 90.63 $\\pm$ 1.77 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a6655b",
   "metadata": {},
   "source": [
    "Συμπερασματικά, θα έλεγε κανείς πως κατά την προεπεξεργασία των δεδομένων, η εξισορρόπηση για το νευρωνικό δίκτυο φαίνεται να πρέπει να πραγματοποιηθεί στο σύνολο μέσω του `RandomOverSampler`, για τον kNN δεν πρέπει να πραγματοποιηθεί εξισορρόπηση, ενώ για τους υπόλοιπους τρεις ο κατάλληλος εξισορροπητής φαίνεται να είναι ο SMOTE. Πρέπει στο σημείο αυτό να τονίσουμε, όμως, πως η εξισορρόπηση, ειδικά μέσω του `RandomOverSampler`, μπορεί στην πράξη να μην οδηγεί στα αποτελέσματα που φαίνονται στον παραπάνω πίνακα. Ο λόγος είναι πως ο συνδυασμός του oversampling με το cross-validation ως τεχνική αξιολόγησης χρησιμοποιώντας το σύνολο εκπαίδευσης ενδέχεται να αυξάνει σημαντικά το bias, χωρίς στην πράξη να βελτιώνει πραγματικά την επίδοση του ταξινομητή (ίσα ίσα ενδέχεται να τη μειώνει). Έτσι, ενδέχεται στην τελική αξιολόγηση να δούμε επίδοση ακόμη και χειρότερη από την out-of-the-box. Για το λόγο αυτό, η εξισορρόπηση θα αξιοποιηθεί μόνο στην περίπτωση του Gaussian NB και του νευρωνικού δικτύου, όπου το «ρίσκο» φαίνεται να αξίζει, μιας και η βελτίωση που υφίστανται, αν δεν οφείλεται σε υπερπροσαρμογή, είναι αρκετά υψηλή."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2498a4cf",
   "metadata": {},
   "source": [
    "## Out-of-the-box επίδοση\n",
    "\n",
    "Έχοντας ολοκληρώσει τη διερεύνηση της προεπεξεργασίας που είναι κατάλληλη στην περίπτωση κάθε ταξινομητή, προχωρούμε στον υπολογισμό της out-of-the-box επίδοσης στην ταξινόμηση των δεδομένων που φέρουν το δείκτη `unmod`, δηλαδή τα δεδομένα που δεν έχουν υποστεί την προεπεξεργασία. Στους προηγούμενους ταξινομητές προστίθεται τώρα και ο dummy, για τον οποίο οποιαδήποτε προεπεξεργασία δεν αναμένεται να οδηγήσει σε κάποια διαφορά και για αυτό το λόγο είχε έως τώρα αγνοηθεί."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb116766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier # for dummy\n",
    "\n",
    "# import the metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67cfc355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "The accuracy achieved by DummyClassifier is 82.16%.\n",
      "The F1 score achieved by DummyClassifier is 0.00%.\n",
      "------------------------------------------------------------------------\n",
      "The accuracy achieved by GaussianNB is 70.54%.\n",
      "The F1 score achieved by GaussianNB is 51.03%.\n",
      "------------------------------------------------------------------------\n",
      "The accuracy achieved by KNeighborsClassifier is 83.13%.\n",
      "The F1 score achieved by KNeighborsClassifier is 59.60%.\n",
      "------------------------------------------------------------------------\n",
      "The accuracy achieved by LogisticRegression is 88.24%.\n",
      "The F1 score achieved by LogisticRegression is 61.54%.\n",
      "------------------------------------------------------------------------\n",
      "The accuracy achieved by MLPClassifier is 88.38%.\n",
      "The F1 score achieved by MLPClassifier is 62.50%.\n",
      "------------------------------------------------------------------------\n",
      "The accuracy achieved by SVC is 88.93%.\n",
      "The F1 score achieved by SVC is 59.18%.\n"
     ]
    }
   ],
   "source": [
    "CLFs = {0 : DummyClassifier(), 1 : GaussianNB(), 2 : neighbors.KNeighborsClassifier(),\n",
    "        3 : LogisticRegression(), 4 : MLPClassifier(), 5 : SVC()}\n",
    "\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "\n",
    "for i in range(6): # 6 classifiers\n",
    "    clf = CLFs[i]\n",
    "    model = clf.fit(X_train_unmod, y_train)\n",
    "    preds = clf.predict(X_test_unmod)\n",
    "    accuracies.append(accuracy_score(y_test,preds))\n",
    "    f1_scores.append(f1_score(y_test,preds))\n",
    "    print(72*\"-\")\n",
    "    print(f\"The accuracy achieved by {str(CLFs[i]).replace('()','')} is {100*accuracies[i]:.2f}%.\")\n",
    "    print(f\"The F1 score achieved by {str(CLFs[i]).replace('()','')} is {100*f1_scores[i]:.2f}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15230cb",
   "metadata": {},
   "source": [
    "Σε ό,τι αφορά τον ταξινομητή dummy, η επίδοσή του είναι η αναμενόμενη. Δεν πρέπει να ξεχνάμε πως τα δεδομένα έχουν χωριστεί σε δεδομένα εκπαίδευσης και δεδομένα αξιολόγησης μέσω stratified split και αφού ο dummy κατηγοριοποιεί όλα τα δείγματα στην κατηγορία με τα περισσότερα δεδομένα, είναι λογικό η ορθότητά του να είναι 82.16% στο σύνολο αξιολόγησης, αφού αυτό είναι και το ποσοστό των urban-δεδομένων στο σύνολο αυτό. Από την άλλη, έχει ιδιαίτερο ενδιαφέρον το γεγονός πως οι υπόλοιποι ταξινομητές πλην του kNN πετυχαίνουν ακρίβεια (ως προς την ορθότητα) υψηλότερη από αυτή που προέκυψε μέσω CV-scoring στα δεδομένα εκπαίδευσης, χωρίς βέβαια οι αποκλίσεις να είναι πάρα πολύ υψηλές. Παρότι αντίστοιχες επιδόσεις δεν παρατηρούνται ως προς το F1 score, είναι βέβαιο πως η out-of-the-box επίδοση των ταξινομητών είναι αρκετά υψηλή.\n",
    "\n",
    "Στη συνέχεια απεικονίζονται τα παραπάνω αποτελέσματα σε μορφή πίνακα markdown, αλλά και σε μορφή bar plot σύγκρισης."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda305a4",
   "metadata": {},
   "source": [
    "<table>\n",
    "\n",
    "<tr>\n",
    "    <th></th>\n",
    "    <th><center>Dummy</center></th>\n",
    "    <th><center>Gaussian NB</center></th>\n",
    "    <th><center>kNN</center></th>\n",
    "    <th><center>Logistic Regression</center></th>\n",
    "    <th><center>MLP</center></th>\n",
    "    <th><center>SVC</center></th> \n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "    <th><center>Accuracy</center></th>\n",
    "    <td><center>82.16%</center></td>\n",
    "    <td><center>70.54%</center></td>\n",
    "    <td><center>83.13%</center></td>\n",
    "    <td><center>88.24%</center></td>\n",
    "    <td><center>87.41%</center></td>\n",
    "    <td><center>88.93%</center></td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "    <th><center>F1 Score</center></th>\n",
    "    <td><center>0.00%</center></td>\n",
    "    <td><center>51.03%</center></td>\n",
    "    <td><center>59.60%</center></td>\n",
    "    <td><center>61.54%</center></td>\n",
    "    <td><center>66.17%</center></td>\n",
    "    <td><center>59.18%</center></td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86c9ad43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Format the scores properly\n",
    "scores = accuracies.copy()\n",
    "scores.extend(f1_scores)\n",
    "scores = np.around(100*np.asarray(scores), 2)\n",
    "\n",
    "# Create data to be inserted into a dataframe for the barplot\n",
    "data = {'Score Type': ['Accuracy','Accuracy','Accuracy','Accuracy','Accuracy','Accuracy',\n",
    "                       'F1 Score','F1 Score','F1 Score','F1 Score','F1 Score','F1 Score'],\n",
    "        'Classifier': ['Dummy', 'Gaussian NB', 'kNN', 'Log. Reg.', 'MLP', 'SVC',\n",
    "                      'Dummy', 'Gaussian NB', 'kNN', 'Log. Reg.', 'MLP', 'SVC'],\n",
    "        'Score (%)': scores}\n",
    "\n",
    "bardf = pd.DataFrame(data)\n",
    "\n",
    "palette = {'Accuracy': mycol, 'F1 Score': mycomplcol}\n",
    "\n",
    "fig = plt.figure(figsize=[8,5])\n",
    "sns.barplot(x=\"Classifier\", y=\"Score (%)\", hue=\"Score Type\", palette=palette, data=bardf)\n",
    "plt.title(\"Out-of-the-box scores for 6 classifiers.\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e201d7",
   "metadata": {},
   "source": [
    "## Βελτιστοποίηση της διαδικασίας\n",
    "\n",
    "Έχοντας πλέον μια εικόνα ως προς την απαραίτητη προεπεξεργασία, καθώς και ως προς τους ταξινομητές που θα αξιοποιηθούν, προχωράμε στην εύρεση των βέλτιστων υπερπαραμέτρων κάθε βήματος. Η βελτιστοποίηση θα πραγματοποιείται σε κάθε περίπτωση μέσω αναζήτησης πλέγματος με δεκαπλή διασταυρούμενη επικύρωση, όπου φυσικά σε κάθε βήμα οι υπερπαράμετροι θα αφορούν την εκάστοτε μέθοδο.\n",
    "\n",
    "Το πρώτο βήμα αποτελεί η σύσταση ενός pipeline, το οποίο θα αφορά τη διαδικασία προεπεξεργασίας. Αξιοποιώντας τη γνώση που εξήχθη από την προηγούμενη ανάλυση, είμαστε σε θέση να ορίσουμε ένα pipeline εξατομικευμένο για κάθε ταξινομητή, συνδυάζοντας τα διάφορα στάδια προεπεξεργασίας που παρουσιάστηκαν και ρυθμίζοντας πιθανές υπερπαραμέτρους που εμφανίζονται στο στάδιο αυτό.\n",
    "\n",
    "Για παράδειγμα, η ακόλουθη διερεύνηση υποδεικνύει ποιες είναι άλλες τιμές που μπορούμε να δοκιμάσουμε για το κατώφλι της `VarianceThreshold`, η οποία αξιοποιήθηκε για τη διαστατική μείωση του προβλήματος:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f016b032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 30 feature(s) with variance lower than 0.011.\n",
      "There are a total of 49 feature(s) with variance lower than 0.017.\n",
      "There are a total of 65 feature(s) with variance lower than 0.023.\n",
      "There are a total of 96 feature(s) with variance lower than 0.029.\n",
      "There are a total of 149 feature(s) with variance lower than 0.036.\n",
      "There are a total of 205 feature(s) with variance lower than 0.042.\n",
      "There are a total of 246 feature(s) with variance lower than 0.048.\n",
      "There are a total of 270 feature(s) with variance lower than 0.054.\n",
      "There are a total of 281 feature(s) with variance lower than 0.060.\n",
      "There are a total of 293 feature(s) with variance lower than 0.066.\n"
     ]
    }
   ],
   "source": [
    "minvar = X_train_unmod.var(axis=0).min()\n",
    "maxvar = X_train_unmod.var(axis=0).max()\n",
    "\n",
    "varrange = maxvar - minvar\n",
    "for i in range(10):\n",
    "    varcheck = minvar + varrange*(i+1)/10\n",
    "    print(f\"There are a total of {(X_train_unmod.var(axis=0) < varcheck).sum()} feature(s) with variance lower than {varcheck:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed2a229",
   "metadata": {},
   "source": [
    "Τα παραπάνω υποδεικνύουν πως κάποιες καλές υποψήφιες τιμές για το κατώφλι είναι οι 0.011, 0.017, 0.023 και 0.029, καθώς δε θα θέλαμε να αφαιρέσουμε περισσότερα από τα μισά χαρακτηριστικά, όπως συμβαίνει από την τιμή 0.036 και πάνω."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21121fe6",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes\n",
    "\n",
    "Η διαδικασία βελτιστοποίησης θα ξεκινήσει με τον Gaussian Naive Bayes ταξινομητή, για τον οποίο είδαμε πως η κανονικοποίηση των δεδομένων δεν επιφέρει αλλαγές στην επίδοση, επομένως δε θα εφαρμοστεί. Ως προς την εξισορρόπησή του, φάνηκε ο `SMOTE` oversampler να οδηγεί στη βέλτιστη επίδοση. Σε ό,τι αφορά υπερπαραμέτρους του ίδιου του ταξινομητή, η μόνη υπερπαράμετρός του που μπορεί να προσαρμοστεί είναι η `var_smoothing`, η οποία αφορά τις διακυμάνσεις των δεδομένων και φροντίζει να αποφεύγονται διαιρέσεις με τυπικά μηδενικές τιμές. Με βάση αυτά, γράφουμε:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fde96f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the pipeline method\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# import the new oversampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "selector = VarianceThreshold()\n",
    "# no scaler required\n",
    "sampler = SMOTE(random_state=24, n_jobs=-1)\n",
    "    \n",
    "clf = GaussianNB()\n",
    "\n",
    "# pipeline for Gaussian NB\n",
    "pipe = Pipeline(steps=[('selector', selector), ('sampler', sampler), ('clf', clf)], memory = 'tmp')\n",
    "    \n",
    "# import the grid search method\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# to time the training and testing process\n",
    "import time\n",
    "\n",
    "# We define a custom function to print diagnostics\n",
    "# during the training and testing of the estimators.\n",
    "def EstDiagnostics(estimator,name,scoring):\n",
    "    \n",
    "    print(f\"Initializing grid search for {name} - set to {scoring} scoring.\")\n",
    "    start_time = time.time()\n",
    "    estimator.fit(X_train_unmod, y_train)\n",
    "    stop_time = time.time()\n",
    "    print(\"Grid search finished.\")\n",
    "    print(f\"Total time elapsed for the training: {(stop_time - start_time):.2f} s.\")\n",
    "    print(\"Below you can see the best parameters found for this estimator.\")\n",
    "    print(estimator.best_params_)\n",
    "    start_time = time.time()\n",
    "    preds = estimator.predict(X_test_unmod)\n",
    "    stop_time = time.time()\n",
    "    print(110*\"-\")\n",
    "    print(f\"The accuracy on the test set is {100*accuracy_score(y_test,preds):.2f}%.\")\n",
    "    print(f\"The F1 score on the test set is {100*f1_score(y_test,preds):.2f}%.\")\n",
    "    print(110*\"-\")\n",
    "    print(f\"Total time elapsed for the testing: {(stop_time - start_time):.2f} s.\")\n",
    "    \n",
    "    return estimator\n",
    "    \n",
    "# Hyperparameters for Gaussian NB\n",
    "smooths = [1e-11, 1e-10, 1e-9, 1e-8]\n",
    "vthreshold = [0.0, 0.011, 0.017, 0.023, 0.029]\n",
    "smote_nbs = [4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d324c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing grid search for Gaussian NB Classifier - set to accuracy scoring.\n",
      "Grid search finished.\n",
      "Total time elapsed for the training: 5.85 s.\n",
      "Below you can see the best parameters found for this estimator.\n",
      "{'clf__var_smoothing': 1e-11, 'sampler__k_neighbors': 9, 'selector__threshold': 0.029}\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "The accuracy on the test set is 75.38%.\n",
      "The F1 score on the test set is 50.83%.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Total time elapsed for the testing: 0.00 s.\n",
      "Initializing grid search for Gaussian NB Classifier - set to F1 scoring.\n",
      "Grid search finished.\n",
      "Total time elapsed for the training: 3.71 s.\n",
      "Below you can see the best parameters found for this estimator.\n",
      "{'clf__var_smoothing': 1e-11, 'sampler__k_neighbors': 7, 'selector__threshold': 0.029}\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "The accuracy on the test set is 75.38%.\n",
      "The F1 score on the test set is 52.15%.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Total time elapsed for the testing: 0.00 s.\n"
     ]
    }
   ],
   "source": [
    "# Grid Search with respect to accuracy score\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, sampler__k_neighbors=smote_nbs, clf__var_smoothing=smooths),\n",
    "                         cv=10, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "gnb_acc = EstDiagnostics(estimator,'Gaussian NB Classifier','accuracy')\n",
    "\n",
    "# Grid Search with respect to f1 score\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, sampler__k_neighbors=smote_nbs, clf__var_smoothing=smooths),\n",
    "                         cv=10, scoring='f1', n_jobs=-1)\n",
    "\n",
    "gnb_f1 = EstDiagnostics(estimator,'Gaussian NB Classifier','F1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba86513",
   "metadata": {},
   "source": [
    "Φαίνεται η βελτιστοποίηση ως προς την ορθότητα να δίνει ίδια ορθότητα στο σύνολο αξιολόγησης σε σχέση με τη βελτιστοποίηση ως προς το F1 Score, όμως ελαφρώς μειωμένο F1 Score (~1.5%), επομένως θεωρούμε πως ο βέλτιστος ταξινομητής Gausian Naive Bayes είναι αυτός με `var_smoothing` = $10^{-11}$, `k_neighbors` = 7 για τον `SMOTE` και `threshold` = 0.029 για την `VarianceThreshold`. Την ίδια διαδικασία καλούμαστε να ακολουθήσουμε και για τους υπόλοιπους ταξινομητές."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b18dd458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of a dict of estimators\n",
    "Estimators = {}\n",
    "\n",
    "# Add the dummy\n",
    "Estimators[0] = DummyClassifier().fit(X_train_unmod,y_train)\n",
    "\n",
    "# Add the optimized estimator in a dict\n",
    "Estimators[1] = gnb_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55d2bdc",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors\n",
    "\n",
    "Συνεχίζοντας με τον kNN, η υπερπαράμετρος που θα ληφθεί υπ' όψιν θα είναι φυσικά το πλήθος πλησιέστερων γειτόνων. Σε ό,τι αφορά το pipeline προεπεξεργασίας, η λογική για την `VarianceThreshold` είναι ίδια με πριν. Πέρα από αυτό, με βάση την προηγούμενη ανάλυση, δεν πραγματοποιείται ούτε scaling ούτε oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c45b5f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing grid search for kNN Classifier - set to accuracy scoring.\n",
      "Grid search finished.\n",
      "Total time elapsed for the training: 11.09 s.\n",
      "Below you can see the best parameters found for this estimator.\n",
      "{'clf__n_neighbors': 8, 'selector__threshold': 0.023}\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "The accuracy on the test set is 85.48%.\n",
      "The F1 score on the test set is 61.82%.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Total time elapsed for the testing: 0.05 s.\n",
      "Initializing grid search for kNN Classifier - set to F1 scoring.\n",
      "Grid search finished.\n",
      "Total time elapsed for the training: 10.87 s.\n",
      "Below you can see the best parameters found for this estimator.\n",
      "{'clf__n_neighbors': 8, 'selector__threshold': 0.023}\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "The accuracy on the test set is 85.48%.\n",
      "The F1 score on the test set is 61.82%.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Total time elapsed for the testing: 0.06 s.\n"
     ]
    }
   ],
   "source": [
    "selector = VarianceThreshold()\n",
    "# no scaler required\n",
    "# no sampler required\n",
    "    \n",
    "clf = neighbors.KNeighborsClassifier(n_jobs=-1)\n",
    "\n",
    "# pipeline for kNN\n",
    "pipe = Pipeline(steps=[('selector', selector), ('clf', clf)], memory = 'tmp')\n",
    "\n",
    "# Hyperparameters for kNN\n",
    "neighbs = np.linspace(3,14).astype('int')\n",
    "vthreshold = [0.0, 0.011, 0.017, 0.023, 0.029]\n",
    "\n",
    "# Grid Search with respect to accuracy score\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, clf__n_neighbors=neighbs),\n",
    "                         cv=10, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "knn_acc = EstDiagnostics(estimator,'kNN Classifier','accuracy')\n",
    "\n",
    "# Grid Search with respect to f1 score\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, clf__n_neighbors=neighbs),\n",
    "                         cv=10, scoring='f1', n_jobs=-1)\n",
    "\n",
    "knn_f1 = EstDiagnostics(estimator,'kNN Classifier','F1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e75ce5",
   "metadata": {},
   "source": [
    "Σε ό,τι αφορά τα αποτελέσματα για τον kNN, ο οποίος επίσης σημειώνει βελτίωση, αν και όχι σημαντικά υψηλή, σε σχέση με την out-of-the-box επίδοσή του, φαίνεται η βελτιστοποίηση ως προς το F1 Score να δίνει τα ίδια αποτελέσματα με τη βελτιστοποίηση ως προς την ορθότητα και συγκεκριμένα πλήθος 8 γειτόνων και κατώφλι για την `VarianceThreshold` ίσο με 0.023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8493d970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the kNN Classifier to the dict of optimized estimators\n",
    "Estimators[2] = knn_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91b77c9",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Προχωρώντας στον ταξινομητή λογιστικής παλινδρόμησης, υπενθυμίζουμε πως η κανονικοποίηση μειώνει την απόδοσή του, ενώ η εξισορρόπηση φαίνεται να βελτιώνει την απόδοσή του, αλλά κατά λιγότερο από 2% στο σύνολο εκπαίδευσης. Το γεγονός αυτό υποδεικνύει πως η τεχνητή εξισορρόπηση του συνόλου εκπαίδευσης ενέχει υψηλό κίνδυνο να δημιουργήσει ένα bias το οποίο θα μειώσει την τελική επίδοση του ταξινομητή, όταν αυτός αξιολογηθεί στο σύνολο αξιολόγησης. Με λίγα λόγια, επιλέγουμε να μη ρισκάρουμε μια βελτίωση η οποία ενδέχεται να δημιουργείται λόγω υπερπροσαρμογής, τη στιγμή που το κέρδος σε απόδοση είναι μικρό. Ως προς τις υπερπαραμέτρους του ίδιου του ταξινομητή, αυτές που θα ληφθούν υπ' όψιν είναι ο αλγόριθμος που θα πραγματοποιήσει τη βελτιστοποίηση, καθώς και το αντίστροφο του παράγοντα ομαλοποίησης. Έχουμε, επομένως:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97bc971a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing grid search for Logistic Regression Classifier - set to accuracy scoring.\n",
      "Grid search finished.\n",
      "Total time elapsed for the training: 59.44 s.\n",
      "Below you can see the best parameters found for this estimator.\n",
      "{'clf__C': 1.0, 'clf__solver': 'saga', 'selector__threshold': 0.0}\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "The accuracy on the test set is 88.38%.\n",
      "The F1 score on the test set is 62.16%.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Total time elapsed for the testing: 0.00 s.\n",
      "Initializing grid search for Logistic Regression Classifier - set to F1 scoring.\n",
      "Grid search finished.\n",
      "Total time elapsed for the training: 59.58 s.\n",
      "Below you can see the best parameters found for this estimator.\n",
      "{'clf__C': 1.0, 'clf__solver': 'saga', 'selector__threshold': 0.0}\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "The accuracy on the test set is 88.38%.\n",
      "The F1 score on the test set is 62.16%.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Total time elapsed for the testing: 0.00 s.\n"
     ]
    }
   ],
   "source": [
    "selector = VarianceThreshold()\n",
    "# no scaler required\n",
    "# no sampler will be used\n",
    "    \n",
    "clf = LogisticRegression(n_jobs=-1)\n",
    "\n",
    "# pipeline for Log. Reg.\n",
    "pipe = Pipeline(steps=[('selector', selector), ('clf', clf)], memory = 'tmp')\n",
    "\n",
    "# Hyperparameters for logistic regression\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "Cs = [1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8]\n",
    "vthreshold = [0.0, 0.011, 0.017, 0.023, 0.029]\n",
    "\n",
    "# Grid Search with respect to accuracy score\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, clf__C=Cs, clf__solver=solvers), cv=10, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "logreg_acc = EstDiagnostics(estimator, 'Logistic Regression Classifier','accuracy')\n",
    "\n",
    "# Grid Search with respect to f1 score\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, clf__C=Cs, clf__solver=solvers), cv=10, scoring='f1', n_jobs=-1)\n",
    "\n",
    "logreg_f1 = EstDiagnostics(estimator, 'Logistic Regression Classifier','F1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb624c7",
   "metadata": {},
   "source": [
    "Οι προκύπτοντες ταξινομητές ταυτίζονται για κάθε τύπου βελτιστοποίηση και, συγκεκριμένα, χρησιμοποιούν ως solver τον saga, με κατώφλι της `VarianceThreshold` ίσο με το μηδέν και την default τιμή για το αντίστροφο του παράγοντα ομαλοποίησης. Συγκρίνοντας με τα out-of-the-box αποτελέσματα, βλέπουμε πως υπάρχει μια βελτίωση, η οποία όμως δεν είναι σε καμία περίπτωση υψηλή. Εγείρεται, επομένως, το ερώτημα, εάν η εξισορρόπηση εν τέλει θα ήταν χρήσιμη στην περίπτωση αυτή. Καθαρά για λόγους διερεύνησης, ας δούμε παρακάτω την αντίστοιχη επίδοση στο σύνολο αξιολόγησης, εφαρμόζοντας τον `SMOTE` για oversampling, ώστε να δούμε εάν η επιλογή μας ήταν ορθή ή όχι."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d601e3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing grid search for Logistic Regression Classifier - set to accuracy scoring.\n",
      "Grid search finished.\n",
      "Total time elapsed for the training: 6.17 s.\n",
      "Below you can see the best parameters found for this estimator.\n",
      "{'sampler__k_neighbors': 10}\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "The accuracy on the test set is 81.74%.\n",
      "The F1 score on the test set is 60.71%.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Total time elapsed for the testing: 0.00 s.\n"
     ]
    }
   ],
   "source": [
    "# Try to introduce oversampling and see if the previous results get better or worse\n",
    "sampler = SMOTE(random_state=24, n_jobs=-1)\n",
    "clf = LogisticRegression(solver='saga', n_jobs=-1)\n",
    "\n",
    "# pipeline for Log. Reg.\n",
    "pipe = Pipeline(steps=[('sampler', sampler), ('clf', clf)], memory = 'tmp')\n",
    "\n",
    "# Hyperparameter for SMOTE\n",
    "smote_nbs = [4,5,6,7,8,9,10]\n",
    "\n",
    "# Grid Search with respect to accuracy score\n",
    "estimator = GridSearchCV(pipe, dict(sampler__k_neighbors=smote_nbs), cv=10, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "logreg_alt = EstDiagnostics(estimator,'Logistic Regression Classifier','accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b7921b",
   "metadata": {},
   "source": [
    "Η επιλογή μας να παραλείψουμε το βήμα εξισορρόπησης φαίνεται a posteriori να ήταν ορθή, καθώς βλέπουμε τη σημαντική μείωση που αυτή θα επέφερε, τόσο ως προς την ορθότητα, όσο και ως προς το F1 Score του ταξινομητή."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3bd3344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Log. Reg. Classifier to the dict of optimized estimators\n",
    "Estimators[3] = logreg_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056d5d52",
   "metadata": {},
   "source": [
    "### Multiple Layer Perceptron (MLP)\n",
    "\n",
    "Ο επόμενος σταθμός είναι το νευρωνικό δίκτυο MLP. Η διερεύνηση ως προς την απαραίτητη προεπεξεργασία υπέδειξε πως η κανονικοποίηση μέσω `StandardScaler` βελτιώνει ελαφρώς την επίδοσή του, ενώ το oversampling φαίνεται να οδηγεί σε τόσο σημαντική βελτίωση που το ρίσκο αυτή να αποτελεί οφθαλμαπάτη αξίζει να ληφθεί, με τον κίνδυνο εν τέλει να οδηγηθούμε σε μείωση της απόδοσης. Η βελτιστοποίησή του θα γίνει σε δύο βήματα: αρχικά, θα διερευνηθούν το βέλτιστο πλήθος layers, η καλύτερη συνάρτηση ενεργοποίησης, καθώς και ο καλύτερος optimizer. Κατόπιν, για δεδομένα αποτελέσματα της πρώτης αναζήτησης πλέγματος, θα διερευνηθούν περαιτέρω άλλες υπερπαράμετροι, οι οποίες εξαρτώνται από την επιλογή συνάρτησης ενεργοποίησης και optimizer. Φυσικά, για το πρώτο βήμα δε θα αξιοποιηθούν τα δεδομένα αξιολόγησης, αλλά η επικύρωση θα γίνει στα δεδομένα εκπαίδευσης."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68f67f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLPDiagnostics(estimator,X,y,scoring):\n",
    "    \n",
    "    print(f\"Initializing grid search for MLP - set to {scoring} scoring.\")\n",
    "    start_time = time.time()\n",
    "    estimator.fit(X_train_unmod, y_train)\n",
    "    stop_time = time.time()\n",
    "    print(\"Grid search finished.\")\n",
    "    print(f\"Total time elapsed for the training: {(stop_time - start_time):.2f} s.\")\n",
    "    print(\"Below you can see the best parameters found for this estimator.\")\n",
    "    print(estimator.best_params_)\n",
    "    start_time = time.time()\n",
    "    preds = estimator.predict(X)\n",
    "    stop_time = time.time()\n",
    "    print(110*\"-\")\n",
    "    print(f\"The accuracy on the train set is {100*accuracy_score(y,preds):.2f}%.\")\n",
    "    print(f\"The F1 score on the train set is {100*f1_score(y,preds):.2f}%.\")\n",
    "    print(110*\"-\")\n",
    "    print(f\"Total time elapsed for the testing: {(stop_time - start_time):.2f} s.\")\n",
    "    \n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fbe17131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing grid search for MLP - set to accuracy scoring.\n",
      "Grid search finished.\n",
      "Total time elapsed for the training: 158.01 s.\n",
      "Below you can see the best parameters found for this estimator.\n",
      "{'clf__activation': 'relu', 'clf__hidden_layer_sizes': (100, 100), 'clf__solver': 'adam'}\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "The accuracy on the train set is 98.99%.\n",
      "The F1 score on the train set is 97.24%.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Total time elapsed for the testing: 0.01 s.\n",
      "Initializing grid search for MLP - set to F1 scoring.\n",
      "Grid search finished.\n",
      "Total time elapsed for the training: 159.42 s.\n",
      "Below you can see the best parameters found for this estimator.\n",
      "{'clf__activation': 'relu', 'clf__hidden_layer_sizes': (100, 100), 'clf__solver': 'adam'}\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "The accuracy on the train set is 98.99%.\n",
      "The F1 score on the train set is 97.24%.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Total time elapsed for the testing: 0.00 s.\n"
     ]
    }
   ],
   "source": [
    "selector = VarianceThreshold()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "sampler = SMOTE(random_state=24, n_jobs=-1)\n",
    "    \n",
    "clf = MLPClassifier(batch_size=32,random_state=24,early_stopping=True,validation_fraction=0.15) # early stopping to avoid overfitting for reasons other than data balancing\n",
    "\n",
    "# pipeline for MLP\n",
    "pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('sampler', sampler), ('clf', clf)], memory = 'tmp')\n",
    "\n",
    "# Hyperparameters for round 1 of MLP optimization\n",
    "activations = ['identity', 'logistic', 'tanh', 'relu']\n",
    "solvers = ['adam', 'lbfgs', 'sgd']\n",
    "hiddens = [(100,),(100,100),(100,100,100),(100,100,100,100)]\n",
    "\n",
    "# Grid Search with respect to accuracy score\n",
    "estimator = GridSearchCV(pipe, dict(clf__hidden_layer_sizes=hiddens, clf__activation=activations, clf__solver=solvers),\n",
    "                         cv=10, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "mlp_ini_acc = MLPDiagnostics(estimator,X_train_unmod,y_train,'accuracy')\n",
    "\n",
    "# Grid Search with respect to f1 score\n",
    "estimator = GridSearchCV(pipe, dict(clf__hidden_layer_sizes=hiddens, clf__activation=activations, clf__solver=solvers),\n",
    "                         cv=10, scoring='f1', n_jobs=-1)\n",
    "\n",
    "mlp_ini_f1 = MLPDiagnostics(estimator,X_train_unmod,y_train,'F1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee9e4cf",
   "metadata": {},
   "source": [
    "Μιας και το σύνολο επικύρωσης για αυτό το πρώτο βήμα αναζήτησης πλέγματος αποτέλεσε ένα κομμάτι του συνόλου εκπαίδευσης, η παράμετρος early stopping εισήχθη προκειμένου να αποφευχθεί η υπερπροσαρμογή του μοντέλου στα δεδομένα. Τα αποτελέσματα που προκύπτουν φαίνονται τόσο εντυπωσιακά, που μας οδηγούν στο συμπέρασμα πως μάλλον η εξισορρόπηση πράγματι οδηγεί σε σημαντική υπερπροσαρμογή, καθώς δεν είναι λογικό η αλλαγή συνάρτησης ενεργοποίησης ή του optimizer να οδηγεί σε βελτίωση 88% -> 99% στην ορθότητα και τόσο υψηλό F1 Score. Για το λόγο αυτό, στο επόμενο βήμα βελτιστοποίησης θα την αφαιρέσουμε από το pipeline.\n",
    "\n",
    "Σε κάθε περίπτωση, φαίνεται ο ιδανικός optimizer να είναι ο adam και η ιδανική συνάρτηση ενεργοποίησης η relu, με το πλήθος των layers να δίνουν βέλτιστα αποτελέσματα στη ρύθμιση (100,100). Έτσι, προχωράμε στην τελική βελτιστοποίηση του μοντέλου, ορίζοντας εκ νέου το παραπάνω pipeline και αυτή τη φορά ρυθμίζοντας τις υπερπαραμέτρους `threshold` του `VarianceThreshold`, καθώς και τις `alpha`, `learning_rate_init` και `beta_1`, του MLP, οι οποίες είναι συμβατές με τον adam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6cebbc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing grid search for MLP - set to accuracy scoring.\n",
      "Grid search finished.\n",
      "Total time elapsed for the training: 242.55 s.\n",
      "Below you can see the best parameters found for this estimator.\n",
      "{'clf__alpha': 0.001, 'clf__beta_1': 0.85, 'clf__learning_rate_init': 0.002, 'selector__threshold': 0.0}\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "The accuracy on the train set is 88.38%.\n",
      "The F1 score on the train set is 69.12%.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Total time elapsed for the testing: 0.00 s.\n",
      "Initializing grid search for MLP - set to F1 scoring.\n",
      "Grid search finished.\n",
      "Total time elapsed for the training: 241.67 s.\n",
      "Below you can see the best parameters found for this estimator.\n",
      "{'clf__alpha': 0.0015, 'clf__beta_1': 0.95, 'clf__learning_rate_init': 0.001, 'selector__threshold': 0.029}\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "The accuracy on the train set is 88.11%.\n",
      "The F1 score on the train set is 61.26%.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Total time elapsed for the testing: 0.00 s.\n"
     ]
    }
   ],
   "source": [
    "selector = VarianceThreshold()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "# no sampler added after all\n",
    "    \n",
    "clf = MLPClassifier(hidden_layer_sizes=(100,100),activation='relu',solver='adam',\n",
    "                    batch_size=32, random_state=24,early_stopping=True,validation_fraction=0.15)\n",
    "\n",
    "# pipeline revisited\n",
    "pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('clf', clf)], memory = 'tmp')\n",
    "\n",
    "# Hyperparameters for round 2 of MLP optimization\n",
    "alphas = [0.0001,0.0005,0.001,0.0015]\n",
    "lrs = [0.001, 0.002, 0.005, 0.01]\n",
    "betas = [0.85, 0.9, 0.92, 0.95]\n",
    "vthreshold = [0.0, 0.011, 0.017, 0.023, 0.029]\n",
    "\n",
    "# Grid Search with respect to accuracy score\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, clf__alpha=alphas, clf__beta_1=betas,\n",
    "                                    clf__learning_rate_init=lrs), cv=10, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "mlp_acc = MLPDiagnostics(estimator,X_test_unmod,y_test,'accuracy')\n",
    "\n",
    "# Grid Search with respect to f1 score\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, clf__alpha=alphas, clf__beta_1=betas,\n",
    "                                    clf__learning_rate_init=lrs), cv=10, scoring='f1', n_jobs=-1)\n",
    "\n",
    "mlp_f1 = MLPDiagnostics(estimator,X_test_unmod,y_test,'F1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967797da",
   "metadata": {},
   "source": [
    "Η βελτιστοποίηση ως προς την ορθότητα δίνει πολύ καλύτερα αποτελέσματα, με τον τελικό εκτιμητή να έχει μηδενικό κατώφλι για την `VarianceThreshold`, ρυθμό εκμάθησης ίσο με 0.002, και παραμέτρους `alpha` και `beta_1` ίσες με 0.001 και 0.85, αντίστοιχα. Κρίνοντας από το τελικό αποτέλεσμα φαίνεται πως η βελτίωση σε σχέση με την out-of-the-box επίδοση δεν υφίσταται ως προς την ορθότητα (τα αποτελέσματα είναι σχεδόν ίσα), αν και σημειώνεται μια άξια αναφοράς βελτίωση σε ό,τι έχει να κάνει με το F1 Score. Εγείρεται, επομένως, ξανά το ερώτημα σχετικά με το εάν η επιλογή μας να αφαιρέσουμε τη διαδικασία εξισορρόπησης από το pipeline ήταν ορθή.\n",
    "\n",
    "Ας δοκιμάσουμε, για του λόγου το αληθές, να δούμε τι θα παίρναμε εάν είχαμε επιλέξει να πραγματοποιήσουμε και εξισορρόπηση των δεδομένων εκπαίδευσης στην περίπτωση του MLP, όπως κάναμε (καθαρά διερευνητικά) και για την περίπτωση της λογιστικής παλινδρόμησης. Για το σκοπό αυτό, δεν θα πραγματοποιήσουμε πλήρη αναζήτηση πλέγματος (αν και αυτό θα ήταν το συνεπέστερο), παρά θα χρησιμοποιήσουμε τα παραπάνω αποτελέσματα για τις παραμέτρους του MLP, προσθέτοντας στο pipeline ξανά μια διαδικασία `SMOTE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7af9c259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing grid search for MLP - set to accuracy scoring.\n",
      "Grid search finished.\n",
      "Total time elapsed for the training: 11.42 s.\n",
      "Below you can see the best parameters found for this estimator.\n",
      "{'sampler__k_neighbors': 4}\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "The accuracy on the train set is 88.80%.\n",
      "The F1 score on the train set is 69.43%.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Total time elapsed for the testing: 0.00 s.\n"
     ]
    }
   ],
   "source": [
    "selector = VarianceThreshold()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "sampler = SMOTE(random_state=24, n_jobs=-1)\n",
    "    \n",
    "clf = MLPClassifier(hidden_layer_sizes=(100,100),activation='relu',solver='adam',\n",
    "                    alpha=0.001, beta_1=0.85, learning_rate_init=0.002, batch_size=32,\n",
    "                    random_state=24,early_stopping=True,validation_fraction=0.15)\n",
    "\n",
    "pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('sampler',sampler), ('clf', clf)], memory = 'tmp')\n",
    "\n",
    "# Grid Search with respect to accuracy score\n",
    "estimator = GridSearchCV(pipe, dict(sampler__k_neighbors=[4,5,6,7,8,9,10]), cv=10, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "mlp_alt = MLPDiagnostics(estimator,X_test_unmod,y_test,'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85e45fe",
   "metadata": {},
   "source": [
    "Εκ του αποτελέσματος, η επιλογή μας φαίνεται μάλλον άνευ σημασίας, αφού η εξισορρόπηση φαίνεται να οδηγεί σε μια ελάχιστη αύξηση της ορθότητας και του F1 Score (της τάξης του 0.5%), αυτό όμως παίρνοντας ως δεδομένη τη ρύθμιση των υπόλοιπων υπερπαραμέτρων (μια εκ νέου αναζήτηση πλέγματος σε όλες τις υπερπαραμέτρους, συμπεριλαμβανομένης αυτής που εισάγεται από τον `SMOTE`, ενδέχεται να οδηγούσε σε χαμηλότερη επίδοση συνολικά)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c0d19e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the MLP to the dict of optimized estimators\n",
    "Estimators[4] = mlp_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2526ddd5",
   "metadata": {},
   "source": [
    "### Support Vector Classifier\n",
    "\n",
    "Ολοκληρώνοντας τη διαδικασία αυτή βελτιστοποίησης, προχωρούμε και στον ταξινομητή διανυσμάτων υποστήριξης, για τον οποίο η προεπεξεργασία μας οδήγησε στο συμπέρασμα πως η κανονικοποίηση μέσω `StandardScaler` έχει νόημα, όμως η εξισορρόπηση μάλλον ενέχει υψηλό ρίσκο υπερπροσαρμογής και άρα μείωση της επίδοσης. Σε ό,τι αφορά την προς ρύθμιση υπερπαράμετρο του ταξινομητή, αυτή είναι φυσικά η συνάρτηση πυρήνα που θα χρησιμοποιηθεί."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45b69c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing grid search for Support Vector Classifier - set to accuracy scoring.\n",
      "Grid search finished.\n",
      "Total time elapsed for the training: 11.33 s.\n",
      "Below you can see the best parameters found for this estimator.\n",
      "{'clf__kernel': 'rbf', 'selector__threshold': 0.017}\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "The accuracy on the test set is 90.04%.\n",
      "The F1 score on the test set is 66.67%.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Total time elapsed for the testing: 0.07 s.\n",
      "Initializing grid search for Support Vector Classifier - set to F1 scoring.\n",
      "Grid search finished.\n",
      "Total time elapsed for the training: 11.30 s.\n",
      "Below you can see the best parameters found for this estimator.\n",
      "{'clf__kernel': 'rbf', 'selector__threshold': 0.017}\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "The accuracy on the test set is 90.04%.\n",
      "The F1 score on the test set is 66.67%.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Total time elapsed for the testing: 0.07 s.\n"
     ]
    }
   ],
   "source": [
    "selector = VarianceThreshold()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "# no sampler\n",
    "    \n",
    "clf = SVC(random_state=24)\n",
    "\n",
    "# pipeline for SVC\n",
    "pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('clf', clf)], memory = 'tmp')\n",
    "\n",
    "# Hyperparameter for SVC\n",
    "kernels=['linear', 'poly', 'rbf', 'sigmoid']\n",
    "vthreshold = [0.0, 0.011, 0.017, 0.023, 0.029]\n",
    "\n",
    "# Grid Search with respect to accuracy score\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, clf__kernel=kernels), cv=10, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "svc_acc = EstDiagnostics(estimator,'Support Vector Classifier','accuracy')\n",
    "\n",
    "# Grid Search with respect to f1 score\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, clf__kernel=kernels), cv=10, scoring='f1', n_jobs=-1)\n",
    "\n",
    "svc_f1 = EstDiagnostics(estimator,'Support Vector Classifier','F1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf34c8cf",
   "metadata": {},
   "source": [
    "Παρατηρούμε πως η βέλτιστη συνάρτηση πυρήνα είναι και η default, δηλαδή η rbf, οπότε η αρκετά υψηλή διαφορά που βλέπουμε στο F1 Score σε σχέση με την out-of-the-box επίδοση οφείλεται στην κανονικοποίηση και τον ορισμό ενός κατωφλίου για τις διακυμάνσεις ίσο με 0.017.\n",
    "\n",
    "Για λόγους πληρότητας, θα διερευνήσουμε και την περίπτωση όπου πραγματοποιούσαμε και εξισορρόπηση του συνόλου:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7169edb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing grid search for Support Vector Classifier - set to accuracy scoring.\n",
      "Grid search finished.\n",
      "Total time elapsed for the training: 222.53 s.\n",
      "Below you can see the best parameters found for this estimator.\n",
      "{'clf__kernel': 'rbf', 'sampler__k_neighbors': 6, 'selector__threshold': 0.0}\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "The accuracy on the test set is 89.07%.\n",
      "The F1 score on the test set is 67.76%.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Total time elapsed for the testing: 0.12 s.\n"
     ]
    }
   ],
   "source": [
    "selector = VarianceThreshold()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "sampler = SMOTE(random_state=24, n_jobs=-1)\n",
    "    \n",
    "clf = SVC(random_state=24)\n",
    "\n",
    "# pipeline for SVC\n",
    "pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('sampler',sampler), ('clf', clf)], memory = 'tmp')\n",
    "#\n",
    "\n",
    "# Hyperparameter for SVC\n",
    "kernels=['linear', 'poly', 'rbf', 'sigmoid']\n",
    "vthreshold = [0.0, 0.011, 0.017, 0.023, 0.029]\n",
    "\n",
    "# Grid Search with respect to accuracy score\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, sampler__k_neighbors=[4,5,6,7,8,9,10],\n",
    "                                   clf__kernel=kernels), cv=10, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "svc_alt = EstDiagnostics(estimator,'Support Vector Classifier','accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e347b14",
   "metadata": {},
   "source": [
    "Ξανά, η ορθότητα φαίνεται να μειώνεται ελαφρώς, αν και η μείωση αυτή εξισορροπείται ίσως από μια αύξηση της τάξης του 1% στο F1 Score. Όπως και στην περίπτωση του MLP, λοιπόν, μπορούμε να συμπεράνουμε πως η επιλογή μας σε ό,τι αφορά την εξισορρόπηση δεν οδήγησε σε σημαντικές διαφορές, σε αντίθεση με όσα είδαμε στην περίπτωση της λογιστικής παλινδρόμησης (όπου η αφαίρεση της εξισορρόπησης από το pipeline οδήγησε σε πολύ καλύτερα αποτελέσματα) ή στην περίπτωση του Gaussian NB (όπου η προσθήκη της εξισορρόπησης στο pipeline οδήγησε σε σημαντική βελτίωση σε σχέση με την out-of-the-box επίδοση)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de6534d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the SVC to the dict of optimized estimators\n",
    "Estimators[5] = svc_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb8979c",
   "metadata": {},
   "source": [
    "## Τελικά συμπεράσματα\n",
    "\n",
    "Έχοντας πλέον ολοκληρώσει τη διαδικασία βελτιστοποίησης και έχοντας αποθηκεύσει τη βελτιστοποιημένη εκδοχή κάθε ταξινομητή στο dictionary Estimators, μπορούμε να συγκεντρώσουμε τα αποτελέσματά τους ως προς την ορθότητα και το F1 Score, όπως αξιολογούνται στο σύνολο αξιολόγησης, σε έναν πίνακα markdown. Πέραν αυτών, συγκεντρώνουμε και τους αντίστοιχους χρόνους εκπαίδευσης (train time) και αξιολόγησης (test time), καθώς και τη μεταβολή της επίδοσής τους σε σχέση με την out-of-the-box επίδοση (update). Σημειώνεται πως στην περίπτωση του MLP, όπου η βελτιστοποίηση έγινε σε δύο βήματα, παρατίθεται στον πίνακα ως χρόνος εκπαίδευσης το άθροισμα των επί μέρους χρόνων εκπαίδευσης κάθε βήματος."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de08b5d",
   "metadata": {},
   "source": [
    "|  |  |   Dummy   | Gaussian NB | kNN | Logistic Regression | MLP | SVC |\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| **Accuracy** | **Score (%)** <br> **Update (%)** | 82.16 <br> 0.00 | 75.38 <br> <font color='green'>+4.84</font> | 85.48 <br> <font color='green'>+2.35</font> | 88.38 <br> <font color='green'>+0.14</font> | 88.38 <br> <font color='green'>+0.97</font> | 90.04 <br> <font color='green'>+1.11</font> |\n",
    "| **F1 Score** | **Score (%)** <br> **Update (%)** | 0.00 <br> 0.00 | 52.15 <br> <font color='green'>+1.12</font> | 61.82 <br> <font color='green'>+2.22</font> | 62.16 <br> <font color='green'>+0.62</font>  | 69.12 <br> <font color='green'>+2.95</font> | 66.67 <br> <font color='green'>+7.49</font> |\n",
    "|  | **Train Time (s)** | - | 3.71 | 10.87 | 59.44 | 400.56 | 11.30 |\n",
    "|  | **Test Time (s)** | - | 0.00 | 0.06 | 0.00 | 0.00 | 0.07 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b6b60d",
   "metadata": {},
   "source": [
    "Τα ίδια αποτελέσματα, πλην των χρόνων εκπαίδευσης, παρουσιάζονται και στο επόμενο bar plot σύγκρισης, κατ' αντιστοιχία με αυτό που κατασκευάστηκε για την out-of-the-box περίπτωση."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9846986",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 792x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gather the scores from each estimator\n",
    "accuracies_upd = []\n",
    "f1_scores_upd = []\n",
    "\n",
    "for i in range(6):\n",
    "    est = Estimators[i]\n",
    "    preds = est.predict(X_test_unmod)\n",
    "    accuracies_upd.append(accuracy_score(y_test,preds))\n",
    "    f1_scores_upd.append(f1_score(y_test,preds))\n",
    "\n",
    "# Format the scores properly\n",
    "scores_upd = accuracies_upd.copy()\n",
    "scores_upd.extend(f1_scores_upd)\n",
    "scores_upd = np.around(100*np.asarray(scores_upd), 2)\n",
    "\n",
    "diffs = scores_upd-scores\n",
    "\n",
    "final_dat = scores.copy().tolist()\n",
    "final_dat.extend(diffs)\n",
    "\n",
    "# Create data to be inserted into a dataframe for the barplot\n",
    "data_upd = {'Score Type': ['Accuracy','Accuracy','Accuracy','Accuracy','Accuracy','Accuracy',\n",
    "                           'F1 Score','F1 Score','F1 Score','F1 Score','F1 Score','F1 Score',\n",
    "                           'Accuracy Update','Accuracy Update','Accuracy Update','Accuracy Update','Accuracy Update','Accuracy Update',\n",
    "                           'F1 Update','F1 Update','F1 Update','F1 Update','F1 Update','F1 Update'],\n",
    "        'Classifier': ['Dummy (Acc)', 'Gaussian NB (Acc)', 'kNN (Acc)', 'Log. Reg. (Acc)', 'MLP (Acc)', 'SVC (Acc)',\n",
    "                       'Dummy (F1)', 'Gaussian NB (F1)', 'kNN (F1)', 'Log. Reg. (F1)', 'MLP (F1)', 'SVC (F1)',\n",
    "                       'Dummy (Acc)', 'Gaussian NB (Acc)', 'kNN (Acc)', 'Log. Reg. (Acc)', 'MLP (Acc)', 'SVC (Acc)',\n",
    "                       'Dummy (F1)', 'Gaussian NB (F1)', 'kNN (F1)', 'Log. Reg. (F1)', 'MLP (F1)', 'SVC (F1)'],\n",
    "        'Score (%)': final_dat}\n",
    "\n",
    "bardf_upd = pd.DataFrame(data_upd)\n",
    "\n",
    "fig = plt.figure(figsize=[11,5])\n",
    "\n",
    "new_cmap = colors.ListedColormap([mycol, 'red', mycomplcol, 'red'])\n",
    "df_pivot = pd.pivot_table(bardf_upd, index='Classifier', columns='Score Type', values='Score (%)', aggfunc='sum')\n",
    "im = df_pivot.plot.bar(stacked=True, colormap=new_cmap)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.title(\"Final scores for 6 classifiers.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f6630",
   "metadata": {},
   "source": [
    "Γίνεται εμφανές πως ο χειρότερος, συγκριτικά, ταξινομητής είναι ο Gaussian Naive Bayes. Μια πιθανή εξήγηση για αυτό είναι πως το παρόν σύνολο δεδομένων αφορά εικόνες, οι οποίες είναι αντικείμενα με χαρακτηριστικά (συνήθως pixels) που δε μπορούν σε καμία περίπτωση να θεωρηθούν ανεξάρτητες και ομοιόμορφα κατανεμημένες τυχαίες μεταβλητές, όπως υποθέτει ο NB.\n",
    "\n",
    "Αξίζει στο σημείο αυτό να σχολιαστεί πως αυτός ίσως είναι και ο λόγος για τον οποίο η προεπεξεργασία των δεδομένων φάνηκε να οδηγεί σε πολύ μικρές βελτιώσεις ή ακόμη και σε αρνητικές μεταβολές στην αξιολόγηση των ταξινομητών. Τόσο το πλήθος των χαρακτηριστικών, όσο και το γεγονός πως καθένα εξ αυτών λάμβανε τιμές στο διάστημα [0,1], φαίνεται να υποδεικνύει πως τα χαρακτηριστικά ήταν, ή τουλάχιστον είχαν σχέση, με pixels. Έτσι, η μη προσεκτική μεταβολή της αρχικής τους μορφής μπορεί πάρα πολύ εύκολα να οδηγήσει σε αποτελέσματα όπως αυτά που είδαμε όταν δοκιμάσαμε, για παράδειγμα, να κανονικοποιήσουμε τα δεδομένα πριν τα εισαγάγουμε στον ταξινομητή λογιστικής παλινδρόμησης. Στο ίδιο γεγονός ενδέχεται να οφείλεται και το εκ πρώτης όψεως παράδοξο πως το oversampling μέσω `SMOTE`, ο οποίος γεννά νέα δεδομένα, οδηγούσε σε μειωμένη επίδοση των ταξινομητών, παρότι το σύνολο δεδομένων είναι σημαντικά μη ισορροπημένο ως προς την ταξινόμηση urban/non-urban.\n",
    "\n",
    "Ο αμέσως επόμενος σε επίδοση ταξινομητής, αγνοώντας πάντα τον Dummy, φαίνεται να είναι ο kNN. Το αποτέλεσμα αυτό μπορεί να αποδοθεί σίγουρα εν μέρει στο γεγονός πως η αρχή λειτουργίας του είναι αρκετά απλοϊκή για να μπορέσει να ανταπεξέλθει με απόδοση παρόμοια με αυτήν πιο σύνθετων ταξινομητών (π.χ. το νευρωνικό δίκτυο).\n",
    "\n",
    "Σε ό,τι αφορά τους υπόλοιπους τρεις ταξινομητές, οι τελικές τους επιδόσεις μπορούν να χαρακτηριστούν ως αρκετά υψηλές, με τον ταξινομητή διανυσμάτων υποστήριξης να σημειώνει τη μεγαλύτερη επίδοση ως προς την ορθότητα και το MLP να δίνει τα βέλτιστα αποτελέσματα ως προς το F1 Score.\n",
    "\n",
    "Προκειμένου να αποκτήσουμε μια εικόνα ως προς το ποιο είναι το εύρος βελτιστοποίησης ανάμεσα στους ταξινομητές, αφότου πρώτα ορίσουμε ορισμένες βοηθητικές συναρτήσεις, απεικονίζουμε παρακάτω τους πίνακες σύγχυσης που προκύπτουν από την ταξινόμηση των δεδομένων αξιολόγησης από τον τελικό Gaussian NB (αριστερά), ο οποίος σημείωσε τη χαμηλότερη επιτυχία και από τον τελικό SVC (δεξιά), ο οποίος σημείωσε την υψηλότερη επιτυχία."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "249f7c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom colormap\n",
    "def CustomCmap(from_rgb,to_rgb):\n",
    "\n",
    "    # from color r,g,b\n",
    "    r1,g1,b1 = from_rgb\n",
    "\n",
    "    # to color r,g,b\n",
    "    r2,g2,b2 = to_rgb\n",
    "\n",
    "    cdict = {'red': ((0, r1, r1),\n",
    "                   (1, r2, r2)),\n",
    "           'green': ((0, g1, g1),\n",
    "                    (1, g2, g2)),\n",
    "           'blue': ((0, b1, b1),\n",
    "                   (1, b2, b2))}\n",
    "\n",
    "    cmap = colors.LinearSegmentedColormap('custom_cmap', cdict)\n",
    "    return cmap\n",
    "\n",
    "mycmap = CustomCmap([1.00, 1.00, 1.00], [0.13333, 0.35294, 0.38824]) # from white to teal\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "    \n",
    "matplotlib.rc_file_defaults() # to remove the sns darkgrid style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb8cd80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1100x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = ['Non-Urban','Urban']\n",
    "\n",
    "preds_nb = Estimators[1].predict(X_test_unmod)\n",
    "cfmatrix_nb = confusion_matrix(y_test, preds_nb)\n",
    "\n",
    "preds_svc = Estimators[5].predict(X_test_unmod)\n",
    "cfmatrix_svc = confusion_matrix(y_test, preds_svc)\n",
    "\n",
    "fig, [ax1,ax2] = plt.subplots(1,2, figsize=(11,3))\n",
    "\n",
    "for ax,cm,title in zip([ax1,ax2],[cfmatrix_nb,cfmatrix_svc],['Gaussian NB','SVC']):\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=mycmap)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=.2)\n",
    "    plt.colorbar(im, cax=cax) #, ticks=[-1,-0.5,0,0.5,1]\n",
    "    ax.set_title(f'Confusion matrix - {title}',fontsize=14)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_yticklabels(classes, rotation=45)\n",
    "    \n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        ax.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    ax.set_ylabel('True label',fontsize=14)\n",
    "    ax.set_xlabel('Predicted label',fontsize=14)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f5f5de",
   "metadata": {},
   "source": [
    "Κλείνοντας την παρούσα ανάλυση, συμπεραίνουμε πως ο προτεινόμενος ταξινομητής για το συγκεκριμένο πρόβλημα καθορίζεται βάσει του σκοπού που θέλουμε να επιτελεί. Συγκεκριμένα, τα σημαντικά προτερήματα του SVC είναι πως σημειώνει την υψηλότερη απόδοση ως προς την ορθότητα, χωρίς να χρειάζεται ιδιαίτερα υψηλούς χρόνους εκπαίδευσης, ειδικά σε σύγκριση με το νευρωνικό δίκτυο.\n",
    "\n",
    "Από την άλλη, όπως φαίνεται στον παραπάνω πίνακα σύγχυσης, ο SVC δείχνει να έχει μια τάση να μην ταξινομεί δεδομένα ως urban, το οποίο φαίνεται από το γεγονός πως τα μη διαγώνια στοιχεία εμφανίζουν σημαντική σχετική απόκλιση (το ένα είναι σχεδόν τετραπλάσιο από το άλλο). Ρίχνοντας μια ματιά στον αντίστοιχο πίνακα σύγχυσης για το νευρωνικό δίκτυο, παρατηρούμε πως παρότι η συνολική του ορθότητα είναι χαμηλότερη από του SVC, εάν κανείς θέλει έναν λιγότερο biased ταξινομητή τότε σίγουρα αυτός είναι που προτείνεται."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8aae2265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_mlp = Estimators[4].predict(X_test_unmod)\n",
    "cfmatrix_mlp = confusion_matrix(y_test, preds_mlp)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,4))\n",
    "\n",
    "im = ax.imshow(cfmatrix_mlp, interpolation='nearest', cmap=mycmap)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=.2)\n",
    "plt.colorbar(im, cax=cax) #, ticks=[-1,-0.5,0,0.5,1]\n",
    "ax.set_title(f'Confusion matrix - MLP',fontsize=15)\n",
    "tick_marks = np.arange(len(classes))\n",
    "ax.set_xticks(tick_marks)\n",
    "ax.set_xticklabels(classes)\n",
    "ax.set_yticks(tick_marks)\n",
    "ax.set_yticklabels(classes, rotation=45)\n",
    "    \n",
    "fmt = 'd'\n",
    "thresh = cfmatrix_mlp.max() / 2.\n",
    "\n",
    "for i, j in itertools.product(range(cfmatrix_mlp.shape[0]), range(cfmatrix_mlp.shape[1])):\n",
    "    ax.text(j, i, format(cfmatrix_mlp[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cfmatrix_mlp[i, j] > thresh else \"black\")\n",
    "\n",
    "ax.set_ylabel('True label',fontsize=15)\n",
    "ax.set_xlabel('Predicted label',fontsize=15)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ff1bc4",
   "metadata": {},
   "source": [
    "Κλείνοντας, εάν κανείς ήθελε να αναζητήσει καλύτερες εναλλακτικές που δεν παρουσιάστηκαν στην παρούσα ανάλυση, μια από αυτές θα μπορούσε να είναι ένα CNN ή ένα νευρωνικό δίκτυο τύπου LSTM. Ένα LSTM οποίο μπορεί να επεξεργάζεται ως input χαρακτηριστικά σε μορφή ακολουθιών με διαφορετικά μήκη, οι οποίες στην περίπτωση της αναγνώρισης εικόνας θα μπορούσαν να αντιστοιχούν στη διαφορετική ευκρίνεια των pixels στα «ουσιώδη» σημεία της εκάστοτε εικόνας (για παράδειγμα, καλύτερη διαμέριση γύρω από αντικείμενα), σε σχέση με τα λιγότερο ουσιώδη σημεία (για παράδειγμα, λιγότερο καλή διαμέριση σε φόντο όπως ο ουρανός). Από την άλλη, τα CNN χρησιμοποιούνται κατ΄ εξοχήν στην ανάλυση εικόνας, αφού είναι φτιαγμένα για αναγνώριση μοτίβων."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
