#!/usr/bin/env python
# coding: utf-8

# # Pattern Recognition (2021-2022) - Lab 3
# 
# ## Affective Music Classification
# 
# Authors: Nikolaos Stamatis (03400115), Spyridon Rigas (03400154)
# 
# Kaggle Usernames: nikos st, Spyros Rigas

# ### Step 0
# 
# The data is first imported by clicking on Click File -> Add or Upload data -> Search by URL -> from https://www.kaggle.com/geoparslp/patreco3-multitask-affective-music
# 
# GPU is enabled on Kaggle by Settings -> Accelerator -> GPU

import numpy as np
import pandas as pd

# The following prints the whole contents of the input file, it is therefore
# commented out in order to avoid spamming.
import os
#for dirname, _, filenames in os.walk('/kaggle/input'):
#    for filename in filenames:
#        print(os.path.join(dirname, filename))

# The command given raises a FileNotFoundError, since there is no data/data directory
# This is why it is replaced by the following:
os.listdir("../input/patreco3-multitask-affective-music/data/")

# ### Step 1
# 
# The following steps correspond to the random choice of two lines from the FMA sub-dataset, the loading of the corresponding files and the depiction of the spectrograms that they contain.

# a: choosing two random files
fpath = "/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train_labels.txt"
# load the train_labels.txt into a pandas dataframe
train_labels = pd.read_csv(fpath,header=0,sep='\t')

import random
random.seed(42) # for debugging

# Pick two random indices
index_1, index_2 = random.sample(range(1, train_labels.shape[0]), 2)

# Read the ID and Genre of the randomly selected lines
ID_1, Genre_1 = train_labels.iloc[index_1][0].replace(".gz", ""), train_labels.iloc[index_1][1]
ID_2, Genre_2 = train_labels.iloc[index_2][0].replace(".gz", ""), train_labels.iloc[index_2][1]

print("The files chosen are the following:")
print(f"File 1: {ID_1}, with Genre: {Genre_1} \t File 2: {ID_2}, with Genre: {Genre_2}")

# b: loading the files
fpath = "/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train/"

spec_1 = np.load(fpath+ID_1)
mel_1, chroma_1 = spec_1[:128], spec_1[128:]
spec_2 = np.load(fpath+ID_2)
mel_2, chroma_2 = spec_2[:128], spec_2[128:]

print(f"The shape of the first spectrogram is {mel_1.shape} and the shape of the second spectrogram is {mel_2.shape}.")


# Personal preferences for plotting
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap, LinearSegmentedColormap

def CustomCmap(from_rgb,to_rgb):

    # from color r,g,b
    r1,g1,b1 = from_rgb

    # to color r,g,b
    r2,g2,b2 = to_rgb

    cdict = {'red': ((0, r1, r1),
                   (1, r2, r2)),
           'green': ((0, g1, g1),
                    (1, g2, g2)),
           'blue': ((0, b1, b1),
                   (1, b2, b2))}

    cmap = LinearSegmentedColormap('custom_cmap', cdict)
    return cmap

mycmap = CustomCmap([72/255, 99/255, 147/255], [1.0, 1.0, 1.0])

mycol = (72/255, 99/255, 147/255)
mycomplcol = (129/255, 143/255, 163/255)

# c: Visualizations
from librosa.display import specshow
from mpl_toolkits.axes_grid1 import make_axes_locatable

# Plot the mel spectrograms
fig, [ax1, ax2] = plt.subplots(1,2, figsize=(12,4))

for ax, mel, genre in zip([ax1, ax2],[mel_1, mel_2],[Genre_1,Genre_2]):
    im = specshow(mel, x_axis='s', y_axis='mel', ax=ax, cmap=mycmap)
    divider = make_axes_locatable(ax)
    cax = divider.append_axes("right", size="5%", pad=.2)
    fig.colorbar(im, cax=cax, format="%+2.f dB")
    ax.set(title=f'Mel Spectrogram for {genre} genre.')

fig.tight_layout()
plt.savefig("Mels.pdf", bbox_inches='tight')
plt.show()


# The mel spectrogram is a 3D representation, where the horizontal axis corresponds to time, the vertical axis corresponds to frequency (which is measured in the mel logarithmic scale - this differentiates mel spectrograms from others) and the color corresponds to the amplitude of a specific frequency at a specific time instance, measured in the decibel scale. Mel spectrograms allow us to distinguish different types of sounds measured over the same time intervals and on the same frequency scale, simply by recognizing the relevant patterns on the decibel scale (i.e. the color code). The above visualizations provide one such example, where the decibels for the Punk genre hardly ever fall under -70 dB, unlike the decibels for the Classical genre.

# ### Step 2
# 
# As previously noted, the mel spectrograms have shapes (128, 1293) and (128, 1291), meaning that a total of 1293 and 1291 time steps, respectively, are taken into account. Training an LSTM on these data would be extremely time consuming, as the number of weights to be considered (and updated by backpropagation)  would be very large. A valid alternative is to use the so called "beat-synced" mel spectrograms, which are generated by considering only the mean between time points where the beat drops.


# Repeat the above process, this time using different files
fpath = "/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train/"

spec_1_s = np.load(fpath+ID_1)
mel_1_s, chroma_1_s = spec_1_s[:128], spec_1_s[128:]
spec_2_s = np.load(fpath+ID_2)
mel_2_s, chroma_2_s = spec_2_s[:128], spec_2_s[128:]

print(f"The shape of the first beat-synced spectrogram is {mel_1_s.shape} and the shape of the second beat-synced spectrogram is {mel_2_s.shape}.")

# The advantages of using the beat-synced files is already evident: the time steps have been reduced from 1293 and 1291 to 48 and 51, respectively, i.e. by two orders of magnitude. The corresponding graphs can be seen below.


# Plot the beat-synced mel spectrograms
fig, [ax1, ax2] = plt.subplots(1,2, figsize=(12,4))

for ax, mel, genre in zip([ax1, ax2],[mel_1_s, mel_2_s],[Genre_1,Genre_2]):
    im = specshow(mel, x_axis='s', y_axis='mel', ax=ax, cmap=mycmap)
    divider = make_axes_locatable(ax)
    cax = divider.append_axes("right", size="5%", pad=.2)
    fig.colorbar(im, cax=cax, format="%+2.f dB")
    ax.set(title=f'Beat-synced Mel Spectrogram for {genre} genre.')

fig.tight_layout()
plt.savefig("Chromas.pdf", bbox_inches='tight')
plt.show()


# Apart from the fact that the time scale has been greatly reduced, due to the reduction of the total time steps, one can also see a coarse-graining effect: while much of the original information is preserved, the beat-synced spectrograms appear as smoothened versions of the non-beat-synced versions. This is simply the price we have to pay in order to be able to utilize these data to train NNs.

# ### Step 3
# 
# Apart from the mel spectrograms, one can also work with chromagrams. A chromagram is but a specific case of a spectrogram, where the amplitude (color) is computed by frequency segments of one chromatic interval (vertical axis), i.e. what corresponds to the interval "between two piano keys" (the shape of the chroma matrices is 12 x something simply because there is a total of 7 notes and 5 sharp notes). This is why each time entry appears as a series of 12 bins stacked on the vertical axis - a chromagram is the equivalent of an octave modulated spectrogram.


print(f"The shape of the first chromagram is {chroma_1.shape} and the shape of the second chromagram is {chroma_2.shape}.")
print(f"The shape of the first beat-synced chromagram is {chroma_1_s.shape} and the shape of the second beat-synced chromagram is {chroma_2_s.shape}.")


# Plot the chromograms
fig, [ax1, ax2] = plt.subplots(1,2, figsize=(12,4))

for ax, chroma, genre in zip([ax1, ax2],[chroma_1, chroma_2],[Genre_1,Genre_2]):
    im = specshow(chroma, y_axis='chroma', x_axis='s', ax=ax, cmap=mycmap)
    divider = make_axes_locatable(ax)
    cax = divider.append_axes("right", size="5%", pad=.2)
    fig.colorbar(im, cax=cax)
    ax.set(title=f'Chromagram for {genre} genre.')

fig.tight_layout()
plt.savefig("Mel-BS.pdf", bbox_inches='tight')
plt.show()


# Plot the chromagrams
fig, [ax1, ax2] = plt.subplots(1,2, figsize=(12,4))

for ax, chroma, genre in zip([ax1, ax2],[chroma_1_s, chroma_2_s],[Genre_1,Genre_2]):
    im = specshow(chroma, y_axis='chroma', x_axis='s', ax=ax, cmap=mycmap)
    divider = make_axes_locatable(ax)
    cax = divider.append_axes("right", size="5%", pad=.2)
    fig.colorbar(im, cax=cax)
    ax.set(title=f'Beat-synced Chromagram for {genre} genre.')

fig.tight_layout()
plt.savefig("Chroma-BS.pdf", bbox_inches='tight')
plt.show()


# The same effects of smoothening and time-reduction are present here as well.

# ### Step 4
# 
# As a preparatory step before the construction and training of LSTM Neural Networks, we define some functions and classes in order to accomodate the process of data preparation and loading.
# 
# The first step is the introduction of a dictionary, which is used to merge similar classes (in order to avoid confusion during their classification) and ignore classes that do not work very well (due to underrepresentation).

import copy
from sklearn.preprocessing import LabelEncoder
from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler

CLASS_MAPPING = {
    "Rock": "Rock",
    "Psych-Rock": "Rock",
    "Indie-Rock": None,
    "Post-Rock": "Rock",
    "Psych-Folk": "Folk",
    "Folk": "Folk",
    "Metal": "Metal",
    "Punk": "Metal",
    "Post-Punk": None,
    "Trip-Hop": "Trip-Hop",
    "Pop": "Pop",
    "Electronic": "Electronic",
    "Hip-Hop": "Hip-Hop",
    "Classical": "Classical",
    "Blues": "Blues",
    "Chiptune": "Electronic",
    "Jazz": "Jazz",
    "Soundtrack": None,
    "International": None,
    "Old-Time": None,
}

# The function defined below is used in order to split the training data into actual training data and validation data: a dataset containing validation data is always required in order to constantly check on the training of the model and avoid overfitting. The splitting can either be performed in a random fashion or not. During the development of code this splitting needs to be disabled, in order to be able to perform debugging. However, once the code is operational, random splitting should be activated, in order to ensure that the results are not split-dependent. Apart from performing this split, the function also creates the corresponding data loaders that will be used to feed the data to the neural networks.


def torch_train_val_split(dataset, batch_train, batch_eval,val_size=.2, shuffle=True, seed=420):
    
    # Creating data indices for training and validation splits:
    dataset_size = len(dataset)
    indices = list(range(dataset_size))
    val_split = int(np.floor(val_size * dataset_size))
    if shuffle:
        np.random.seed(seed)
        np.random.shuffle(indices)
    train_indices = indices[val_split:]
    val_indices = indices[:val_split]

    # Creating PT data samplers and loaders:
    train_sampler = SubsetRandomSampler(train_indices)
    val_sampler = SubsetRandomSampler(val_indices)

    # Note that the DataLoaders now load 3 elements: x, y and x length
    train_loader = DataLoader(dataset,batch_size=batch_train,sampler=train_sampler)
    val_loader = DataLoader(dataset,batch_size=batch_eval,sampler=val_sampler)
    
    return train_loader, val_loader


# The following function has been edited and is pretty self-explanatory, since the methods introduced have already been used: the loading of mel spectrograms, chromagrams, or both (fused).


# Helper functions to read fused, mel, and chromagram
def read_spectrogram(spectrogram_file, spectype='both'):
    # with open(spectrogram_file, "r") as f:
    spectrograms = np.load(spectrogram_file)
    # spectrograms contains a fused mel spectrogram and chromagram
    if spectype=='both':
        return spectrograms.T
    elif spectype=='mel':
        return spectrograms[:128].T
    elif spectype=='chroma':
        return spectrograms[128:].T


# What follows is a simple Label Transformer class, which inherits from sklearn's LabelEncoder and simply transforms target values either in element or in list form. If the target values are given as string-type categories, they are transformed into integers.


class LabelTransformer(LabelEncoder):
    def inverse(self, y):
        try:
            return super(LabelTransformer, self).inverse_transform(y)
        except:
            return super(LabelTransformer, self).inverse_transform([y])

    def transform(self, y):
        try:
            return super(LabelTransformer, self).transform(y)
        except:
            return super(LabelTransformer, self).transform([y])


# Another type of transform required for LSTMs, as thoroughly explained in the 2nd lab, is the padding transform. Since not all input sequences have the same length as far as time steps are concerned, the padding transform is applied in order to set the length of all sequences equal to the longest sequence's length by padding with zeros (note that the implementation includes a padding_value=0 argument, however this is practically useless, as the padding is performed with zeros by default, due to the calling of np.zeros).


class PaddingTransform(object):
    # We note here that padding_value=0 is never utilized, since the padding
    # is performed by default using zeros, since np.zeros is called.
    def __init__(self, max_length, padding_value=0):
        self.max_length = max_length
        self.padding_value = padding_value

    def __call__(self, s):
        if len(s) == self.max_length:
            return s

        if len(s) > self.max_length:
            return s[: self.max_length]

        if len(s) < self.max_length:
            s1 = copy.deepcopy(s)
            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)
            s1 = np.vstack((s1, pad))
            return s1


# The following class concludes this preparatory analysis and is used to construct an extension to PyTorch's Dataset class. The class is responsible for the reading of the relevant files (either test or train) from a given path and apply the class mapping defined via the above dictionary on demand. The aforementioned padding is also applied, creating sequences of max_length (actual maximum length if max_length is set to a negative number). The class is slightly modified from the given version, in order to incorporate specific spectrogram loading. The output of the SpectrogramDataset is a list of N items, where N is the number of train data, where each item consists of the padded sequence, the label assigned to it from the LabelTransformer and the sequence's original length.

class SpectrogramDataset(Dataset):
    def __init__(
        self, path, class_mapping=None, train=True, max_length=-1, spectype = 'both', regression=None
    ):
        t = "train" if train else "test"
        p = os.path.join(path, t)
        self.regression = regression
        self.spectype = spectype

        self.index = os.path.join(path, f"{t}_labels.txt")
        
        self.files, labels = self.get_files_labels(self.index, class_mapping)        
        self.feats = [read_spectrogram(os.path.join(p, f), spectype=self.spectype) for f in self.files]
        self.feat_dim = self.feats[0].shape[1]
        self.lengths = [len(i) for i in self.feats]
        self.max_length = max(self.lengths) if max_length <= 0 else max_length
        self.zero_pad_and_stack = PaddingTransform(self.max_length)
        self.label_transformer = LabelTransformer()
        if isinstance(labels, (list, tuple)):
            if not regression:
                self.labels = np.array(self.label_transformer.fit_transform(labels)).astype("int64")
            else:
                self.labels = np.array(labels).astype("float64")

    def get_files_labels(self, txt, class_mapping):
        with open(txt, "r") as fd:
            lines = [l.rstrip().split("\t") for l in fd.readlines()[1:]]
        files, labels = [], []
        for l in lines:
            if self.regression:
                l = l[0].split(",")
                files.append(l[0] + ".fused.full.npy")
                labels.append(l[self.regression])
                continue
            label = l[1]
            if class_mapping:
                label = class_mapping[l[1]]
            if not label:
                continue
            ###########################################
            #fname = l[0]
            #if fname.endswith(".gz"):
            #    fname = ".".join(fname.split(".")[:-1])
            #files.append(fname)
            ###########################################
            _id = l[0].split('.')[0]
            npy_file = '{}.fused.full.npy'.format(_id)
            ###########################################
            files.append(npy_file)
            labels.append(label)
        return files, labels

    def __getitem__(self, item):
        length = min(self.lengths[item], self.max_length)
        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], length

    def __len__(self):
        return len(self.labels)


# In order to show how the class mapping of the previously defined class works, we first show an initial histogram of all genres present in the train dataset. Even though there does not seem to be significant underrepresentation of any genre (with the exception of Post-Rock, perhaps), there indeed are genres that are similar to each other and would probably lead to confusions (such as Rock and Indie-Rock).


# These simplify the choosing between beat-synced and non-beat-synced files
mpath = "/kaggle/input/patreco3-multitask-affective-music/data/"
bpath = "fma_genre_spectrograms/" # alternative: "fma_genre_spectrograms_beat/"

import seaborn as sns
sns.set(style = "darkgrid") # Personal preference


# Use the previously defined df to extract distinct genres
train_labels['Genre'].value_counts().plot(kind='barh',color=mycol)
plt.savefig("bars-before.pdf", bbox_inches='tight')
plt.show()

# The effect of the class mapping is the following:

train_dataset = SpectrogramDataset(mpath+bpath, class_mapping=CLASS_MAPPING)

genres_trans = []
for item in train_dataset:
    # Perform the inverse transform to get the non-integer type class
    # assigned to each item
    genres_trans.append(train_dataset.label_transformer.inverse(item[1])[0])
train_labels_trans = pd.DataFrame({'Transformed Genres':genres_trans})
train_labels_trans['Transformed Genres'].value_counts().plot(kind='barh', color=mycol)
plt.savefig("bars-after.pdf", bbox_inches='tight')
plt.show()


# How class mapping works is now clear: all types of rock music have been merged into one, and so have all types of folk, metal, electronic music, etc. Even though some categories have more representatives compared to others, the number of data is not too small and, importantly, confusions are not expected to arise at the same level as before.

# Note at this point that due to:
# 
# * Kaggle having a limit on RAM usage
# * The data taking up a lot of space
# 
# it is important to clear lengthy data, such as DataFrames or DataLoaders so that the notebook does not blow up. For this reason, we import the garbage cleaner and use it every time we are done with using one kind of object.

import gc

del train_dataset
del genres_trans
gc.collect()


# ### Step 5
# 
# Now that the preparatory steps are completed, we proceed with the construction of the LSTM, by adapting the code found [here](https://github.com/slp-ntua/patrec-labs/blob/main/lab3/lstm.py).


# import relevant modules
import torch
import torch.nn as nn
from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence

from datetime import datetime

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


class PadPackedSequence(nn.Module):
    def __init__(self):
        super(PadPackedSequence, self).__init__()
        self.batch_first = True
        self.max_length = None

    def forward(self, x):
        out, lengths = pad_packed_sequence(
            x, batch_first=self.batch_first, total_length=self.max_length  # type: ignore
        )
        lengths = lengths.to(out.device)
        return out, lengths  # type: ignore


class PackSequence(nn.Module):
    def __init__(self):
        super(PackSequence, self).__init__()
        self.batch_first = True

    def forward(self, x, lengths):
        lengths = lengths.to("cpu")
        out = pack_padded_sequence(
            x, lengths, batch_first=self.batch_first, enforce_sorted=False
        )

        return out


class LSTMBackbone(nn.Module):
    def __init__(self,input_dim,output_dim,rnn_size=128,num_layers=1,bidirectional=False,dropout=0.1,):
        super(LSTMBackbone, self).__init__()
        self.bidirectional = bidirectional
        self.feature_size = rnn_size * 2 if self.bidirectional else rnn_size

        self.input_dim = input_dim
        self.rnn_size = rnn_size
        self.num_layers = num_layers
        self.hidden_size = rnn_size
        self.pack = PackSequence()
        self.unpack = PadPackedSequence()
        self.batch_first = True
        self.lstm = nn.LSTM(
            input_size=input_dim,
            hidden_size=rnn_size,
            num_layers=num_layers,
            batch_first=True,
            bidirectional=self.bidirectional,
            dropout=dropout,
        )
        self.drop = nn.Dropout(dropout)
        
        self.linear = nn.Linear(self.feature_size, output_dim)

    def forward(self, x, lengths):
        packed = self.pack(x, lengths)
        output, _ = self.lstm(packed)
        output, lengths = self.unpack(output)
        output = self.drop(output)

        rnn_all_outputs, last_timestep = self._final_output(output, lengths)
        
        # Use the last_timestep for classification / regression
        last_timestep = self.linear(last_timestep)
        
        # Alternatively rnn_all_outputs can be used with an attention mechanism
        return last_timestep

    def _merge_bi(self, forward, backward):
        return torch.cat((forward, backward), dim=-1)

    def _final_output(self, out, lengths):

        if not self.bidirectional:
            return out, self._select_last_unpadded(out, lengths)

        forward, backward = (out[..., : self.hidden_size], out[..., self.hidden_size :])
        # Last backward corresponds to first token
        last_backward_out = backward[:, 0, :] if self.batch_first else backward[0, ...]
        # Last forward for real length or seq (unpadded tokens)
        last_forward_out = self._select_last_unpadded(forward, lengths)
        out = self._merge_bi(forward, backward) if self._merge_bi != "cat" else out

        return out, self._merge_bi(last_forward_out, last_backward_out)

    def _select_last_unpadded(self, out, lengths):
        gather_dim = 1  # Batch first
        gather_idx = ((lengths - 1).unsqueeze(1).expand((-1, self.hidden_size)).unsqueeze(gather_dim))
        # Last forward for real length or seq (unpadded tokens)
        last_out = out.gather(gather_dim, gather_idx).squeeze(gather_dim)

        return last_out
    

def load_backbone_from_checkpoint(model, checkpoint_path):
    model.load_state_dict(torch.load(checkpoint_path))


class CNNBackbone(nn.Module):
    def __init__(self, input_features, input_timesteps, conv_channels, kernels, maxpools, lin_channels, dropout, batchnorm):
        """
        Agrs:
            input_features (int):
                the number of input features. For example, for
                chromagrams input_features = 12
            input_timesteps (int):
                the sequence length, i.e. the number of time steps
                all data are padded when inserted, so all sequences
                must have the same length
            conv_channels (list):
                contains the input and output channels for each
                convolutional layer, therefore using a total of
                len(channels)-1 convolutional layers
            kernels (list):
                contains the kernel sizes to be considered per
                convolution. Must have length len(channels)-1
            maxpools (list):
                contains the MaxPool2d kernel sizes to be considered
                per convolution. Must have length len(channels)-1
            lin_channels (list):
                contains the output channels for each linear layer
                following the convolutions, therefore using a total of
                len(lin_channels) linear layers.
                Note that the last element must be equal to the number
                of classes to be determined.
            classes (int):
                number of output features
            dropout (float):
                dropout probability, 0 <= dropout <= 1
            batchnorm (bool):
                boolean parameter to control whether batch normalization
                is applied or not.
        """
        super(CNNBackbone, self).__init__()
        self.num_conv_layers = len(kernels)
        self.batchnorm = batchnorm
        
        seq = []
        for i in range(self.num_conv_layers):
            seq.append(nn.Conv2d(in_channels=conv_channels[i], 
                                 out_channels=conv_channels[i+1],
                                 kernel_size=kernels[i], stride=1, padding=1))
            seq.append(nn.ReLU())
            if self.batchnorm:
                seq.append(nn.BatchNorm2d(num_features=conv_channels[i+1],track_running_stats=False))
            seq.append(nn.MaxPool2d(kernel_size=maxpools[i]))
            
            
        # Flatten the output of the final convolution layer
        seq.append(nn.Flatten())
        
        convolutions = nn.Sequential(*seq)
        
        # Calculation of first linear layer dimensions
        # We build an empty tensor of appropriate size and let him go through
        # the above sequence, in order to calculate the output's size automatically
        first_lin = convolutions(torch.empty(1,conv_channels[0],input_timesteps,input_features)).size(-1)
        
        self.num_lin_layers = len(lin_channels)
        for i in range(self.num_lin_layers):
            if i == self.num_lin_layers-1:
                seq.append(nn.Linear(lin_channels[i-1], lin_channels[i]))
                break
            elif i == 0:
                seq.append(nn.Linear(first_lin, lin_channels[i]))
            else:
                seq.append(nn.Linear(lin_channels[i-1], lin_channels[i]))
            seq.append(nn.ReLU())
            seq.append(nn.Dropout(dropout))
                
        self.fitter = nn.Sequential(*seq)

    def forward(self, x):
        """CNN forward
        Args:
            x (torch.Tensor):
                [B, S, F] Batch size x sequence length x feature size
                padded inputs
        Returns:
            torch.Tensor: [B, O] Batch size x CNN output size cnn outputs
        """
        x = x.transpose(1,2)
        x.unsqueeze_(1)
        out = self.fitter(x)
        return out


# adapted from https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py
class EarlyStopping:
    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pth', trace_func=print):
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.Inf
        self.delta = delta
        self.path = path
        self.trace_func = trace_func
    def __call__(self, val_loss, model):

        score = -val_loss

        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
        elif score < self.best_score + self.delta:
            self.counter += 1
            self.trace_func(f'Validation loss increase spotted. Early stopping counter: {self.counter} out of {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
            self.counter = 0

    def save_checkpoint(self, val_loss, model):
        '''Saves model when validation loss decrease.'''
        if self.verbose:
            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')
        torch.save(model.state_dict(), self.path)
        self.val_loss_min = val_loss

def training_loop(model, train_dataloader, optimizer, device="cuda"):
    model.train()
    batch_losses = []
            
    for batch in train_dataloader:
        x_batch, y_batch, x_len = batch
                
        # Move to device
        x_batch, y_batch = x_batch.to(device), y_batch.to(device)
                
        # Clear the previous gradients first
        optimizer.zero_grad()
        
        # forward pass
        if isinstance(model, LSTMBackbone):
            yhat = model(x_batch, x_len)
        elif isinstance(model, CNNBackbone):
            yhat = model(x_batch) # No unpacking occurs in CNNs
        
        # loss calculation
        if isinstance(loss_function, nn.CrossEntropyLoss):
            loss = loss_function(yhat, y_batch)
        elif isinstance(loss_function, MultiTaskLoss):
            new_yhat = list((torch.flatten(yhat[0]).to(device),
                             torch.flatten(yhat[1]).to(device),
                             torch.flatten(yhat[2]).to(device)))
            new_ybatch = list((y_batch[:,0].to(device), y_batch[:,1].to(device),
                               y_batch[:,2].to(device)))
            loss = loss_function(new_yhat, new_ybatch)
        else: # Workaround for non-multi-task regression
            yhat = torch.flatten(yhat)
            loss = loss_function(yhat, y_batch)
        
        # Backward pass
        loss.backward()
        
        # Update weights
        optimizer.step()
        
        batch_losses.append(loss.data.item())
        
    train_loss = np.mean(batch_losses)

    return train_loss # Return train_loss and anything else you need


def validation_loop(model, val_dataloader, device="cuda"):
    
    model.eval()
    batch_losses = []
    
    for batch in val_dataloader:
        x_batch, y_batch, x_len = batch
                
        # Move to device
        x_batch, y_batch = x_batch.to(device), y_batch.to(device)
        
        if isinstance(model, LSTMBackbone):
            yhat = model(x_batch, x_len)
        elif isinstance(model, CNNBackbone):
            yhat = model(x_batch) # No unpacking occurs in CNNs
        
        # loss calculation
        if isinstance(loss_function, nn.CrossEntropyLoss):
            loss = loss_function(yhat, y_batch)
        elif isinstance(loss_function, MultiTaskLoss):
            new_yhat = list((torch.flatten(yhat[0]).to(device),
                             torch.flatten(yhat[1]).to(device),
                             torch.flatten(yhat[2]).to(device)))
            new_ybatch = list((y_batch[:,0].to(device), y_batch[:,1].to(device),
                               y_batch[:,2].to(device)))
            loss = loss_function(new_yhat, new_ybatch)
        else: # Workaround for non-multi-task regression
            yhat = torch.flatten(yhat)
            loss = loss_function(yhat, y_batch)
        
        batch_losses.append(loss.data.item())
        
    val_loss = np.mean(batch_losses)

    return val_loss # Return validation_loss and anything else you need


def overfit_with_a_couple_of_batches(model, train_dataloader, typemod, verbose_ct=100):
    
    num_batches = 1 # Choose a few batches only
    batches = []
    if typemod=='LSTM':
        epochs = 4000  # An absurd number of epochs
    else:
        epochs = 400
    train_losses = []
    
    for i in range(num_batches):
        batch = next(iter(train_dataloader))
        batches.append(batch)
        
    for epoch in range(epochs):
        
        model.train()
        batch_losses = []
        
        for batch in batches:
            
            x_batch, y_batch, x_len = batch
                
            # Move to device
            x_batch, y_batch = x_batch.to(device), y_batch.to(device)

            # Clear the previous gradients first
            optimizer.zero_grad()

            # forward pass
            if isinstance(model, LSTMBackbone):
                yhat = model(x_batch, x_len)
            elif isinstance(model, CNNBackbone):
                yhat = model(x_batch) # No unpacking occurs in CNNs

            # loss calculation
            loss = loss_function(yhat, y_batch)

            # Backward pass
            loss.backward()

            # Update weights
            optimizer.step()

            batch_losses.append(loss.data.item())
            
        train_loss = np.mean(batch_losses)
        train_losses.append(train_loss)
        if epoch % verbose_ct == 0:
            print(f"[{epoch}/{epochs}] Training loss: {train_loss:.4f}.")
            
    plt.plot(train_losses, label="Training loss", color=mycol)
    plt.legend(loc='best')
    plt.ylabel('Mean Loss')
    plt.xlabel('Epochs')
    plt.title(f"Loss graph during the process of training the {typemod}.")
    plt.savefig(f'Overfit-{typemod}.pdf', bbox_inches='tight')
    plt.show()


def train(model, train_dataloader, val_dataloader, optimizer, epochs, device="cuda", overfit_batch=False, patience=-1, verbose_ct=100):

    train_losses = []
    val_losses = []
    if isinstance(model, LSTMBackbone):
        typemod = 'LSTM'
    elif isinstance(model, CNNBackbone):
        typemod = 'CNN'
    if overfit_batch:
        print(f"Initiating {typemod} training - few batches edition.")
        overfit_with_a_couple_of_batches(model, train_dataloader, typemod, verbose_ct)
    else:
        print(f"Initiating {typemod} training.")
        model_path = f'{typemod}.pt'
        
        if patience != -1:
            early_stopping = EarlyStopping(patience=patience, verbose=False, path='checkpoint.pth')
            
        for epoch in range(epochs):
            # Training loop
            
            train_loss = training_loop(model, train_dataloader, optimizer, device)    
            train_losses.append(train_loss)
            
            # Validation loop
            with torch.no_grad():
                
                val_loss = validation_loop(model, val_dataloader, device)
                val_losses.append(val_loss)
                
            if patience != -1:
                early_stopping(val_loss, model)
                
                if early_stopping.early_stop:
                    print("Patience limit reached. Early stopping and going back to last checkpoint.")
                    break
        
            if epoch % verbose_ct == 0:        
                print(f"[{epoch}/{epochs}] Training loss: {train_loss:.4f}\t Validation loss: {val_loss:.4f}.")
            
        if patience != -1 and early_stopping.early_stop == True:
            load_backbone_from_checkpoint(model,'checkpoint.pth')        

        torch.save(model.state_dict(), model_path)

    print(f"{typemod} training finished.")
    
    return train_losses, val_losses
    
def evaluate(model, test_dataloader, device="cuda"):
    model.eval()
    predictions = []
    labels = []
    
    with torch.no_grad():
        for batch in test_dataloader:
            
            x_batch, y_batch, x_len = batch
                
            # Move to device
            x_batch, y_batch = x_batch.to(device), y_batch.to(device)
            
            if isinstance(model, LSTMBackbone):
                yhat = model(x_batch, x_len)
            elif isinstance(model, CNNBackbone):
                yhat = model(x_batch) # No unpacking occurs in CNNs
            
            # Calculate the index of the maximum argument
            yhat_idx = torch.argmax(yhat, dim=1)
            
            predictions.append(yhat_idx.cpu().numpy())
            labels.append(y_batch.cpu().numpy())
    
    return predictions, labels  # Return the model predictions

# Small code to plot losses after training
def plot_losses(train_losses,val_losses,typemod,title):
    """The method plots the calculated loss values for training and validation
    """
    plt.plot(train_losses, label="Training loss", color=mycol)
    plt.plot(val_losses, label="Validation loss", color=mycomplcol)
    plt.legend(loc='best')
    plt.ylabel('Mean Loss')
    plt.xlabel('Epochs')
    plt.title(f"Loss graph during the process of training the {typemod}.")
    plt.savefig(title, bbox_inches='tight')
    plt.show()


# #### Overfitting the models
# 
# We begin with overfit_batch training on the beat-synced mel data (because it's faster) to ensure that everything runs smoothly. This is why we set patience to -1 and deactivate the dropout layer and the L2 regularization (since these are terms that are inserted in order to avoid overfitting, which we are trying to achieve here).

batch_size = 32
split_fraction = 1/3

bpath = "fma_genre_spectrograms_beat/"

beat_mel_data = SpectrogramDataset(mpath+bpath, class_mapping=CLASS_MAPPING, spectype='mel')
train_loader_beat_mel, val_loader_beat_mel = torch_train_val_split(beat_mel_data, batch_size ,batch_size, val_size=split_fraction)


# LSTM
num_mel = 128
#num_chroma = 12
output_dim = 10 # number of genres
rnn_size = 32
num_layers = 1
dropout = 0.0
learning_rate = 0.001
weight_decay = 0.0
patience = -1
overfit_batch = True
bidirectional = True
verbose_ct = 500

epochs = 500

model = LSTMBackbone(input_dim = num_mel, output_dim=output_dim, rnn_size = rnn_size, num_layers = num_layers, bidirectional = bidirectional, dropout = dropout)
model.double()
model.to(device)
loss_function = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) #, weight_decay = weight_decay

# Overfit the model
train_losses, val_losses = train(model, train_loader_beat_mel, val_loader_beat_mel, optimizer, epochs, device=device, overfit_batch=overfit_batch, patience=patience, verbose_ct = verbose_ct)


# CNN

input_features = beat_mel_data[0][0].shape[1] # insert the used dataset here. These are practically 128 if mel, 12 if chroma and 140 if fused
input_timesteps = beat_mel_data[0][0].shape[0] # insert the used dataset here
conv_channels = [1,4,16,32,64]
kernels = [3,3,3,3]
maxpools = [2,2,3,3]
lin_channels = [128,10] # 10 corresponds to number of classes
dropout = 0.0
batchnorm = True
# -------------------
learning_rate = 0.001
weight_decay = 1e-6
patience = -1
overfit_batch = True
verbose_ct = 100

epochs = 500

model = CNNBackbone(input_features = input_features, input_timesteps = input_timesteps,
                  conv_channels = conv_channels, kernels = kernels, maxpools = maxpools,
                  lin_channels = lin_channels, dropout = dropout, batchnorm = batchnorm)
model.double()
model.to(device)
loss_function = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) #, weight_decay = weight_decay

# Overfit the model
train_losses, val_losses = train(model, train_loader_beat_mel, val_loader_beat_mel, optimizer, epochs, device=device, overfit_batch=overfit_batch, patience=patience, verbose_ct = verbose_ct)


# Even though they will be reloaded later on
del train_loader_beat_mel
del val_loader_beat_mel
del beat_mel_data
gc.collect()


# ### Step 5 & Step 6 & Step 7
# 
# In order to avoid loading the data multiple times, we train both models simultaneously for each dataset, then discard the dataset to save memory and proceed to the next one.
# 
# #### Mel Spectrogram Data
# 
# We proceed with the actual training of the LSTM on the non-beat-synced mel spectrogram data. Afterwards, we evaluate the trained model on the test data. For that purpose, we construct dataloaders to read the data.


from sklearn.metrics import f1_score, accuracy_score, recall_score, classification_report

batch_size = 32
split_fraction = 1/3

mpath = "/kaggle/input/patreco3-multitask-affective-music/data/"


bpath = "fma_genre_spectrograms/"

mel_data = SpectrogramDataset(mpath+bpath, class_mapping=CLASS_MAPPING, spectype='mel')
train_loader_mel, val_loader_mel = torch_train_val_split(mel_data, batch_size ,batch_size, val_size=split_fraction)

mel_dt_t = SpectrogramDataset(mpath+bpath, train=False, class_mapping=CLASS_MAPPING, spectype='mel')
test_loader_mel = DataLoader(mel_dt_t,batch_size=batch_size)


# LSTM
num_mel = 128
#num_chroma = 12
output_dim = 10 # number of genres
rnn_size = 100
num_layers = 2
dropout = 0.2
learning_rate = 0.00001
weight_decay = 1e-6
patience = 15
overfit_batch = False
bidirectional = True
verbose_ct = 1

epochs = 2500

model = LSTMBackbone(input_dim = num_mel, output_dim=output_dim, rnn_size = rnn_size, num_layers = num_layers, bidirectional = bidirectional, dropout = dropout)
model.double()
model.to(device)
loss_function = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)

# Train the model
train_losses, val_losses = train(model, train_loader_mel, val_loader_mel, optimizer, epochs, device=device, overfit_batch=overfit_batch, patience=patience, verbose_ct = verbose_ct)

typemod = 'LSTM'
title = f"Mel-{typemod}.pdf"

# Plot the loss diagram
plot_losses(train_losses, val_losses, typemod, title)

# Evaluate the model
predictions, labels = evaluate(model, test_loader_mel, device=device)

y_true = np.concatenate(labels, axis=0)
y_pred = np.concatenate(predictions, axis=0)

print(classification_report(y_true, y_pred))


# CNN

input_features = mel_data[0][0].shape[1] # insert the used dataset here. These are practically 128 if mel, 12 if chroma and 140 if fused
input_timesteps = mel_data[0][0].shape[0] # insert the used dataset here
conv_channels = [1,16,64,256,512]
kernels = [3,3,3,3]
maxpools = [2,2,2,2]
lin_channels = [128,64,10]
dropout = 0.23
learning_rate = 0.00001
weight_decay = 1e-6
patience = 12
overfit_batch = False
verbose_ct = 1

epochs = 2500

model = CNNBackbone(input_features = input_features, input_timesteps = input_timesteps,
                    conv_channels = conv_channels, kernels = kernels, maxpools = maxpools,
                    lin_channels = lin_channels, dropout = dropout, batchnorm=False)
model.double()
model.to(device)
loss_function = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)

# Train the model
t_losses, v_losses = train(model, train_loader_mel, val_loader_mel, optimizer, epochs, device=device, overfit_batch=overfit_batch, patience=patience, verbose_ct = verbose_ct)

typemod = 'CNN'
title = f"Mel-{typemod}.pdf"

# Plot the loss diagram
plot_losses(t_losses, v_losses, typemod, title)

# Evaluate the model
predictions, labels = evaluate(model, test_loader_mel, device=device)

y_true = np.concatenate(labels, axis=0)
y_pred = np.concatenate(predictions, axis=0)

print(classification_report(y_true, y_pred))


del train_loader_mel
del val_loader_mel
del test_loader_mel
del mel_data
del mel_dt_t
gc.collect()


# #### Beat-Synced Mel Spectrogram Data


bpath = "fma_genre_spectrograms_beat/"

beat_mel_data = SpectrogramDataset(mpath+bpath, class_mapping=CLASS_MAPPING, spectype='mel')
train_loader_beat_mel, val_loader_beat_mel = torch_train_val_split(beat_mel_data, batch_size ,batch_size, val_size=split_fraction)

beat_mel_dt_t = SpectrogramDataset(mpath+bpath, train=False, class_mapping=CLASS_MAPPING, spectype='mel')
test_loader_beat_mel = DataLoader(beat_mel_dt_t,batch_size=batch_size)

# LSTM
num_mel = 128
#num_chroma = 12
output_dim = 10 # number of genres
rnn_size = 100
num_layers = 2
dropout = 0.2
learning_rate = 0.00002
weight_decay = 1e-6
patience = 15
overfit_batch = False
bidirectional = True
verbose_ct = 1

epochs = 2500

model = LSTMBackbone(input_dim = num_mel, output_dim=output_dim, rnn_size = rnn_size, num_layers = num_layers, bidirectional = bidirectional, dropout = dropout)
model.double()
model.to(device)
loss_function = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)

# Train the model
train_losses, val_losses = train(model, train_loader_beat_mel, val_loader_beat_mel, optimizer, epochs, device=device, overfit_batch=overfit_batch, patience=patience, verbose_ct = verbose_ct)

typemod = 'LSTM'
title = f"Beat-Synced-Mel-{typemod}.pdf"
# Plot the loss diagram
plot_losses(train_losses, val_losses, typemod, title)

# Evaluate the model
predictions, labels = evaluate(model, test_loader_beat_mel, device=device)

y_true = np.concatenate(labels, axis=0)
y_pred = np.concatenate(predictions, axis=0)

print(classification_report(y_true, y_pred))

# Has to be done so that the CNN can evaluate the test data
del test_loader_beat_mel
del beat_mel_dt_t
gc.collect()

mlength = beat_mel_data[0][0].shape[0]

beat_mel_dt_t = SpectrogramDataset(mpath+bpath,max_length=mlength, train=False, class_mapping=CLASS_MAPPING, spectype='mel')
test_loader_beat_mel = DataLoader(beat_mel_dt_t,batch_size=batch_size)


# CNN

input_features = mel_data[0][0].shape[1] # insert the used dataset here. These are practically 128 if mel, 12 if chroma and 140 if fused
input_timesteps = mel_data[0][0].shape[0] # insert the used dataset here
conv_channels = [1,16,64,256,512]
kernels = [3,3,3,3]
maxpools = [2,2,2,2]
lin_channels = [128,64,10]
dropout = 0.23
learning_rate = 0.00001
weight_decay = 1e-6
patience = 12
overfit_batch = False
verbose_ct = 1

epochs = 2500

model = CNNBackbone(input_features = input_features, input_timesteps = input_timesteps,
                    conv_channels = conv_channels, kernels = kernels, maxpools = maxpools,
                    lin_channels = lin_channels, dropout = dropout, batchnorm=False)
model.double()
model.to(device)
loss_function = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)

# Train the model
train_losses, val_losses = train(model, train_loader_beat_mel, val_loader_beat_mel, optimizer, epochs, device=device, overfit_batch=overfit_batch, patience=patience, verbose_ct = verbose_ct)

typemod = 'CNN'
title = f"Beat-Synced-Mel-{typemod}.pdf"

# Plot the loss diagram
plot_losses(train_losses, val_losses, typemod, title)

# Evaluate the model
predictions, labels = evaluate(model, test_loader_beat_mel, device=device)

y_true = np.concatenate(labels, axis=0)
y_pred = np.concatenate(predictions, axis=0)

print(classification_report(y_true, y_pred))


del train_loader_beat_mel
del val_loader_beat_mel
del test_loader_beat_mel
del beat_mel_data
del beat_mel_dt_t
gc.collect()


# #### Chromagram Data


bpath = "fma_genre_spectrograms/"

chroma_data = SpectrogramDataset(mpath+bpath, class_mapping=CLASS_MAPPING, spectype='chroma')
train_loader_chroma, val_loader_chroma = torch_train_val_split(chroma_data, batch_size ,batch_size, val_size=split_fraction)

chroma_dt_t = SpectrogramDataset(mpath+bpath, train=False, class_mapping=CLASS_MAPPING, spectype='chroma')
test_loader_chroma = DataLoader(chroma_dt_t,batch_size=batch_size)

# LSTM
#num_mel = 128
num_chroma = 12
output_dim = 10 # number of genres
rnn_size = 100
num_layers = 2
dropout = 0.2
learning_rate = 0.00001
weight_decay = 1e-6
patience = 15
overfit_batch = False
bidirectional = True
verbose_ct = 1

epochs = 2500

model = LSTMBackbone(input_dim = num_chroma, output_dim=output_dim, rnn_size = rnn_size, num_layers = num_layers, bidirectional = bidirectional, dropout = dropout)
model.double()
model.to(device)
loss_function = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)

# Train the model
train_losses, val_losses = train(model, train_loader_chroma, val_loader_chroma, optimizer, epochs, device=device, overfit_batch=overfit_batch, patience=patience, verbose_ct = verbose_ct)

typemod = 'LSTM'
title = f"Chroma-{typemod}.pdf"
# Plot the loss diagram
plot_losses(train_losses, val_losses, typemod, title)

# Evaluate the model
predictions, labels = evaluate(model, test_loader_chroma, device=device)

y_true = np.concatenate(labels, axis=0)
y_pred = np.concatenate(predictions, axis=0)

print(classification_report(y_true, y_pred))


# CNN

input_features = mel_data[0][0].shape[1] # insert the used dataset here. These are practically 128 if mel, 12 if chroma and 140 if fused
input_timesteps = mel_data[0][0].shape[0] # insert the used dataset here
conv_channels = [1,16,64,256,512]
kernels = [3,3,3,3]
maxpools = [2,2,2,2]
lin_channels = [128,64,10]
dropout = 0.23
learning_rate = 0.00001
weight_decay = 1e-6
patience = 12
overfit_batch = False
verbose_ct = 1

epochs = 2500

model = CNNBackbone(input_features = input_features, input_timesteps = input_timesteps,
                    conv_channels = conv_channels, kernels = kernels, maxpools = maxpools,
                    lin_channels = lin_channels, dropout = dropout, batchnorm=False)
model.double()
model.to(device)
loss_function = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)

# Train the model
train_losses, val_losses = train(model, train_loader_chroma, val_loader_chroma, optimizer, epochs, device=device, overfit_batch=overfit_batch, patience=patience, verbose_ct = verbose_ct)

typemod = 'CNN'
title = f"Chroma-{typemod}.pdf"

# Plot the loss diagram
plot_losses(train_losses, val_losses, typemod, title)

# Evaluate the model
predictions, labels = evaluate(model, test_loader_chroma, device=device)

y_true = np.concatenate(labels, axis=0)
y_pred = np.concatenate(predictions, axis=0)

print(classification_report(y_true, y_pred))

del train_loader_chroma
del val_loader_chroma
del test_loader_chroma
del chroma_data
del chroma_dt_t
gc.collect()


# #### Fused Spectrogram Data

bpath = "fma_genre_spectrograms/"

fused_data = SpectrogramDataset(mpath+bpath, class_mapping=CLASS_MAPPING, spectype='both')
train_loader_fused, val_loader_fused = torch_train_val_split(fused_data, batch_size ,batch_size, val_size=split_fraction)

fused_dt_t = SpectrogramDataset(mpath+bpath, train=False, class_mapping=CLASS_MAPPING, spectype='both')
test_loader_fused = DataLoader(fused_dt_t,batch_size=batch_size)


# LSTM
num_mel = 128
num_chroma = 12
output_dim = 10 # number of genres
rnn_size = 100
num_layers = 2
dropout = 0.2
learning_rate = 0.00001
weight_decay = 1e-6
patience = 15
overfit_batch = False
bidirectional = True
verbose_ct = 1

epochs = 2500

model = LSTMBackbone(input_dim = num_chroma+num_mel, output_dim=output_dim, rnn_size = rnn_size, num_layers = num_layers, bidirectional = bidirectional, dropout = dropout)
model.double()
model.to(device)
loss_function = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)

# Train the model
train_losses, val_losses = train(model, train_loader_fused, val_loader_fused, optimizer, epochs, device=device, overfit_batch=overfit_batch, patience=patience, verbose_ct = verbose_ct)

typemod = 'LSTM'
title = f"Fused-{typemod}.pdf"
# Plot the loss diagram
plot_losses(train_losses, val_losses, typemod, title)

# Evaluate the model
predictions, labels = evaluate(model, test_loader_fused, device=device)

y_true = np.concatenate(labels, axis=0)
y_pred = np.concatenate(predictions, axis=0)

print(classification_report(y_true, y_pred))


# CNN

input_features = mel_data[0][0].shape[1] # insert the used dataset here. These are practically 128 if mel, 12 if chroma and 140 if fused
input_timesteps = mel_data[0][0].shape[0] # insert the used dataset here
conv_channels = [1,16,64,256,512]
kernels = [3,3,3,3]
maxpools = [2,2,2,2]
lin_channels = [128,64,10]
dropout = 0.23
learning_rate = 0.00001
weight_decay = 1e-6
patience = 12
overfit_batch = False
verbose_ct = 1

epochs = 2500

model = CNNBackbone(input_features = input_features, input_timesteps = input_timesteps,
                    conv_channels = conv_channels, kernels = kernels, maxpools = maxpools,
                    lin_channels = lin_channels, dropout = dropout, batchnorm=False)
model.double()
model.to(device)
loss_function = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)

# Train the model
train_losses, val_losses = train(model, train_loader_fused, val_loader_fused, optimizer, epochs, device=device, overfit_batch=overfit_batch, patience=patience, verbose_ct = verbose_ct)

typemod = 'CNN'
title = f"Fused-{typemod}.pdf"

# Plot the loss diagram
plot_losses(train_losses, val_losses, typemod, title)

# Evaluate the model
predictions, labels = evaluate(model, test_loader_fused, device=device)

y_true = np.concatenate(labels, axis=0)
y_pred = np.concatenate(predictions, axis=0)

print(classification_report(y_true, y_pred))


del train_loader_fused
del val_loader_fused
del test_loader_fused
del fused_data
del fused_dt_t
gc.collect()


# #### Metrics for evaluation
# 
# The metrics used for the evaluation of the above model are the following:
# 
# * **Acuracy**: The percentage of correct classifications over the total number of classifications performed. It's practically the most straightforward measure to identify the success of a classifier.
# * **Precision**: The percentage of items correctly identified as members of one Genre over the total number of items classified in this Genre. In other words, it's the ratio $$\frac{\text{TP}}{\text{TP + FP}},$$ where TP = True Positive (Correctly classified in this Genre) and FP = False Positive (Incorrectly classified in this Genre). For example, it expresses the probability that a song classified in the Post-Punk Genre, actually belongs in this Genre.
# * **Recall**: Defined using the terminology introduced for Precision, Recall is equal to $$\frac{\text{TP}}{\text{TP + FN}},$$ Using the previous example, it expresses the probability that a song that belongs in the Post-Punk Genre was actually classified in this Genre.
# * **F1-Score**: The F1-Score is simply the harmonic mean of precision and recall, i.e. $$ 2\frac{\text{Precision}\cdot\text{Recall}}{\text{Precision}+\text{Recall}}.$$
# 
# Since Precision, Recall and therefore F1-Score are measures defined for each Genre and not for the whole dataset, some averaged versions thereof need to be defined in order to characterize the classifier in its entirety. These are known as **macro** and **micro** averaged measures. The macro averaged version of each aforementioned measure is simply the unweighted mean value of the measure, taken over all Genres. The micro averaged version of these measures is a weigthed mean, which takes into account class imbalance by calculating TP, FP and FN instances for all Genres.
# 
# Based on these definitions, one may reach the following conclusions:
# 
# - When the difference between accuracy and F1-Score is relatively big, is an indication of an imbalanced dataset, i.e. a dataset where some Genres are significantly more represented compared to others.
# 
# - High discrepancies between micro and macro averages are also an indication of an imbalanced dataset.
# 
# - Whether Recall or Precision is a better metric is a completely problem-dependent issue. For example, classifiers that perform disease recognition tasks are expected to value False Negatives more than False Positives, which means that Recall is a better measure for them. In cases such as this, accuracy and F1-Score provide limited information, since the problem at hand requires extra bias towards one specific type of error.



### Step 8 - Regression models

# We redefine some previously defined functions and define some extra ones to deal with
# the new dataset and the regression problem

# Now we have to make a test-split as well, in order to be able to evaluate
# our models, since test data is not available.
def new_torch_split(dataset, batch_train, batch_eval, val_size=.25, test_size=.15, shuffle=True, seed=420):
    
    # Creating data indices for training and validation splits:
    dataset_size = len(dataset)
    indices = list(range(dataset_size))
    val_split = int(np.floor(val_size * dataset_size))
    test_split = int(np.floor(test_size*dataset_size))
    if shuffle:
        np.random.seed(seed)
        np.random.shuffle(indices)
    val_indices = indices[:val_split]
    test_indices = indices[val_split:val_split+test_split]
    train_indices = indices[val_split+test_split:]

    # Creating PT data samplers and loaders:
    train_sampler = SubsetRandomSampler(train_indices)
    val_sampler = SubsetRandomSampler(val_indices)
    test_sampler = SubsetRandomSampler(test_indices)

    train_loader = DataLoader(dataset,batch_size=batch_train,sampler=train_sampler)
    val_loader = DataLoader(dataset,batch_size=batch_eval,sampler=val_sampler)
    test_loader = DataLoader(dataset,batch_size=batch_eval,sampler=test_sampler)
    
    return train_loader, val_loader, test_loader

def evaluate_regression(model, test_dataloader, device="cuda"):
    model.eval()
    predictions = []
    labels = []
    
    with torch.no_grad():
        for batch in test_dataloader:
            
            x_batch, y_batch, x_len = batch
                
            # Move to device
            x_batch, y_batch = x_batch.to(device), y_batch.to(device)
            
            if isinstance(model, LSTMBackbone):
                yhat = model(x_batch, x_len)
            elif isinstance(model, CNNBackbone):
                yhat = model(x_batch) # No unpacking occurs in CNNs
                
            yhat = torch.flatten(yhat)
            
            predictions.append(yhat.cpu().numpy())
            labels.append(y_batch.cpu().numpy())
    
    return predictions, labels  # Return the model predictions
    
def plot_reg_results(y_true,y_pred,typemod,typefeat,title):
    plt.plot(y_true, y_pred, 'o', color=mycol)
    plt.ylabel('Predicted Values')
    plt.xlabel('True Values')
    plt.title(f"Scatterplot for {typefeat} - {typemod}.")
    plt.savefig(title, bbox_inches='tight')
    plt.show()
    
class RegSpectrogramDataset(Dataset):
    def __init__(self, path, train=True, max_length=-1, spectype = 'both', regtype='V'):
        self.regtype = regtype # regtype can also be E or D
        t = "train" if train else "test"
        p = os.path.join(path, t)
        self.index = os.path.join(path, f"{t}_labels.txt")
        self.spectype = spectype
        self.files, labels = self.get_files_labels(self.index)
        
        self.feats = [read_spectrogram(os.path.join(p, f+".fused.full.npy"), spectype=self.spectype) for f in self.files]
        self.feat_dim = self.feats[0].shape[1]
        self.lengths = [len(i) for i in self.feats]
        self.max_length = max(self.lengths) if max_length <= 0 else max_length
        self.zero_pad_and_stack = PaddingTransform(self.max_length)
        self.labels = np.array(labels).astype("float64")

    def get_files_labels(self, txt):
        with open(txt, "r") as fd:
            lines = [l.rstrip().split("\t") for l in fd.readlines()[1:]]
            
        files, labels = [], []
        for l in lines:
            l = l[0].split(",")
            k = l[1:]
            k = list(map(float,k))
            files.append(l[0])
            
            if self.regtype=='V':
                labels.append(k[0])
            elif self.regtype=='E':
                labels.append(k[1])
            elif self.regtype=='D':
                labels.append(k[2])
            else:
                labels.append(k)
        return files, labels

    def __getitem__(self, item):
        length = min(self.lengths[item], self.max_length)
        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], length

    def __len__(self):
        return len(self.labels)
        
## Valence

# Beat-Synced-Mel-Spectrograms

from scipy.stats import spearmanr

batch_size = 32
val_size = 0.25
test_size = 0.15

bpath = "multitask_dataset_beat/"

# regtype='V' concerns Valence data
beat_mel_data = RegSpectrogramDataset(mpath+bpath, spectype='mel', regtype='V')
train_beat_mel, val_beat_mel, test_beat_mel = new_torch_split(beat_mel_data, batch_size ,batch_size, val_size = val_size, test_size = test_size)

## LSTM - Valence Grid Search
#### Initiate the Grid Search

from sklearn.model_selection import ParameterGrid
# LSTM
num_mel = 128
#num_chroma = 12
output_dim = 1 # regression
rnn_size = 100
num_layers = 2
dropout = 0.2
learning_rate = 0.00002
weight_decay = 1e-6
patience = 12
overfit_batch = False
bidirectional = True
verbose_ct = 1000

epochs = 2000


param_grid = {'rnn_size': [100, 200, 400, 600], 
              'num_layers' : [2, 3, 4, 5],
               'learning_rate': [1e-05, 5e-06],
               'loss_functions': [nn.MSELoss(), 
                                  nn.L1Loss(), 
                                  nn.SmoothL1Loss()]}

my_specs = []
my_losses = []

grid = ParameterGrid(param_grid)

for params in grid:
    curr_specs = [params['rnn_size'], params['num_layers'], params['learning_rate'], params['loss_functions']]
    model = LSTMBackbone(input_dim = num_mel, output_dim = output_dim, rnn_size = params['rnn_size'],
                         num_layers = params['num_layers'], bidirectional = bidirectional, dropout = dropout)
    model.double()
    model.to(device)
    loss_function = params['loss_functions']
    optimizer = torch.optim.Adam(model.parameters(), lr = params['learning_rate'], weight_decay = weight_decay)

    # Train the model
    train_losses, val_losses = train(model, train_beat_mel, val_beat_mel, optimizer, epochs, 
                                     device=device, overfit_batch=overfit_batch, patience=patience, 
                                     verbose_ct = verbose_ct)

    typemod = 'LSTM'
    title = f"Beat-Synced-Mel-{typemod}-Regression.pdf"
    # Plot the loss diagram
    # plot_losses(train_losses, val_losses, typemod, title)

    # Evaluate the model
    predictions, labels = evaluate_regression(model, test_beat_mel, device=device)

    y_true = np.concatenate(labels, axis=0)
    y_pred = np.concatenate(predictions, axis=0)

    typefeat = 'Valence'
    plottitle = f'Beat-Synced-Mel-{typefeat}-{typemod}'
    # plot_reg_results(y_true,y_pred,typemod,typefeat,plottitle)

    result = spearmanr(y_true, y_pred)
    my_losses.append(result[0])
    my_specs.append(curr_specs)
    print(curr_specs)
    print(f"The Spearman's rank correlation measure is equal to {100*result[0]:.2f} with p-value = {result[1]:.4f}.")


my_data = [my_specs, my_losses]
grid_search_summary = pd.DataFrame(my_data)

# Show the results in an order of a descending Spearman correlation.

grid_search_summary.sort_values(by=1, axis=1, ascending=False).T

# Fit again the best model.

from sklearn.model_selection import ParameterGrid
# LSTM
num_mel = 128
#num_chroma = 12
output_dim = 1 # regression
rnn_size = 100
num_layers = 2
dropout = 0.2
learning_rate = 0.00002
weight_decay = 1e-6
patience = 12
overfit_batch = False
bidirectional = True
verbose_ct = 1000

epochs = 2000


param_grid = {'rnn_size': [600], 
              'num_layers' : [5],
               'learning_rate': [1e-05],
               'loss_functions': [nn.L1Loss()]}

my_specs = []
my_losses = []
my_val_loss = []

grid = ParameterGrid(param_grid)

counter = 0 
for params in grid:
    counter = counter + 1
    print('Model {} / {}'.format(counter, len(grid)))
    curr_specs = [params['rnn_size'], params['num_layers'], params['learning_rate'], params['loss_functions']]
    model = LSTMBackbone(input_dim = num_mel, output_dim = output_dim, rnn_size = params['rnn_size'],
                         num_layers = params['num_layers'], bidirectional = bidirectional, dropout = dropout)
    model.double()
    model.to(device)
    loss_function = params['loss_functions']
    optimizer = torch.optim.Adam(model.parameters(), lr = params['learning_rate'], weight_decay = weight_decay)

    # Train the model
    train_losses, val_losses = train(model, train_beat_mel, val_beat_mel, optimizer, epochs, 
                                     device=device, overfit_batch=overfit_batch, patience=patience, 
                                     verbose_ct = verbose_ct)
    last_v_loss = val_losses[len(val_losses)-1]

    typemod = 'LSTM'
    title = f"Beat-Synced-Mel-{typemod}-Regression.pdf"
    # Plot the loss diagram
    plot_losses(train_losses, val_losses, typemod, title)

    # Evaluate the model
    predictions, labels = evaluate_regression(model, test_beat_mel, device=device)

    y_true = np.concatenate(labels, axis=0)
    y_pred = np.concatenate(predictions, axis=0)

    typefeat = 'Valence'
    plottitle = f'Beat-Synced-Mel-{typefeat}-{typemod}'
    plot_reg_results(y_true,y_pred,typemod,typefeat,plottitle)

    result = spearmanr(y_true, y_pred)
    my_losses.append(result[0])
    my_specs.append(curr_specs)
    my_val_loss.append(last_v_loss)
    print(curr_specs)
    print(f"The Spearman's rank correlation measure is equal to {100*result[0]:.2f} with p-value = {result[1]:.4f}.")
    
## LSTM-Energy

#### Load the data.

from scipy.stats import spearmanr

batch_size = 32
val_size = 0.25
test_size = 0.15

bpath = "multitask_dataset_beat/"

# regtype='V' concerns Valence data
beat_mel_data = RegSpectrogramDataset(mpath+bpath, spectype='mel', regtype='E')
train_beat_mel, val_beat_mel, test_beat_mel = new_torch_split(beat_mel_data, 
                                                              batch_size, 
                                                              batch_size, 
                                                              val_size = val_size, 
                                                              test_size = test_size)
                                                              
# Fit the best model.

from sklearn.model_selection import ParameterGrid
# LSTM
num_mel = 128
#num_chroma = 12
output_dim = 1 # regression
rnn_size = 100
num_layers = 2
dropout = 0.2
learning_rate = 0.00002
weight_decay = 1e-6
patience = 12
overfit_batch = False
bidirectional = True
verbose_ct = 1000

epochs = 2000


param_grid = {'rnn_size': [600], 
              'num_layers' : [5],
               'learning_rate': [1e-05],
               'loss_functions': [nn.SmoothL1Loss()]}

my_specs = []
my_losses = []
my_val_loss = []

grid = ParameterGrid(param_grid)

counter = 0 
for params in grid:
    counter = counter + 1
    print('Model {} / {}'.format(counter, len(grid)))
    curr_specs = [params['rnn_size'], params['num_layers'], params['learning_rate'], params['loss_functions']]
    model = LSTMBackbone(input_dim = num_mel, output_dim = output_dim, rnn_size = params['rnn_size'],
                         num_layers = params['num_layers'], bidirectional = bidirectional, dropout = dropout)
    model.double()
    model.to(device)
    loss_function = params['loss_functions']
    optimizer = torch.optim.Adam(model.parameters(), lr = params['learning_rate'], weight_decay = weight_decay)

    # Train the model
    train_losses, val_losses = train(model, train_beat_mel, val_beat_mel, optimizer, epochs, 
                                     device=device, overfit_batch=overfit_batch, patience=patience, 
                                     verbose_ct = verbose_ct)
    last_v_loss = val_losses[len(val_losses)-1]

    typemod = 'LSTM'
    title = f"Beat-Synced-Mel-{typemod}-Regression.pdf"
    # Plot the loss diagram
    plot_losses(train_losses, val_losses, typemod, title)

    # Evaluate the model
    predictions, labels = evaluate_regression(model, test_beat_mel, device=device)

    y_true = np.concatenate(labels, axis=0)
    y_pred = np.concatenate(predictions, axis=0)

    typefeat = 'Valence'
    plottitle = f'Beat-Synced-Mel-{typefeat}-{typemod}'
    plot_reg_results(y_true,y_pred,typemod,typefeat,plottitle)

    result = spearmanr(y_true, y_pred)
    my_losses.append(result[0])
    my_specs.append(curr_specs)
    my_val_loss.append(last_v_loss)
    print(curr_specs)
    print(f"The Spearman's rank correlation measure is equal to {100*result[0]:.2f} with p-value = {result[1]:.4f}.")


my_data = [my_specs, my_val_loss, my_losses]
grid_search_summary = pd.DataFrame(my_data)

## LSTM-Danceability

#### Load the data.

from scipy.stats import spearmanr

batch_size = 32
val_size = 0.25
test_size = 0.15

bpath = "multitask_dataset_beat/"

# regtype='V' concerns Valence data
beat_mel_data = RegSpectrogramDataset(mpath+bpath, spectype='mel', regtype='D')
train_beat_mel, val_beat_mel, test_beat_mel = new_torch_split(beat_mel_data, 
                                                              batch_size, 
                                                              batch_size, 
                                                              val_size = val_size, 
                                                              test_size = test_size)

# Fit the best model.

from sklearn.model_selection import ParameterGrid
# LSTM
num_mel = 128
#num_chroma = 12
output_dim = 1 # regression
rnn_size = 100
num_layers = 2
dropout = 0.2
learning_rate = 0.00002
weight_decay = 1e-6
patience = 12
overfit_batch = False
bidirectional = True
verbose_ct = 1000

epochs = 2000


param_grid = {'rnn_size': [600], 
              'num_layers' : [5],
               'learning_rate': [5e-06],
               'loss_functions': [nn.L1Loss()]}

my_specs = []
my_losses = []
my_val_loss = []

grid = ParameterGrid(param_grid)

counter = 0 
for params in grid:
    counter = counter + 1
    print('Model {} / {}'.format(counter, len(grid)))
    curr_specs = [params['rnn_size'], params['num_layers'], params['learning_rate'], params['loss_functions']]
    model = LSTMBackbone(input_dim = num_mel, output_dim = output_dim, rnn_size = params['rnn_size'],
                         num_layers = params['num_layers'], bidirectional = bidirectional, dropout = dropout)
    model.double()
    model.to(device)
    loss_function = params['loss_functions']
    optimizer = torch.optim.Adam(model.parameters(), lr = params['learning_rate'], weight_decay = weight_decay)

    # Train the model
    train_losses, val_losses = train(model, train_beat_mel, val_beat_mel, optimizer, epochs, 
                                     device=device, overfit_batch=overfit_batch, patience=patience, 
                                     verbose_ct = verbose_ct)
    last_v_loss = val_losses[len(val_losses)-1]

    typemod = 'LSTM'
    title = f"Beat-Synced-Mel-{typemod}-Regression.pdf"
    # Plot the loss diagram
    plot_losses(train_losses, val_losses, typemod, title)

    # Evaluate the model
    predictions, labels = evaluate_regression(model, test_beat_mel, device=device)

    y_true = np.concatenate(labels, axis=0)
    y_pred = np.concatenate(predictions, axis=0)

    typefeat = 'Valence'
    plottitle = f'Beat-Synced-Mel-{typefeat}-{typemod}'
    plot_reg_results(y_true,y_pred,typemod,typefeat,plottitle)

    result = spearmanr(y_true, y_pred)
    my_losses.append(result[0])
    my_specs.append(curr_specs)
    my_val_loss.append(last_v_loss)
    print(curr_specs)
    print(f"The Spearman's rank correlation measure is equal to {100*result[0]:.2f} with p-value = {result[1]:.4f}.")


my_data = [my_specs, my_val_loss, my_losses]
grid_search_summary = pd.DataFrame(my_data)

## CNN-Valence

#### Load the data.

from scipy.stats import spearmanr

batch_size = 32
val_size = 0.25
test_size = 0.15

bpath = "multitask_dataset_beat/"

# regtype='V' concerns Valence data
beat_mel_data = RegSpectrogramDataset(mpath+bpath, spectype='mel', regtype='V')
train_beat_mel, val_beat_mel, test_beat_mel = new_torch_split(beat_mel_data, 
                                                              batch_size, 
                                                              batch_size, 
                                                              val_size = val_size, 
                                                              test_size = test_size)

# Fit the model.

input_features = beat_mel_data[0][0].shape[1] # insert the used dataset here. These are practically 128 if mel, 12 if chroma and 140 if fused
input_timesteps = beat_mel_data[0][0].shape[0] # insert the used dataset here
conv_channels = [1, 16, 64, 256, 512]
kernels = [3, 3, 3, 3]
maxpools = [2, 2, 2, 2]
lin_channels = [128, 64, 1]
dropout = 0.23
learning_rate = 0.00001
weight_decay = 1e-6
patience = 12
overfit_batch = False
verbose_ct = 1000

epochs = 2500

model = CNNBackbone(input_features = input_features, input_timesteps = input_timesteps,
                    conv_channels = conv_channels, kernels = kernels, maxpools = maxpools,
                    lin_channels = lin_channels, dropout = dropout, batchnorm=False)
model.double()
model.to(device)
loss_function = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)

# Train the model
t_losses, v_losses = train(model, train_beat_mel, val_beat_mel, optimizer, epochs, device=device, overfit_batch=overfit_batch, patience=patience, verbose_ct = verbose_ct)

typemod = 'CNN'
title = f"Beat-Synced-Mel-{typemod}-Regression.pdf"

# Plot the loss diagram
plot_losses(t_losses, v_losses, typemod, title)

# Evaluate the model
predictions, labels = evaluate_regression(model, test_beat_mel, device=device)

y_true = np.concatenate(labels, axis=0)
y_pred = np.concatenate(predictions, axis=0)

typefeat = 'Valence'
plottitle = f'Beat-Synced-Mel-{typefeat}-{typemod}'
plot_reg_results(y_true,y_pred,typemod,typefeat,plottitle)

result = spearmanr(y_true, y_pred)
print(f"The Spearman's rank correlation measure is equal to {100*result[0]:.2f} with p-value = {result[1]:.4f}.")

## CNN-Energy

#### Load the data.

from scipy.stats import spearmanr

batch_size = 32
val_size = 0.25
test_size = 0.15

bpath = "multitask_dataset_beat/"

# regtype='V' concerns Valence data
beat_mel_data = RegSpectrogramDataset(mpath+bpath, spectype='mel', regtype='E')
train_beat_mel, val_beat_mel, test_beat_mel = new_torch_split(beat_mel_data, 
                                                              batch_size, 
                                                              batch_size, 
                                                              val_size = val_size, 
                                                              test_size = test_size)

# Fit the model.

input_features = beat_mel_data[0][0].shape[1] # insert the used dataset here. These are practically 128 if mel, 12 if chroma and 140 if fused
input_timesteps = beat_mel_data[0][0].shape[0] # insert the used dataset here
conv_channels = [1, 16, 64, 256, 512]
kernels = [3, 3, 3, 3]
maxpools = [2, 2, 2, 2]
lin_channels = [128, 64, 1]
dropout = 0.23
learning_rate = 0.00001
weight_decay = 1e-6
patience = 12
overfit_batch = False
verbose_ct = 1000

epochs = 2500

model = CNNBackbone(input_features = input_features, input_timesteps = input_timesteps,
                    conv_channels = conv_channels, kernels = kernels, maxpools = maxpools,
                    lin_channels = lin_channels, dropout = dropout, batchnorm=False)
model.double()
model.to(device)
loss_function = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)

# Train the model
t_losses, v_losses = train(model, train_beat_mel, val_beat_mel, optimizer, epochs, device=device, overfit_batch=overfit_batch, patience=patience, verbose_ct = verbose_ct)

typemod = 'CNN'
title = f"Beat-Synced-Mel-{typemod}-Regression.pdf"

# Plot the loss diagram
plot_losses(t_losses, v_losses, typemod, title)

# Evaluate the model
predictions, labels = evaluate_regression(model, test_beat_mel, device=device)

y_true = np.concatenate(labels, axis=0)
y_pred = np.concatenate(predictions, axis=0)

typefeat = 'Valence'
plottitle = f'Beat-Synced-Mel-{typefeat}-{typemod}'
plot_reg_results(y_true,y_pred,typemod,typefeat,plottitle)

result = spearmanr(y_true, y_pred)
print(f"The Spearman's rank correlation measure is equal to {100*result[0]:.2f} with p-value = {result[1]:.4f}.")

## CNN-Danceability

#### Load the data.

from scipy.stats import spearmanr

batch_size = 32
val_size = 0.25
test_size = 0.15

bpath = "multitask_dataset_beat/"

# regtype='V' concerns Valence data
beat_mel_data = RegSpectrogramDataset(mpath+bpath, spectype='mel', regtype='D')
train_beat_mel, val_beat_mel, test_beat_mel = new_torch_split(beat_mel_data, 
                                                              batch_size, 
                                                              batch_size, 
                                                              val_size = val_size, 
                                                              test_size = test_size)
                                                              
# Fit the model.

input_features = beat_mel_data[0][0].shape[1] # insert the used dataset here. These are practically 128 if mel, 12 if chroma and 140 if fused
input_timesteps = beat_mel_data[0][0].shape[0] # insert the used dataset here
conv_channels = [1, 16, 64, 256, 512]
kernels = [3, 3, 3, 3]
maxpools = [2, 2, 2, 2]
lin_channels = [128, 64, 1]
dropout = 0.23
learning_rate = 0.00001
weight_decay = 1e-6
patience = 12
overfit_batch = False
verbose_ct = 1000

epochs = 2500

model = CNNBackbone(input_features = input_features, input_timesteps = input_timesteps,
                    conv_channels = conv_channels, kernels = kernels, maxpools = maxpools,
                    lin_channels = lin_channels, dropout = dropout, batchnorm=False)
model.double()
model.to(device)
loss_function = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)

# Train the model
t_losses, v_losses = train(model, train_beat_mel, val_beat_mel, optimizer, epochs, device=device, overfit_batch=overfit_batch, patience=patience, verbose_ct = verbose_ct)

typemod = 'CNN'
title = f"Beat-Synced-Mel-{typemod}-Regression.pdf"

# Plot the loss diagram
plot_losses(t_losses, v_losses, typemod, title)

# Evaluate the model
predictions, labels = evaluate_regression(model, test_beat_mel, device=device)

y_true = np.concatenate(labels, axis=0)
y_pred = np.concatenate(predictions, axis=0)

typefeat = 'Valence'
plottitle = f'Beat-Synced-Mel-{typefeat}-{typemod}'
plot_reg_results(y_true,y_pred,typemod,typefeat,plottitle)

result = spearmanr(y_true, y_pred)
print(f"The Spearman's rank correlation measure is equal to {100*result[0]:.2f} with p-value = {result[1]:.4f}.")

# Save the scatterplot.

plt.plot(y_true, y_pred, 'o', color=mycol)
plt.ylabel('Predicted Values')
plt.xlabel('True Values')
plt.title(f"Scatterplot for Danceability - {typemod}.")
#plt.savefig(title, bbox_inches='tight')
plt.savefig('CNN-Scatterplot-Danceability.pdf')


## STEPS 9

# Change a bit the definition of the CNN Backbone

class CNNBackbone(nn.Module):
    def __init__(self, input_features, input_timesteps, conv_channels, kernels, maxpools, lin_channels, dropout, batchnorm):
        """
        Agrs:
            input_features (int):
                the number of input features. For example, for
                chromagrams input_features = 12
            input_timesteps (int):
                the sequence length, i.e. the number of time steps
                all data are padded when inserted, so all sequences
                must have the same length
            conv_channels (list):
                contains the input and output channels for each
                convolutional layer, therefore using a total of
                len(channels)-1 convolutional layers
            kernels (list):
                contains the kernel sizes to be considered per
                convolution. Must have length len(channels)-1
            maxpools (list):
                contains the MaxPool2d kernel sizes to be considered
                per convolution. Must have length len(channels)-1
            lin_channels (list):
                contains the output channels for each linear layer
                following the convolutions, therefore using a total of
                len(lin_channels) linear layers.
                Note that the last element must be equal to the number
                of classes to be determined.
            classes (int):
                number of output features
            dropout (float):
                dropout probability, 0 <= dropout <= 1
            batchnorm (bool):
                boolean parameter to control whether batch normalization
                is applied or not.
        """
        super(CNNBackbone, self).__init__()
        self.num_conv_layers = len(kernels)
        self.batchnorm = batchnorm
        self.dropout = nn.Dropout(dropout)
        
        seq = []
        for i in range(self.num_conv_layers):
            seq.append(nn.Conv2d(in_channels=conv_channels[i], 
                                 out_channels=conv_channels[i+1],
                                 kernel_size=kernels[i], stride=1, padding=1))
            seq.append(nn.ReLU())
            if self.batchnorm:
                seq.append(nn.BatchNorm2d(num_features=conv_channels[i+1],track_running_stats=False))
            seq.append(nn.MaxPool2d(kernel_size=maxpools[i]))
            
        # Flatten the output of the final convolution layer
        seq.append(nn.Flatten())
        
        self.fitter = nn.Sequential(*seq)
        
        # Calculation of first linear layer dimensions
        # We build an empty tensor of appropriate size and let him go through
        # the above sequence, in order to calculate the output's size automatically
        first_lin = self.fitter(torch.empty(1,conv_channels[0],input_timesteps,input_features)).size(-1)
        
        self.fcNo1 = nn.Linear(first_lin, lin_channels[0])
        self.fcNo2 = nn.Linear(lin_channels[0], lin_channels[1])
        self.fcNo3 = nn.Linear(lin_channels[1], lin_channels[2])

    def forward(self, x):
        x = x.transpose(1,2)
        x.unsqueeze_(1)
        out_conv = self.fitter(x)
        
        out_fc1 = self.fcNo1(out_conv)
        out_fc1 = nn.ReLU()(out_fc1)
        out_fc1 = self.dropout(out_fc1)
        
        out_fc2 = self.fcNo2(out_fc1)
        out_fc2 = nn.ReLU()(out_fc2)
        out_fc2 = self.dropout(out_fc2)
        
        out = self.fcNo3(out_fc2)
        
        return out
        
from sklearn.metrics import f1_score, accuracy_score, recall_score, classification_report

batch_size = 32
split_fraction = 1/3

mpath = "/kaggle/input/patreco3-multitask-affective-music/data/"

bpath = "fma_genre_spectrograms_beat/"

beat_mel_data = SpectrogramDataset(mpath+bpath, class_mapping=CLASS_MAPPING, spectype='mel')
train_loader_beat_mel, val_loader_beat_mel = torch_train_val_split(beat_mel_data, batch_size ,batch_size, val_size=split_fraction)

mlength = beat_mel_data[0][0].shape[0]

beat_mel_dt_t = SpectrogramDataset(mpath+bpath,max_length=mlength, train=False, class_mapping=CLASS_MAPPING, spectype='mel')
test_loader_beat_mel = DataLoader(beat_mel_dt_t,batch_size=batch_size)

# Train the CNN on FMA

input_features = beat_mel_data[0][0].shape[1] # insert the used dataset here. These are practically 128 if mel, 12 if chroma and 140 if fused
input_timesteps = beat_mel_data[0][0].shape[0] # insert the used dataset here
#conv_channels = [1,16,64,256,512]
conv_channels = [1,4,16,64,256]
kernels = [3,3,3,3]
maxpools = [2,2,2,2]
lin_channels = [128,64,10]
dropout = 0.15
learning_rate = 0.00001
weight_decay = 1e-6
patience = 12
overfit_batch = False
verbose_ct = 1

epochs = 2500

model = CNNBackbone(input_features = input_features, input_timesteps = input_timesteps,
                    conv_channels = conv_channels, kernels = kernels, maxpools = maxpools,
                    lin_channels = lin_channels, dropout = dropout, batchnorm=False)
model.double()
model.to(device)
loss_function = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)

# Train the model
t_losses, v_losses = train(model, train_loader_beat_mel, val_loader_beat_mel, optimizer, epochs, device=device, overfit_batch=overfit_batch, patience=patience, verbose_ct = verbose_ct)

typemod = 'CNN'
title = f"Mel-{typemod}.pdf"

# Plot the loss diagram
plot_losses(t_losses, v_losses, typemod, title)

# Evaluate the model
predictions, labels = evaluate_classification(model, test_loader_beat_mel, device=device)

y_true = np.concatenate(labels, axis=0)
y_pred = np.concatenate(predictions, axis=0)

print(classification_report(y_true, y_pred))

# Delete the old dataloaders and dataset, to proceed to regression
del train_loader_beat_mel
del val_loader_beat_mel
del test_loader_beat_mel
del beat_mel_data
del beat_mel_dt_t
gc.collect()

os.rename(f'{typemod}.pt', f'{typemod}-stable.pt')

### Valence

batch_size = 32
val_size = 0.25
test_size = 0.15

bpath = "multitask_dataset_beat/"

# regtype='V' concerns Valence data, else E or D
beat_mel_data = RegSpectrogramDataset(mpath+bpath, max_length=mlength, spectype='mel', regtype='V')
train_beat_mel, val_beat_mel, test_beat_mel = new_torch_split(beat_mel_data, batch_size ,batch_size, val_size = val_size, test_size = test_size, seed=False)

# We currently have the best trained CNN model on the FMA dataset.
model2 = CNNBackbone(input_features = input_features, input_timesteps = input_timesteps,
                    conv_channels = conv_channels, kernels = kernels, maxpools = maxpools,
                    lin_channels = lin_channels, dropout = dropout, batchnorm=False)
model2.double()
load_backbone_from_checkpoint(model2, '/kaggle/input/cnnstable/CNN-stable.pt')

# To freeze the parameters uncomment the following lines, otherwise we proceed with fine tuning
#for param in model2.parameters():
#    param.requires_grad = False

# We want to cut off the final 2 linear layers and replace them with new ones, so that the network can learn
# them on the new dataset.
model2.fcNo2 = nn.Linear(128,64)
model2.fcNo3 = nn.Linear(64,1) # <- 1, because of regression task

learning_rate = 0.00001
weight_decay = 1e-6
patience = 15

model2.double()
model2.to(device)
loss_function = nn.MSELoss().to(device)
optimizer2 = torch.optim.Adam(model2.parameters(), lr = learning_rate, weight_decay = weight_decay)

# Train the model
t_losses, v_losses = train(model2, train_beat_mel, val_beat_mel, optimizer2, epochs, device=device, overfit_batch=overfit_batch, patience=patience, verbose_ct = verbose_ct)

typemod = 'CNN'
title = f"Beat-Synced-Mel-{typemod}-Regression.pdf"

# Plot the loss diagram
plot_losses(t_losses, v_losses, typemod, title)

# Evaluate the model
predictions, labels = evaluate_regression(model2, test_beat_mel, device=device)

y_true = np.concatenate(labels, axis=0)
y_pred = np.concatenate(predictions, axis=0)

typefeat = 'Energy'
plottitle = f'Beat-Synced-Mel-{typefeat}-{typemod}.pdf'
plot_reg_results(y_true,y_pred,typemod,typefeat,plottitle)

result = spearmanr(y_true, y_pred)
print(f"The Spearman's rank correlation measure is equal to {100*result[0]:.2f} with p-value = {result[1]:.4f}.")

### Energy

batch_size = 32
val_size = 0.25
test_size = 0.15

bpath = "multitask_dataset_beat/"

# regtype='V' concerns Valence data, else E or D
beat_mel_data = RegSpectrogramDataset(mpath+bpath, max_length=mlength, spectype='mel', regtype='E')
train_beat_mel, val_beat_mel, test_beat_mel = new_torch_split(beat_mel_data, batch_size ,batch_size, val_size = val_size, test_size = test_size, seed=False)

# We currently have the best trained CNN model on the FMA dataset.
model3 = CNNBackbone(input_features = input_features, input_timesteps = input_timesteps,
                    conv_channels = conv_channels, kernels = kernels, maxpools = maxpools,
                    lin_channels = lin_channels, dropout = dropout, batchnorm=False)
model3.double()
load_backbone_from_checkpoint(model3, '/kaggle/input/cnnstable/CNN-stable.pt')

# To freeze the parameters uncomment the following lines, otherwise we proceed with fine tuning
#for param in model2.parameters():
#    param.requires_grad = False

# We want to cut off the final 2 linear layers and replace them with new ones, so that the network can learn
# them on the new dataset.
model3.fcNo2 = nn.Linear(128,64)
model3.fcNo3 = nn.Linear(64,1) # <- 1, because of regression task

learning_rate = 0.00005
weight_decay = 1e-6
patience = 15

model3.double()
model3.to(device)
loss_function = nn.MSELoss().to(device)
optimizer3 = torch.optim.Adam(model3.parameters(), lr = learning_rate, weight_decay = weight_decay)

# Train the model
t_losses, v_losses = train(model3, train_beat_mel, val_beat_mel, optimizer3, epochs, device=device, overfit_batch=overfit_batch, patience=patience, verbose_ct = verbose_ct)

typemod = 'CNN'
title = f"Beat-Synced-Mel-{typemod}-Regression.pdf"

# Plot the loss diagram
plot_losses(t_losses, v_losses, typemod, title)

# Evaluate the model
predictions, labels = evaluate_regression(model3, test_beat_mel, device=device)

y_true = np.concatenate(labels, axis=0)
y_pred = np.concatenate(predictions, axis=0)

typefeat = 'Energy'
plottitle = f'Beat-Synced-Mel-{typefeat}-{typemod}.pdf'
plot_reg_results(y_true,y_pred,typemod,typefeat,plottitle)

result = spearmanr(y_true, y_pred)
print(f"The Spearman's rank correlation measure is equal to {100*result[0]:.2f} with p-value = {result[1]:.4f}.")


# STEP 10

# Define a new CNN class for Multitask Learning

class CNNBackbone(nn.Module):
    def __init__(self, input_features, input_timesteps, conv_channels, kernels, maxpools, lin_channels, dropout, batchnorm):
        super(CNNBackbone, self).__init__()
        self.num_conv_layers = len(kernels)
        self.batchnorm = batchnorm
        self.dropout = nn.Dropout(dropout)
        
        seq = []
        for i in range(self.num_conv_layers):
            seq.append(nn.Conv2d(in_channels=conv_channels[i], 
                                 out_channels=conv_channels[i+1],
                                 kernel_size=kernels[i], stride=1, padding=1))
            seq.append(nn.ReLU())
            if self.batchnorm:
                seq.append(nn.BatchNorm2d(num_features=conv_channels[i+1],track_running_stats=False))
            seq.append(nn.MaxPool2d(kernel_size=maxpools[i]))
            
        # Flatten the output of the final convolution layer
        seq.append(nn.Flatten())
        
        self.fitter = nn.Sequential(*seq)
        
        # Calculation of first linear layer dimensions
        # We build an empty tensor of appropriate size and let him go through
        # the above sequence, in order to calculate the output's size automatically
        first_lin = self.fitter(torch.empty(1,conv_channels[0],input_timesteps,input_features)).size(-1)
        
        self.valence_fcNo1 = nn.Linear(first_lin, lin_channels[0])
        self.valence_fcNo2 = nn.Linear(lin_channels[0], lin_channels[1])
        self.valence_fcNo3 = nn.Linear(lin_channels[1], lin_channels[2])
        
        self.energy_fcNo1 = nn.Linear(first_lin, lin_channels[0])
        self.energy_fcNo2 = nn.Linear(lin_channels[0], lin_channels[1])
        self.energy_fcNo3 = nn.Linear(lin_channels[1], lin_channels[2])
        
        self.dance_fcNo1 = nn.Linear(first_lin, lin_channels[0])
        self.dance_fcNo2 = nn.Linear(lin_channels[0], lin_channels[1])
        self.dance_fcNo3 = nn.Linear(lin_channels[1], lin_channels[2])

    def forward(self, x):
        x = x.transpose(1,2)
        x.unsqueeze_(1)
        out_conv = self.fitter(x)
        
        # Valence Layers
        valence_fc1 = self.valence_fcNo1(out_conv)
        valence_fc1 = nn.ReLU()(valence_fc1)
        valence_fc1 = self.dropout(valence_fc1)
        
        valence_fc2 = self.valence_fcNo2(valence_fc1)
        valence_fc2 = nn.ReLU()(valence_fc2)
        valence_fc2 = self.dropout(valence_fc2)
        
        out_val = self.valence_fcNo3(valence_fc2)
        
        # Energy Layers
        energy_fc1 = self.energy_fcNo1(out_conv)
        energy_fc1 = nn.ReLU()(energy_fc1)
        energy_fc1 = self.dropout(energy_fc1)
        
        energy_fc2 = self.energy_fcNo2(energy_fc1)
        energy_fc2 = nn.ReLU()(energy_fc2)
        energy_fc2 = self.dropout(energy_fc2)
        
        out_en = self.energy_fcNo3(energy_fc2)
        
        # Danceability Layers
        dance_fc1 = self.dance_fcNo1(out_conv)
        dance_fc1 = nn.ReLU()(dance_fc1)
        dance_fc1 = self.dropout(dance_fc1)
        
        dance_fc2 = self.dance_fcNo2(dance_fc1)
        dance_fc2 = nn.ReLU()(dance_fc2)
        dance_fc2 = self.dropout(dance_fc2)
        
        out_dance = self.dance_fcNo3(dance_fc2)
        
        out_list = list((out_val, out_en, out_dance))
        
        # Returns output for all three tasks
        return out_list
        
class MultiTaskLoss(nn.Module):
    def __init__(self, weights):
        """
        Agrs:
            weights (list):
                weight for each loss
        """
        super(MultiTaskLoss, self).__init__()
        self.weights = weights

    def forward(self, predictions, targets):
        """
        Agrs:
            predictions (list):
                output of CNN's forward, including the predicted values for
                valence, energy and danceability (in that order)
            targets (list):
                target values of valence, energy and danceability
        """
        single_loss = nn.MSELoss()

        loss_val = single_loss(predictions[0], targets[0])
        loss_en = single_loss(predictions[1], targets[1])
        loss_dance = single_loss(predictions[2], targets[2])
        
        total_loss = self.weights[0]*loss_val + self.weights[1]*loss_en + self.weights[2]*loss_dance
        
        return total_loss
        
def evaluate_multitask(model, test_dataloader, device="cuda"):
    model.eval()
    predictions_val = []
    labels_val = []
    predictions_en = []
    labels_en = []
    predictions_dance = []
    labels_dance = []
    
    with torch.no_grad():
        for batch in test_dataloader:
            
            x_batch, y_batch, x_len = batch
                
            # Move to device
            x_batch, y_batch = x_batch.to(device), y_batch.to(device)
            
            if isinstance(model, LSTMBackbone):
                yhat = model(x_batch, x_len)
            elif isinstance(model, CNNBackbone):
                yhat = model(x_batch) # No unpacking occurs in CNNs
                
            predictions_val.append(torch.flatten(yhat[0]).cpu().numpy())
            predictions_en.append(torch.flatten(yhat[1]).cpu().numpy())
            predictions_dance.append(torch.flatten(yhat[2]).cpu().numpy())
            
            labels_val.append(y_batch[:,0].cpu().numpy())
            labels_en.append(y_batch[:,1].cpu().numpy())
            labels_dance.append(y_batch[:,2].cpu().numpy())
    
    return predictions_val, predictions_en, predictions_dance, labels_val, labels_en, labels_dance  # Return the model predictions
    
batch_size = 32
val_size = 0.25
test_size = 0.15

bpath = "multitask_dataset_beat/"

# regtype='FULL' loads full data (valence, energy, danceability)
beat_mel_data = RegSpectrogramDataset(mpath+bpath, spectype='mel', regtype='FULL')
train_beat_mel, val_beat_mel, test_beat_mel = new_torch_split(beat_mel_data, batch_size ,batch_size, val_size = val_size, test_size = test_size, seed=False)

input_features = beat_mel_data[0][0].shape[1] # insert the used dataset here. These are practically 128 if mel, 12 if chroma and 140 if fused
input_timesteps = beat_mel_data[0][0].shape[0] # insert the used dataset here
conv_channels = [1,4,16,64,256]
kernels = [3,3,3,3]
maxpools = [2,2,2,2]
lin_channels = [128,64,1]
dropout = 0.2
learning_rate = 0.00005
weight_decay = 1e-6
patience = 12
overfit_batch = False
verbose_ct = 1

epochs = 2500

model = CNNBackbone(input_features = input_features, input_timesteps = input_timesteps,
                    conv_channels = conv_channels, kernels = kernels, maxpools = maxpools,
                    lin_channels = lin_channels, dropout = dropout, batchnorm=False)
model.double()
model.to(device)

weights = [2/3,1/6,1/6]
loss_function = MultiTaskLoss(weights = weights)

optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)

# Train the model
t_losses, v_losses = train(model, train_beat_mel, val_beat_mel, optimizer, epochs, device=device, overfit_batch=overfit_batch, patience=patience, verbose_ct = verbose_ct)

typemod = 'CNN'
title = f"Beat-Synced-Mel-{typemod}-Regression.pdf"

# Plot the loss diagram
plot_losses(t_losses, v_losses, typemod, title)

# Evaluate the model
pred_val, pred_en, pred_dance, lab_val, lab_en, lab_dance = evaluate_multitask(model, test_beat_mel, device=device)

y_val_true = np.concatenate(lab_val, axis=0)
y_val_pred = np.concatenate(pred_val, axis=0)

typefeat = 'Valence'
plottitle = f'Multitask-{typefeat}'
plot_reg_results(y_val_true,y_val_pred,typemod,typefeat,plottitle)

result_val = spearmanr(y_val_true, y_val_pred)

y_en_true = np.concatenate(lab_en, axis=0)
y_en_pred = np.concatenate(pred_en, axis=0)

typefeat = 'Energy'
plottitle = f'Multitask-{typefeat}'
plot_reg_results(y_en_true,y_en_pred,typemod,typefeat,plottitle)

result_en = spearmanr(y_en_true, y_en_pred)

y_dance_true = np.concatenate(lab_dance, axis=0)
y_dance_pred = np.concatenate(pred_dance, axis=0)

typefeat = 'Danceability'
plottitle = f'Multitask-{typefeat}'
plot_reg_results(y_dance_true,y_dance_pred,typemod,typefeat,plottitle)

result_dance = spearmanr(y_dance_true, y_dance_pred)

print("Spearman's rank correlation measure is equal to:")
print(f"Valence: {100*result_val[0]:.2f}%, with p-value = {result_val[1]:.4f}.")
print(f"Energy: {100*result_en[0]:.2f}%, with p-value = {result_en[1]:.4f}.")
print(f"Danceability: {100*result_dance[0]:.2f}%, with p-value = {result_dance[1]:.4f}.")
totspear = (1/3)*(result_val[0] + result_en[0] + result_dance[0])
print(f"Total: {100*totspear:.2f}%.")

# STEP 11 - KAGGLE SUBMISSION

import glob
    
class MultitaskDataset(Dataset):
    
    def __init__(self, max_length=-1):
        path = '../input/patreco3-multitask-affective-music/data/multitask_dataset_beat/test'
        
        file_list=glob.glob(path+'/*.npy')
        flist=[]
        idds=[]
        for f in file_list:
            flist.append(f[-19:])   
            idds.append(f[-19:-15]) 
        self.files = flist
        self.ids = idds
        
        self.feats = [read_spectrogram(os.path.join(path, f), spectype='mel') for f in self.files]
        self.feat_dim = self.feats[0].shape[1]
        self.lengths = [len(i) for i in self.feats]
        self.max_length = max(self.lengths) if max_length <= 0 else max_length
        self.zero_pad_and_stack = PaddingTransform(self.max_length)

    
    def __getitem__(self, item):
        #return self.zero_pad_and_stack(self.feats[item]), self.ids[item]
        return self.zero_pad_and_stack(self.feats[item]), self.files[item]
    
    def __len__(self):
        # Returns the number of dataset samples
        return len(self.files)
        
mlength = beat_mel_data[0][0].shape[0]
test_data = MultitaskDataset(max_length=mlength)
test_loader = DataLoader(test_data,batch_size=1)

with open("solution.txt", 'w') as f:
    f.write("Id.fused.full.npy.gz,valence,energy,danceability\n")

    model.eval()
    
    with torch.no_grad():
        for test_batch in test_loader:
            
            x, name = test_batch
            name = name[0]
                
            # Move to device
            x = x.to(device)
            
            yhat = model(x)
                
            val = torch.flatten(yhat[0]).cpu().numpy().item()
            en = torch.flatten(yhat[1]).cpu().numpy().item()
            dance =  torch.flatten(yhat[2]).cpu().numpy().item()
            
            f.write(f"{name}.gz,{val:.3f},{en:.3f},{dance:.3f}\n")